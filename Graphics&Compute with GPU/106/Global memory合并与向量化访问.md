# Global memory合并与向量化访问

### 🧑‍💻 User

gpu global memory合并访存的机制是什么？既然有合并访存，那么在数据总量一样的情况下，transaction数量是一致的，为什么还需要向量化访问(如float4)？

---

### 🤖 Assistant

这是一个非常深刻且触及GPU架构核心的问题。你的直觉很敏锐：**在理想的合并访存（Coalesced Access）下，读取同样大小的数据，无论是用 `float` 循环4次，还是用 `float4` 读取1次，产生的内存总线事务（Transactions）数量确实是一样的。**

然而，在实际的高性能计算优化中，向量化访问（如 `float4`、`int4`）仍然至关重要。

下面我将分两部分来解答：首先解释合并访存的机制，然后深入剖析为什么在事务数量一致的情况下，我们仍需要向量化访问。

---

### 第一部分：GPU Global Memory 合并访存机制

GPU的全局内存（Global Memory）访问是非常昂贵的操作（通常需要几百个时钟周期）。为了掩盖高延迟并提高带宽利用率，GPU硬件包含了一个“合并单元”（Coalescing Unit）。

#### 1. 基本原理
当一个 Warp（通常是32个线程）执行一条加载或存储指令时，硬件会检测这32个线程所请求的内存地址。如果这些地址满足特定条件（连续且对齐），硬件会将它们打包成尽可能少的**内存事务（Memory Transactions）**。

#### 2. 内存事务的粒度
现代NVIDIA GPU（如Ampere, Ada Lovelace, Hopper）的全局内存访问通常通过二级缓存（L2 Cache）进行，L2 Cache Line的大小通常是 **32 Bytes**（扇区/Sector）的倍数，常见的一笔事务是 **32 Bytes** 或 **128 Bytes**（取决于是否命中L1 Cache以及具体架构）。

#### 3. 具体的合并场景
假设一个 Warp 有32个线程（T0...T31），访问 `float`（4 Bytes）数组。

*   **场景 A：理想合并 (Coalesced)**
    *   T0 访问地址 $Addr$，T1 访问 $Addr+4$，...，T31 访问 $Addr + 31 \times 4$。
    *   总请求数据量：$32 \text{ threads} \times 4 \text{ Bytes} = 128 \text{ Bytes}$。
    *   如果起始地址 $Addr$ 是128字节对齐的，这128字节正好落在一个 Cache Line 中。
    *   **结果**：产生 **1个** 128字节的内存事务。这是最高效率。

*   **场景 B：未对齐 (Misaligned)**
    *   如果数据是连续的，但起始地址没有对齐（例如偏移了1个float）。
    *   数据将跨越两个 128字节的 Cache Line。
    *   **结果**：产生 **2个** 内存事务（虽然可能只传输了部分有效数据）。

*   **场景 C：跨步/随机 (Strided/Random)**
    *   如果每个线程访问的地址相距甚远（跨度大于128字节）。
    *   **结果**：最坏情况下，硬件必须为每个线程发起一个单独的32字节事务。总共 **32个** 事务。总线利用率极低（有效数据4字节，传输32字节，利用率1/8）。

---

### 第二部分：为什么还需要向量化访问 (float4)？

你提到的前提是正确的：
*   **Case 1 (使用 float):** 一个Warp执行4次 `LD.32` 指令。每次指令读取128字节（1个事务）。总共读取512字节，产生 **4个事务**。
*   **Case 2 (使用 float4):** 一个Warp执行1次 `LD.128` 指令。单次指令让每个线程读取16字节。总共读取 $32 \times 16 = 512$ 字节。硬件会将其拆分为 **4个连续的128字节事务**。

**结论：传输的数据总量一样，占用的内存带宽（Transactions）也一样。**

那么，为什么要用 `float4`？原因在于 **指令级并行（ILP）**、**流水线开销** 和 **延迟隐藏**。

#### 1. 减少指令流水线开销 (Instruction Issue Overhead)
GPU虽然是吞吐量导向的，但指令发射（Issue）和管线资源也是有限的。

*   **Float 方式：**
    需要 **4条** 加载指令，外加可能的循环控制指令（比较、跳转）和地址计算指令（指针递增）。
    $$ \text{Total Instructions} \approx 4 \times (\text{Load} + \text{AddressCalc}) + \text{LoopOverhead} $$
*   **Float4 方式：**
    只需要 **1条** `LD.128` 加载指令。地址计算也只需要做一次。
    $$ \text{Total Instructions} \approx 1 \times \text{Load} $$

**优势**：`float4` 极大地减少了 Load/Store Unit (LSU) 的指令压力。LSU 往往是GPU中的瓶颈资源。更少的指令意味着解码器和调度器的压力更小，能够留出更多的周期给计算指令（ALU）。

#### 2. 更好的延迟隐藏 (Latency Hiding)
这是最关键的一点。

*   **Float 方式**：你发射第1条 load 指令，然后发射第2条... 或者是串行依赖。如果后续计算依赖于这些数据，线程会很快由于等待内存而挂起（Stall）。
*   **Float4 方式**：你发射1条指令，这条指令一口气请求了 512 Bytes 的数据。
    *   这相当于在内存子系统中“排队”了更多的工作。
    *   对于GPU来说，**“在飞行中”（In-flight）的内存请求越多，越容易跑满内存带宽**。
    *   使用 `float4` 可以用更少的活跃 Warp 数（Occupancy）就能达到内存带宽的饱和。如果你的Kernel受限于寄存器数量导致 Occupancy 不高，`float4` 是救命稻草。

#### 3. 强制对齐 (Enforced Alignment)
当你定义 `float4` 时，编译器和硬件强制要求数据的首地址必须是 **16字节对齐** 的。
*   使用 `float` 指针时，由于C++的灵活性，编译器有时不敢确定指针是否对齐，可能会生成更保守、效率更低的代码（或者是Peeling loop）。
*   使用 `float4`，对齐是显式的。这保证了硬件**绝对**能进行合并访存，不会出现意外的非合并访问。

#### 4. 寄存器利用与编码效率 (SASS Level)
在汇编层面（SASS），加载128位数据（`LDG.E.128`）通常比加载4次32位数据更紧凑。
此外，编译器更容易对 `float4` 进行寄存器分配优化，因为它明确知道这4个数据是作为一个整体被加载和使用的。

### 举个直观的例子

假设你要搬运 1000 块砖头（数据）。
*   **合并访存（Coalescing）** 保证了你使用的是大卡车（128B Transaction）而不是小推车（32B Transaction）。
*   **float x 4**：你雇佣了工头，让他下达 **4次命令**，每次命令让工人们装满一辆卡车发出去。
    *   工头喊：“装第一车！” -> 等待 -> 发车。
    *   工头喊：“装第二车！” -> ...
*   **float4**：你雇佣了工头，让他下达 **1次命令**：“把这四辆卡车都装满发出去！”
    *   工头喊一次话，四辆卡车几乎同时开始装货。

虽然卡车数量（带宽消耗）一样，但**下命令的开销（指令数）**只有四分之一，而且**由于并行度更高，等待时间更容易被填补**。

### 总结

| 特性 | float (Loop x4) | float4 (Vectorized) | 评价 |
| :--- | :--- | :--- | :--- |
| **内存事务数** | 4 (假设Coalesced) | 4 | 平手 (在带宽层面) |
| **指令数量** | 4 Load + 地址计算 + 循环 | 1 Load | **float4 胜 (大幅减少指令)** |
| **LSU 压力** | 高 | 低 | **float4 胜** |
| **内存请求密度** | 低 (需多次发射) | 高 (单次发射大块请求) | **float4 胜 (更易饱和带宽)** |
| **对齐要求** | 4 Bytes | 16 Bytes | float4 要求更严，但保证了效率 |

因此，在编写CUDA Kernel时，如果数据布局允许（例如 Structure of Arrays），**优先使用 `float4` / `int4` 进行数据读写**，主要是为了**降低指令开销**和**提高内存请求的在途并发数（Memory Level Parallelism）**，而不仅仅是为了合并访存。

---

### 🧑‍💻 User

我认为：
1. 合并访存回合并到L2 cacheline，nv是128Byte，那么如果数据量是1G，无非是线程总数不一样而已，transaction的数量就是1G/128，所以对于MSS下游的来说是一样的。
2. 根本原因在于coalease之前，float4发射的LD指令数量只有1/4，而LSU处理能力是有上限的，过多的指令数量会导致指令发不下去。

---

### 🤖 Assistant

你的观点非常精准，甚至可以说是一针见血。你指出的两点核心完全正确，特别是第二点，它揭示了在带宽未满之前，限制GPU性能的真正瓶颈——**指令吞吐与LSU压力**。

我们可以把你的观点拆解并稍微做一些底层架构上的补充，以印证你的判断：

### 1. 关于“Transaction数量一致，下游MSS压力一致”
**你的观点：** 正确。
**补充：**
确实，对于 L2 Cache 和 DRAM 控制器（Memory Controller）来说，它们看到的只是一堆 32-Byte 或 128-Byte 的 Sector 请求。
*   如果你的 Kernel 是 Memory Bound（带宽受限）的，且早已跑满了显存带宽（比如 `copy` kernel），那么用 `float` 循环展开还是 `float4`，在**极限带宽**的数值上差别不会太大（前提是编译器没有傻到把 `float` 编译成非合并访问）。
*   硬件的 Coalescing Unit 位于 SM 和 L1/L2 之间，它的工作就是把来自 Warp 的请求打包。只要地址连续，无论是 4条指令凑出来的，还是1条指令发出来的，到了 L2 这一层，看起来确实是一样的。

### 2. 关于“核心原因是 LSU 指令发射瓶颈”
**你的观点：** 非常正确，这是现代 GPU 优化中最重要的考量之一。
**补充：**
这是问题的本质。我们来量化一下为什么 LSU（Load/Store Unit）会成为瓶颈：

#### A. SM 的指令流水线限制
一个 SM（Streaming Multiprocessor）每个时钟周期能发射（Issue）的指令数是有限的。以 Ampere 架构（RTX 30系/A100）为例：
*   一个 SM 分为 4 个分区（SMSP）。
*   每个分区在每个周期通常只能发射 **1 条** Warp 指令（Warp Scheduler 发射能力）。

如果你使用 `float` 读取 16 Bytes 数据：
*   需要 **4 个周期** 来发射 4 条 `LDG.E.32` 指令。
*   这 4 个周期内，Warp Scheduler 被占满，无法发射其他计算指令（除非是双发射架构且指令类型允许并行，但也非常受限）。

如果你使用 `float4` 读取 16 Bytes 数据：
*   只需要 **1 个周期** 发射 1 条 `LDG.E.128` 指令。
*   省下的 3 个周期，调度器可以发射后续的 FP32 计算指令，或者切换到其他 Warp，从而极大地提高了流水线的效率。

#### B. LSU (Load/Store Unit) 的吞吐限制
除了发射端，执行端（LSU 管线）也有吞吐上限。
LSU 是 SM 内部非常繁忙的部件，它不仅处理 Global Memory，还要处理 Shared Memory、Local Memory 和 Constant Memory。
*   如果代码中充斥着大量的 `LD.32`，LSU 队列会迅速填满。
*   一旦 LSU 队列满（Stall），Warp 就无法继续发射内存指令，导致整个流水线停顿。
*   **`float4` 相当于提高了 LSU 的“每指令传输效率”（Bytes per Instruction），让 LSU 在同样的工作频率下处理了 4 倍的数据量。**

#### C. 辅助指令的开销（指令密度）
正如你提到的，不只是 `LD` 指令本身。
*   **`float` 循环写法**：`LD` + `IADD` (地址+4) + `ISETP` (循环计数比较) + `BRANCH`。这些辅助指令会跟 `LD` 指令争抢宝贵的发射槽位。
*   **`float4` 写法**：地址计算一次搞定，没有循环开销。代码密度更高，Instruction Cache (I-Cache) 的命中率也更好。

### 总结你的观点

你是完全正确的。**合并访存（Coalescing）是“及格线”**，保证了内存带宽**有可能**被跑满，而不是被零碎的请求浪费掉。

而**向量化访问（float4）是“提速器”**，它解决的问题不在于显存物理带宽，而在于：
1.  **突破指令发射带宽（Instruction Issue Bandwidth）的瓶颈。**
2.  **降低 LSU 的排队压力。**
3.  **提高指令流水线的有效载荷比（Payload per Instruction）。**

在高频的 Kernel 优化中，往往最后拼的不是显存带宽（那个很容易跑满），拼的是 **Instruction Latency** 和 **Pipeline Stall**，这时候 `float4` 就是必杀技。