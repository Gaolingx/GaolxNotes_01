# vLLM张量并行限制原因分析

### 🧑‍💻 User

为什么vllm中，张量并行必须是4卡或者8卡，即hidden和head要被均分到gpu中，不是说3不行。除不尽的都不行？

---

### 🤖 Assistant

在 vLLM（以及其他基于 Megatron-LM 风格的张量并行库，如 DeepSpeed）中，要求张量并行组（Tensor Parallel Group, TP）的大小（GPU 数量）必须是 4 或 8（有时也支持 2），并且 `hidden_size` 和 `num_heads` 必须能被 TP 大小整除，这主要是由以下几个关键因素共同决定的：

1.  **数学除法的硬性要求（核心原因）：**
    *   张量并行（TP）的核心思想是将模型的权重张量（如 Q, K, V, O 投影矩阵，FFN 层的两个矩阵）**水平切分**到不同的 GPU 上。
    *   对于 Transformer 中的关键层：
        *   **注意力层 (Attention):** `num_heads` 必须能被 TP 大小整除。每个 GPU 负责处理 `num_heads / TP` 个头。如果除不尽，就无法平均分配每个头的计算。
        *   **MLP 层 (Feed-Forward Network):** `hidden_size` 必须能被 TP 大小整除。每个 GPU 负责处理 `hidden_size / TP` 维度的数据。同样，除不尽就无法平均分配。
        *   **输入/输出嵌入层：** 通常也涉及到 `hidden_size` 维度的切分。
    *   **结果：** 如果 `hidden_size` 或 `num_heads` 不能被 TP 大小整除，那么每个 GPU 分到的维度大小就不是整数。在计算机内存中分配张量时，维度必须是整数。**无法将 1280 维平均分给 3 个 GPU（1280 / 3 ≈ 426.666），这是物理上不允许的。**

2.  **CUDA Warp 效率与计算优化：**
    *   NVIDIA GPU 的基本执行单位是 warp（通常是 32 个线程）。为了达到最佳性能，计算操作（尤其是 GEMM - 矩阵乘）需要在 warp 级别高效利用。
    *   深度学习框架（如 PyTorch）和底层库（如 cuBLAS, cuDNN）对特定大小的矩阵操作进行了高度优化。
    *   要求 `hidden_size / TP` 和 `num_heads / TP` 是整数，**并且最好是较大的、2 的幂次方或能被 32/64/128 等整除的数**（如 64, 128, 256），可以确保：
        *   每个 GPU 上分到的子矩阵大小规整。
        *   GPU 核心（尤其是 Tensor Cores）能够高效地处理这些子矩阵。
        *   内存访问模式对齐良好，减少 bank conflict 和提高缓存利用率。
        *   避免出现不规则的小块计算，这些小块的并行效率通常很低。
    *   **例如：** `hidden_size=4096`, `TP=8` -> 每个 GPU 处理 512 维。512 能被 64/128 整除，是 GEMM 操作非常友好的大小。如果用 `TP=3`，即使 `hidden_size` 能被 3 整除（如 3072 -> 1024 维），1024 虽然不小，但框架和库针对常见 TP 大小（2,4,8）和模型尺寸（如 4096, 5120, 8192）做了大量特定优化，非标准 TP 大小难以获得同等优化。如果用 `TP=5` 分 4096，则每个 GPU 分到 819.2 维，这首先在数学上就不成立。

3.  **通信模式与效率：**
    *   张量并行需要在 GPU 之间频繁地进行 `all-reduce` 通信（在注意力输出和 FFN 层输出之后）。
    *   通信库（如 NCCL）在特定大小的通信组（尤其是 2, 4, 8 这种 2 的幂次方）上通常有最优化的算法和性能。
    *   非 2 的幂次方的通信组（如 3, 5, 6, 7）可能无法使用最优的通信算法（如 ring all-reduce 在 2 的幂次方上最有效），导致通信延迟增加或带宽利用率降低。

4.  **工程实现与测试：**
    *   像 Megatron-LM、DeepSpeed 和 vLLM 这样的框架，其张量并行实现是**高度优化且相对固定的**。它们预设了 TP=1, 2, 4, 8 这些常见场景的实现路径。
    *   支持一个任意的、非标准的 TP 大小（如 3, 5, 6, 7）意味着：
        *   需要编写大量额外的、非通用的代码来处理各种可能的除法余数情况（但如前所述，除法余数在核心维度分配上根本不允许）。
        *   需要为这些非标准配置设计新的通信模式和计算图。
        *   需要对这些非标准配置进行大量的测试和性能调优，以确保正确性和效率。
    *   考虑到 2/4/8 卡配置已经能覆盖绝大多数单节点（1-8 卡）和多节点（通过 DP+TP）的常见需求，并且模型尺寸（`hidden_size`, `num_heads`）通常设计为能被 2/4/8 整除（如 1024, 2048, 3072, 4096, 5120, 6144, 8192 等），**支持任意 TP 大小的工程成本和收益不成比例**。

**总结：**

1.  **数学必要性：** `hidden_size` 和 `num_heads` **必须**能被 TP 大小整除，否则无法将维度平均分配到各 GPU。
2.  **性能优化：** TP=2/4/8 能确保每个 GPU 分到的维度大小是整数且通常是计算友好的（如 512, 1024），并契合 GPU warp 执行、Tensor Core 使用和内存访问模式，最大化计算效率。
3.  **通信优化：** 2/4/8 卡的通信组能利用 NCCL 的最优通信算法（如 ring all-reduce）。
4.  **工程成本：** 支持任意 TP 大小（尤其是非 2 的幂次方且不能整除模型维度时）需要大量额外复杂代码和测试，而主流模型尺寸和硬件配置（单节点 1/2/4/8 卡）使得这种需求很小，性价比低。

**因此，这不是一个绝对的技术限制（理论上你可以修改框架支持任意能整除的 TP，比如 6 卡分 `hidden_size=6144`）**，而是基于**数学硬约束**、**追求极致性能**和**工程实践成本效益**的综合考虑，将支持的 TP 大小限定在常见且高效的 2、4、8 上。`TP=3` 不行，首先是因为 `hidden_size` 和 `num_heads` 除以 3 很可能不是整数（违反核心数学约束），即使某个模型维度恰好能被 3 整除（如 3072），其计算和通信效率也通常不如使用 4 或 8 卡配置。

---

### 🧑‍💻 User

为什么llama.cpp的pipeline parallel就没有gpu数量的硬性要求？

---

### 🤖 Assistant

这是一个非常好的观察！`llama.cpp` 的 Pipeline Parallelism (PP) 相比 vLLM 的张量并行 (TP) 对 GPU 数量的要求**宽松得多**，甚至可以说**几乎没有硬性数量要求**（只要 GPU 数 <= 模型层数）。核心原因在于 **PP 和 TP 的切分维度本质不同以及它们各自的目标和实现复杂度**：

1.  **切分维度的根本区别：**
    *   **张量并行 (TP - Tensor Parallelism):** 在 **单层内部** 对权重张量进行**水平切分**。它切分的是模型的 **特征维度（`hidden_size`）或注意力头的数量（`num_heads`）**。这要求切分后的子维度大小必须是整数，并且为了计算高效，最好是一个能被硬件友好处理（如整除 warp 大小、Tensor Core 要求）的数。这就是为什么 `hidden_size` 和 `num_heads` **必须** 被 TP 组大小整除。
    *   **流水线并行 (PP - Pipeline Parallelism):** 在 **模型层之间** 进行切分。它将模型的 **层（Layers）** 划分到不同的 GPU 上。每个 GPU 负责模型的一个**连续子集**（比如 GPU0 负责第 1-10 层，GPU1 负责第 11-20 层，等等）。切分单位是**层**，这是一个**离散的、可数的**实体。

2.  **层是离散实体，无需整除维度：**
    *   层数 (`num_layers`) 是一个整数。当你把 `L` 层分配给 `P` 个 GPU时，你只需要确保 `P <= L`。
    *   分配层时，目标是**尽可能均匀**（使每个 GPU 上的计算量接近），但这**不是数学上的强制要求**。你可以有各种分配策略：
        *   **均匀分配 (最优)：** 如果 `L % P == 0`，则每个 GPU 分得 `L / P` 层。
        *   **非均匀分配 (完全可行)：** 如果 `L % P != 0` (例如 L=28, P=3)，你可以分配成 (10, 9, 9) 层或者 (9, 10, 9) 层等。虽然计算负载可能不完全平衡（最后一个 GPU 可能稍微忙一点或闲一点），但这在**功能上是完全正确且可运行的**。不会出现维度不是整数这种根本性的错误。

3.  **`llama.cpp` PP 实现的相对简单性：**
    *   **Naive PP：** `llama.cpp` 实现的 PP 通常是比较“朴素”的 Pipeline Parallelism，可能更接近于 GPipe 的朴素版本，或者甚至没有严格的 micro-batching。它主要依赖**层间通信**：一个 GPU 计算完它负责的所有层后，将最终的输出张量（通常是 `[batch_size, seq_len, hidden_size]`）传递给下一个 GPU。下一个 GPU 将这个张量作为输入，继续计算它负责的层。
    *   **通信模式简单：** 通信主要发生在相邻的 GPU 之间 (GPU `i` -> GPU `i+1`)，并且传输的是整个层的输出张量。这种点对点通信 (`send`/`recv` 或 `P2P`）对通信组大小没有特殊要求。它不像 TP 那样需要复杂的 `all-reduce`（其性能对组大小敏感，尤其是需要 ring 算法时）。
    *   **计算独立性：** 在 PP 中，每个 GPU 上执行的是**完整的层计算**（例如，一个完整的 Transformer Block，包含 Attention 和 MLP）。这意味着在单个 GPU 内部的计算，**不需要像 TP 那样进行跨 GPU 的同步协作**来完成一个算子。每个 GPU 独立地运行它自己的层计算，计算完成后把结果扔给下一个 GPU 即可。因此，不需要担心 `hidden_size` 或 `num_heads` 在单个 GPU 内部的计算是否“整除友好”，因为它们在单个 GPU 上是以**完整维度**进行计算的。

4.  **`llama.cpp` 的目标和权衡：**
    *   `llama.cpp` 的核心优势在于其 **C++ 实现、轻量级、广泛的硬件支持** (从服务器 GPU 到笔记本 CPU 甚至手机) 以及 **低精度推理优化** (GGUF)。它的 PP 实现更侧重于**功能的正确性、实现的相对简洁性和广泛的适用性**，而不是像专为大规模训练/推理设计的框架 (如 Megatron-LM, DeepSpeed, vLLM) 那样追求极致的分布式计算效率、复杂的负载均衡和重叠通信。
    *   接受**非均匀层分配带来的潜在负载不均衡**是实现灵活性和广泛支持的一个合理代价。对于很多推理场景，特别是在 GPU 数量不多（比如 2-8 卡）且模型层数足够的情况下，这种不均衡通常是可接受的。

5.  **为什么 vLLM 的 TP 要求严格而 PP 可能也灵活？**
    *   vLLM 的核心创新在于其 **PagedAttention 和高效的内存管理**，极大优化了大模型推理的吞吐量，特别是对于长序列和动态批处理。它的 TP 实现继承自 Megatron-LM 风格，**高度优化且紧密耦合**于其计算内核，因此继承了 TP 的严格整除要求。
    *   理论上，vLLM 也可以实现类似 `llama.cpp` 的 PP，并且对 GPU 数量要求不严格（只要 `P <= num_layers`）。vLLM 也支持 PP。但在实际中，vLLM 文档和常见示例通常更强调 TP（因为 TP 在单节点内通信效率更高），并且其 PP 实现可能也包含更多优化（如 micro-batching），对均匀分配有偏好。但 **PP 的本质决定了它不像 TP 那样有维度的硬性数学约束**。

**总结：**

`llama.cpp` Pipeline Parallelism 对 GPU 数量没有像 vLLM Tensor Parallelism 那样的硬性要求（必须是 2/4/8 且整除维度），根本原因在于：

1.  **切分维度不同：** PP 切分**层（离散可数）**，TP 切分**特征/头维度（需连续整除）**。
2.  **无维度整除需求：** 分配层时，`num_layers` 除以 GPU 数量**不需要整除**，非均匀分配在功能上完全可行（虽可能负载不均衡）。
3.  **计算独立性：** 每个 GPU 执行完整的层计算，**无需在单层内跨 GPU 协作**，避免了 TP 的核心约束。
4.  **通信简单：** 主要依赖相邻 GPU 间的点对点数据传输，对通信组大小无特殊算法要求。
5.  **实现目标：** `llama.cpp` PP 优先考虑**功能实现、简洁性和广泛适用性**，可以接受非均匀分配带来的潜在效率损失。

因此，你可以相对自由地选择 GPU 数量进行 `llama.cpp` 的流水线并行，只要 GPU 数量不超过模型的总层数即可。这是 PP 相较于 TP 的一个显著优势，尤其是在硬件配置不那么标准或需要灵活扩展时。