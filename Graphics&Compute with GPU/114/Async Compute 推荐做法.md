# Async Compute æ¨èåšæ³•

### ğŸ§‘â€ğŸ’» User

About Async Compute and Overlapï¼Œä¸ºä»€ä¹ˆä»¥ä¸‹åšæ³•æ˜¯æ¨èçš„ï¼Ÿ

- Use GPU Trace provided by NVIDIA Nsight Graphics to identify potential overlap pairs:
Look for a combination of low top unit throughput metrics.
  - If the SM occupancy shows a significant portion of unused warp slots, then itâ€™s potentially an effective overlap. SM Idle % without conflicting high throughput units is almost always a guaranteed improvement.
  - Capture another GPU Trace to confirm the result.
- Try overlapping different datapaths. For example, FP, ALU, Memory Requests, RT Core, Tensor Core, Graphics-pipe.
  - FP, ALU, and Tensor share a different register file.
- Overlap compute workloads with other compute workloads. This scenario is very efficient on NVIDIA Ampere Architecture GPUs.
- Consider converting some of the graphics work such as post-processing passes to compute: this can present new overlap opportunities.
- Consider running async work between frames.
- Measure the performance difference over the whole frame or average over multiple frames if intraframe async compute is implemented.
- Verify the behavior across different GPU tiers. High-end GPUs have more SM units, so more potential for overlap.
- Verify the behavior at different resolutions. Low resolution usually means less pixel warps and thus more idle time for the SMs and more overlap potential.

ä»¥ä¸‹ä¸æ¨èï¼š
- Donâ€™t only focus purely on the SM warp occupancy, start by looking at unit throughputs.
- Donâ€™t use long async compute workloads unless they can finish comfortably before the dependency on the sync queue.
- Donâ€™t overlap workloads that use the same resource for reading and writing, as it causes data hazards.
- Donâ€™t overlap workloads with high L1 and L2 usage and VRAM throughput metrics. Oversubscription or reduction in cache hit-rate will result in performance degradation.
- Be careful with more than two queues if hardware-accelerated GPU scheduling is disabled. Software scheduled workloads from more than two queues (copy queue aside) may result in workload serialization.
- Be careful with overlapping compute-over-compute workloads where both cause WFIs. WFIs during simultaneous compute on both queues can result in synchronization across the workloads. Frequent descriptor heap changes on the async queue may cause additional WFIs.
- Donâ€™t use DX12 command queue priorities to influence async and sync workload priorities. The interface simply dictates the queue from which the commands are consumed first and does not affect warp priorities in any meaningful way.
- Donâ€™t overlap RTCore workloads. Both share the same throughput units and due to interference will degrade performance.

---

### ğŸ¤– Assistant

è¿™äº›â€œæ¨è / ä¸æ¨èâ€å®è·µçš„æ ¸å¿ƒé€»è¾‘ï¼Œå¹¶ä¸åœ¨äºæŸä¸€æ¡ç»éªŒæœ¬èº«ï¼Œè€Œåœ¨äº**Async Compute æ˜¯å¦çœŸçš„å½¢æˆäº†â€œèµ„æºäº’è¡¥çš„å¹¶è¡Œâ€ï¼Œè€Œä¸æ˜¯â€œåŒä¸€ç“¶é¢ˆä¸Šçš„æ—¶é—´åˆ‡ç‰‡â€**ã€‚ä¸‹é¢æˆ‘æŒ‰â€œç¡¬ä»¶è°ƒåº¦çœŸå®çº¦æŸ â†’ æŒ‡æ ‡é€‰æ‹© â†’ æ¶æ„å±‚åŸå› â€çš„é¡ºåºï¼ŒæŠŠä¸ºä»€ä¹ˆè¿™äº›åšæ³•æ˜¯æ­£ç¡®çš„ç³»ç»Ÿæ€§åœ°è§£é‡Šæ¸…æ¥šã€‚

---

## ä¸€ã€ä¸ºä»€ä¹ˆè¦ä» **Unit Throughput** è€Œä¸æ˜¯ **SM Occupancy** å…¥æ‰‹

### 1. SM Occupancy åªæ˜¯â€œçº¿ç¨‹æ˜¯å¦èƒ½é©»ç•™â€ï¼Œä¸æ˜¯â€œæ˜¯å¦æœ‰å¯æ‰§è¡Œçš„å·¥ä½œâ€

* SM occupancy åæ˜ çš„æ˜¯ï¼š

  * Warp æ˜¯å¦èƒ½è¢«è°ƒåº¦è¿› SM
  * æ˜¯å¦è¢«å¯„å­˜å™¨ / shared memory é™åˆ¶
* ä½† **warp èƒ½é©»ç•™ â‰  warp æ­£åœ¨æ‰§è¡Œæœ‰ç”¨æŒ‡ä»¤**

çœŸå®æ‰§è¡Œä¸­ï¼Œwarp å¯èƒ½å› ä¸ºï¼š

* memory dependency
* pipeline hazard
* scoreboard stall
* ç­‰å¾… tensor / RT / LSU pipeline

è€Œå¤„äº **Idle / Waiting** çŠ¶æ€ã€‚

### 2. Unit Throughput ç›´æ¥åæ˜ â€œå“ªä¸ªç¡¬ä»¶å•å…ƒåœ¨é—²ç€â€

Nsight Graphics çš„ Top Unit Throughputï¼ˆSOLï¼‰æŒ‡æ ‡ï¼Œæœ¬è´¨ä¸Šå›ç­”çš„æ˜¯ï¼š

> â€œåœ¨è¿™æ®µæ—¶é—´å†…ï¼Œå“ªäº› execution unit æ²¡è¢«å–‚é¥±ï¼Ÿâ€

ä¾‹å¦‚ï¼š

* FP32 ALU 20%
* Tensor Core 5%
* LSU 80%
* RT Core 0%

è¿™æ„å‘³ç€ï¼š

* **ç®—åŠ›ä¾§å­˜åœ¨å¤§é‡å¯è¢«å¡«å……çš„ç©ºæ´**
* åªè¦æ–° workload ä¸å’Œ LSU å†²çªï¼Œå°±å‡ ä¹æ˜¯â€œç™½æ¡æ€§èƒ½â€

è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæ–‡æ¡£å¼ºè°ƒï¼š

> *SM Idle % without conflicting high throughput units is almost always a guaranteed improvement*

è¿™æ˜¯åœ¨**ç¡¬ä»¶å±‚é¢è¿‘ä¼¼ç¡®å®šæ€§æˆç«‹**çš„åˆ¤æ–­ã€‚

---

## äºŒã€ä¸ºä»€ä¹ˆæ¨èâ€œå¯»æ‰¾ä½ååå•å…ƒçš„äº’è¡¥å¯¹â€

### 1. GPU æ˜¯å¤š datapath å¹¶è¡Œç³»ç»Ÿï¼Œä¸æ˜¯å•ä¸€ç®—åŠ›æ± 

NVIDIA GPU å†…éƒ¨è‡³å°‘åŒ…å«ä»¥ä¸‹ç›¸å¯¹ç‹¬ç«‹çš„ datapathï¼š

* FP / INT ALU
* Tensor Core
* Load/Store (Memory Requests)
* RT Core
* Graphics fixed-function pipeï¼ˆROPã€Rasterã€Setupï¼‰

Async Compute çš„æœ¬è´¨æ˜¯ï¼š

> **è®©ä¸åŒ datapath çš„ pipeline åŒæ—¶ä¿æŒ non-empty**

### 2. FP / ALU / Tensor â€œå¯„å­˜å™¨æ–‡ä»¶åˆ†ç¦»â€éå¸¸å…³é”®

åœ¨ Ampere åŠä¹‹åæ¶æ„ä¸­ï¼š

* Tensor Core ä½¿ç”¨ç‹¬ç«‹å¯„å­˜å™¨ bank
* FP / INT ä½¿ç”¨é€šç”¨ RF
* Tensor pipeline ä¸ FP32 pipeline ç»“æ„æ€§åˆ†ç¦»

è¿™æ„å‘³ç€ï¼š

* Tensor-heavy CS å¯ä»¥ä¸ FP-heavy PS å¹¶è¡Œ
* Tensor-heavy AI denoise å¯ä»¥å’Œ vertex / raster overlap

è¿™ä¸æ˜¯â€œç†è®ºå¯èƒ½â€ï¼Œè€Œæ˜¯ **ç¡¬ä»¶è®¾è®¡ç›®æ ‡**ã€‚

---

## ä¸‰ã€ä¸ºä»€ä¹ˆâ€œCompute-over-Computeâ€åœ¨ Ampere ä¸Šåè€Œé«˜æ•ˆ

è¿™æ˜¯å¾ˆå¤šäººç›´è§‰ä¸Šä¼šæ€€ç–‘çš„ä¸€ç‚¹ã€‚

### 1. Ampere çš„å…³é”®å˜åŒ–

* æ›´å¼ºçš„ instruction-level interleaving
* æ›´æˆç†Ÿçš„ scoreboard ä¸ dual-issue
* æ›´é«˜æ•ˆçš„ async pipeline draining
* Tensor / FP / LSU æ›´ç‹¬ç«‹

å› æ­¤ï¼š

* ä¸¤ä¸ª compute queue å¹¶ä¸ç­‰ä»·äºâ€œæ—¶é—´åˆ‡ç‰‡â€
* è€Œæ˜¯å¯èƒ½å½¢æˆ **çœŸæ­£çš„å¤š pipeline å¹¶è¡Œ**

### 2. ä½†å‰æä»ç„¶æ˜¯ï¼š**unit usage äº’è¡¥**

å¦‚æœä¸¤ä¸ª compute workloadï¼š

* éƒ½æ˜¯ memory-bound
* æˆ–éƒ½åœ¨ saturate L2 / DRAM

é‚£ä¹ˆ overlap ä¸€å®šæ˜¯è´Ÿæ”¶ç›Šï¼Œè¿™ä¹Ÿæ˜¯åé¢â€œä¸æ¨èâ€çš„æ¥æºã€‚

---

## å››ã€ä¸ºä»€ä¹ˆå»ºè®®æŠŠéƒ¨åˆ† Graphics Pass è½¬æˆ Compute

### 1. Graphics pipeline çš„å›ºå®šé˜¶æ®µé™åˆ¶ overlap

Graphics queueï¼š

* å¼ºä¾èµ– pipeline order
* éšå« barrierï¼ˆå¦‚ render target transitionsï¼‰
* å—é™äº raster / ROP ç»“æ„

Compute queueï¼š

* barrier æ›´æ˜¾å¼
* æ›´å®¹æ˜“æ‹†åˆ†ä¸ºå°ç²’åº¦ä»»åŠ¡
* æ›´é€‚åˆå¼‚æ­¥è°ƒåº¦

### 2. Compute åŒ– = æ›´å¯æ§çš„ overlap æ‹“æ‰‘

ä¾‹å¦‚ï¼š

* SSAO
* Bloom
* TAA resolve
* Post-process blur

è¿™äº›æœ¬è´¨æ˜¯ï¼š

* texture read-heavy
* ALU-heavy
* å¯¹ graphics fixed-function ä¾èµ–å¼±

Compute åŒ–åï¼š

* å¯ä»¥ç²¾å‡†å®‰æ’åœ¨ graphics pipeline çš„â€œç©ºæ´â€ä¸­æ‰§è¡Œ
* æ›´å®¹æ˜“å½¢æˆ datapath äº’è¡¥

---

## äº”ã€ä¸ºä»€ä¹ˆè¦â€œè·¨å¸§ asyncâ€

### 1. åŒä¸€å¸§å†… overlap çš„çª—å£éå¸¸çŸ­

Intraframe async computeï¼š

* ä¾èµ– tight synchronization
* å®¹æ˜“è¢«ä¸€ä¸ª barrier åƒæ‰å…¨éƒ¨æ”¶ç›Š

### 2. Interframe async çš„ä¼˜åŠ¿

* dependency è·ç¦»å¤§
* scheduling è‡ªç”±åº¦é«˜
* èƒ½é¿å¼€ WFIï¼ˆWait For Idleï¼‰

è¿™åœ¨ç°å®å¼•æ“ä¸­å¾€å¾€æ˜¯**æœ€ç¨³å¦¥ã€æœ€å®¹æ˜“è·å¾—æ”¶ç›Š**çš„ async æ¨¡å¼ã€‚

---

## å…­ã€ä¸ºä»€ä¹ˆå¿…é¡»â€œæ•´å¸§ / å¤šå¸§â€æµ‹é‡

Async Compute çš„æ”¶ç›Šå¾€å¾€è¡¨ç°ä¸ºï¼š

* GPU bubble å‡å°‘
* frame tail ç¼©çŸ­
* pipeline æ›´å¹³æ»‘

è€Œä¸æ˜¯ï¼š

* å•ä¸ª pass æ—¶é—´ä¸‹é™

å¦‚æœåªçœ‹å• passï¼š

* ä½ ç”šè‡³å¯èƒ½çœ‹åˆ°å®ƒâ€œå˜æ…¢äº†â€
  ä½†æ•´å¸§ï¼š
* frame time æ›´çŸ­
* variance æ›´ä½

---

## ä¸ƒã€ä¸ºä»€ä¹ˆé«˜ç«¯ GPUã€ä½åˆ†è¾¨ç‡æ›´å®¹æ˜“å—ç›Š

### 1. é«˜ç«¯ GPU

* æ›´å¤š SM
* æ›´å¤š execution unit
* æ›´å®¹æ˜“å‡ºç°â€œæœªè¢«ä½¿ç”¨çš„ç®—åŠ›å²›â€

Async Compute çš„ç©ºé—´æ›´å¤§ã€‚

### 2. ä½åˆ†è¾¨ç‡

* Pixel warp æ•°é‡å‡å°‘
* Raster / PS å‹åŠ›é™ä½
* SM æ›´å®¹æ˜“å‡ºç° idle slot

è¿™æ­£æ˜¯ async compute æœ€å®¹æ˜“â€œå¡«æ´â€çš„åœºæ™¯ã€‚

---

## å…«ã€é€æ¡è§£é‡Šâ€œä¸æ¨èâ€çš„åº•å±‚åŸå› 

### 1. åªçœ‹ SM Occupancy æ˜¯é”™è¯¯çš„

å› ä¸ºï¼š

* Occupancy â‰  Execution
* é«˜ occupancy ä¹Ÿå¯èƒ½ 90% æ—¶é—´åœ¨ç­‰ memory

### 2. é•¿ async workload é£é™©æé«˜

* ä¼šé¡¶ä½ dependency barrier
* å¯¼è‡´ sync queue ç­‰å¾…
* ç›´æ¥æ‹‰é•¿ frame tail

Async workload å¿…é¡»æ˜¯ï¼š

> **short, prefetch-like, latency-hiding**

### 3. è¯»å†™åŒä¸€èµ„æº = data hazard

* éšå¼ cache flush
* å¼ºåˆ¶ barrier
* L1/L2 invalidation

ç›´æ¥æŠ¹æ€ overlapã€‚

### 4. é«˜ L1/L2 / VRAM ä½¿ç”¨ä¸å¯ overlap

è¿™æ˜¯æœ€å¸¸è§çš„â€œè´Ÿæ”¶ç›Š async computeâ€æ¥æºï¼š

* cache thrashing
* DRAM oversubscription
* hit-rate ä¸‹é™ â†’ latency ä¸Šå‡

### 5. å¤š queue + è½¯ä»¶è°ƒåº¦ = serialization

åœ¨æœªå¯ç”¨ HAGS æ—¶ï¼š

* OS å±‚è°ƒåº¦
* driver ä¸²è¡Œæäº¤
* åè€Œæ¯”å• queue æ›´æ…¢

### 6. åŒ compute éƒ½è§¦å‘ WFI éå¸¸å±é™©

WFI ä¼šï¼š

* drain pipeline
* å¼ºåˆ¶åŒæ­¥
* æŠ¹æ‰æŒ‡ä»¤çº§ overlap

Descriptor heap é¢‘ç¹åˆ‡æ¢æ˜¯å¸¸è§è¯±å› ã€‚

### 7. DX12 queue priority å¹¶ä¸ç­‰äº warp priority

Queue priorityï¼š

* åªå½±å“ command fetch
* ä¸å½±å“ SM å†… warp scheduling

å› æ­¤å‡ ä¹æ— æ³•ç”¨äº fine-grained async tuningã€‚

### 8. ä¸æ¨è overlap RTCore workload

RT Coreï¼š

* ååå•å…ƒé«˜åº¦é›†ä¸­
* cache / memory pressure æé«˜
* ä¸å…¶ä»– RT workload å†²çªæå¤§

é‡å åªä¼šå¯¼è‡´ï¼š

* traversal å˜æ…¢
* BVH cache miss ä¸Šå‡

---

## æ€»ç»“ä¸€å¥è¯

**Async Compute ä¸æ˜¯â€œå¹¶è¡Œå¤šå¹²ç‚¹æ´»â€ï¼Œè€Œæ˜¯â€œç”¨æœ¬æ¥é—²ç€çš„ç¡¬ä»¶å•å…ƒå¹²æ´»â€ã€‚**

å› æ­¤ï¼š

* ä» unit throughput å‡ºå‘æ˜¯å¿…ç„¶
* èµ„æºäº’è¡¥æ˜¯å”¯ä¸€æˆåŠŸæ¡ä»¶
* memory / cache å†²çªæ˜¯æœ€å¤§æ•Œäºº
* Ampere ä¹‹å compute-over-compute æ‰çœŸæ­£å¯è¡Œ
* é”™è¯¯çš„ async æ¯”æ²¡æœ‰ async æ›´ç³Ÿ

å¦‚æœä½ æ„¿æ„ï¼Œä¸‹ä¸€æ­¥æˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ª**å…·ä½“ Nsight GPU Trace æ¡ˆä¾‹**ï¼Œé€é¡¹å¯¹ç…§è¿™äº›åŸåˆ™ï¼Œæ¼”ç¤ºâ€œä¸€ä¸ª async ä¼˜åŒ–æ˜¯å¦‚ä½•ä»çœ‹èµ·æ¥åˆç†åˆ°æœ€ç»ˆè¢«å¦å®šçš„â€ã€‚
