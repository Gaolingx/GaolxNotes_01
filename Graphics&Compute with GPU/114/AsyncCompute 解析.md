# AsyncCompute Ëß£Êûê

### üßë‚Äçüíª User

Âú®Ëøë2Âπ¥GDCËÇ≤Á¢ßÂêÑÂ∑•‰ΩúÂÆ§ÂàÜ‰∫´ÁöÑpptÊ∏≤ÊüìÁÆ°Á∫ø‰∏≠ÈÉΩÂá∫Áé∞‰∫ÜAsyncComputeÔºåÂü∫Êú¨‰∏äÂ∞±ÊòØÂú®Render XXXXÊ∏≤ÊüìÂêÑ‰∏™Ê≠•È™§‰πãÂ§ñÂèàÊúâ‰∏ÄÊù°Âπ∂Ë°åÁöÑÁß∞‰∏∫AysncComputeÁöÑÁ∫øÔºàCompute QueueÔºâÔºåÈáåËæπÁöÑÊìç‰ΩúÈÉΩÊòØCompute ShaderÂÆûÁé∞ÁöÑ„ÄÇ
Ëøô‰∏™Á•ûÁßòÁöÑAsyncComputeÁ∫øÁ©∂Á´üÊòØ‰ªÄ‰πàÔºü

---

### ü§ñ Assistant

Âú®Ëøë‰∏§Âπ¥ GDC ‰∏äËÇ≤Á¢ßÂêÑÂ∑•‰ΩúÂÆ§Â±ïÁ§∫ÁöÑÊ∏≤ÊüìÁÆ°Á∫ø PPT ‰∏≠ÔºåÈÇ£Êù°Ë¢´ÂçïÁã¨ÁîªÂá∫Êù•„ÄÅ‰∏é‰º†Áªü **Graphics Queue** Âπ∂Ë°åÁöÑ **Async ComputeÔºàCompute QueueÔºâ**ÔºåÊú¨Ë¥®‰∏äÂπ∂‰∏çÁ•ûÁßòÔºåÂÆÉÊòØ**Áé∞‰ª£ GPU Á°¨‰ª∂Âπ∂Ë°åÊâßË°åËÉΩÂäõÂú® API Â±ÇÁöÑÊòæÂºèÊö¥Èú≤‰∏éÂ∑•Á®ãÂåñÂà©Áî®**„ÄÇ

ÂèØ‰ª•‰ªé **‚ÄúÂÆÉ‰∏çÊòØ‰ªÄÈ∫º‚Äù** Âíå **‚ÄúÂÆÉÂà∞Â∫ïÊòØ‰ªÄ‰πà‚Äù** ‰∏§‰∏™Â±ÇÈù¢Êù•ÁêÜËß£„ÄÇ

---

## ‰∏Ä„ÄÅAsync Compute ‰∏çÊòØ‚ÄúÂè¶‰∏ÄÂº† GPU‚ÄùÔºå‰πü‰∏çÊòØ‚ÄúÂÅ∑ÂÅ∑Êõ¥Âø´ÁöÑ Compute Shader‚Äù

ËøôÊòØÂæàÂ§ö‰∫∫Á¨¨‰∏ÄÊ¨°ÁúãÂà∞ÈÇ£Êù°Á∫øÊó∂ÁöÑÁõ¥ËßâËØØËß£„ÄÇ

Async Compute **Âπ∂‰∏çÊòØ**Ôºö

1. **È¢ùÂ§ñÁöÑ‰∏ÄÂ•óÁÆóÂäõ**

   * ÂÆÉ‰∏çÊèê‰æõÊñ∞ÁöÑ ALU„ÄÅTMU ÊàñÂ∏¶ÂÆΩ
   * ÊâÄÊúâÁÆóÂäõ‰ªçÁÑ∂Êù•Ëá™Âêå‰∏ÄÂùó GPU

2. **Compute Shader ÁöÑÁâπÊÆäÁâàÊú¨**

   * Shader ‰ª£Á†ÅÂ±ÇÈù¢ÂÆåÂÖ®Áõ∏Âêå
   * Âå∫Âà´‰∏çÂú® HLSL/GLSLÔºåËÄåÂú® **Êèê‰∫§Âà∞Âì™‰∏™Á°¨‰ª∂ÈòüÂàó**

3. **Ëá™Âä®Âä†ÈÄü**

   * Â¶ÇÊûúËµÑÊ∫ê„ÄÅÂêåÊ≠•„ÄÅÂ∏¶ÂÆΩÊ≤°ÊúâËÆæËÆ°Â•Ω
   * Async Compute ÂèçËÄåÂèØËÉΩ **Êõ¥ÊÖ¢**

---

## ‰∫å„ÄÅAsync Compute ÁöÑÊú¨Ë¥®ÔºöÁã¨Á´ãÁöÑÁ°¨‰ª∂ÊâßË°åÈòüÂàóÔºàHardware QueueÔºâ

### 1. Áé∞‰ª£ GPU ÊòØÂ§öÈòüÂàóËÆæÂ§á

‰ª• GCN / RDNA / Turing+ ‰∏∫‰ª£Ë°®ÁöÑ GPUÔºåÈÉΩÂÖ∑Â§áÔºö

* **Graphics Queue**

  * Vertex / Pixel / Geometry
* **Compute Queue**

  * Compute ShaderÔºà‰∏çËµ∞ raster pipelineÔºâ
* ÔºàÊúâÊó∂ËøòÊúâ Copy / DMA QueueÔºâ

Ëøô‰∫õÈòüÂàóÂú®Á°¨‰ª∂‰∏äÊòØ**ÁúüÂÆûÂ≠òÂú®„ÄÅÂèØÂπ∂Ë°åË∞ÉÂ∫¶ÁöÑ**„ÄÇ

> Async Compute = **ÂÖÅËÆ∏ Compute Queue ‰∏é Graphics Queue ÂêåÊó∂Ê¥ªË∑É**

---

### 2. API Â±ÇÁöÑ‰ΩìÁé∞

Âú®Áé∞‰ª£ API ‰∏≠ËøôÊòØÊòæÂºèÁöÑÔºö

* **DX12**

  * `D3D12_COMMAND_LIST_TYPE_DIRECT`
  * `D3D12_COMMAND_LIST_TYPE_COMPUTE`
* **Vulkan**

  * Graphics Queue
  * Compute-only Queue

ÂºïÊìéÊää‰ªªÂä°ÂàÜÂà´Êèê‰∫§Âà∞‰∏çÂêåÈòüÂàóÔºåÁî± GPU ÁöÑ **Á°¨‰ª∂Ë∞ÉÂ∫¶Âô®ÔºàSchedulerÔºâ** ÂÜ≥ÂÆöÂ¶Ç‰Ωï‰∫§ÈîôÊâßË°å„ÄÇ

---

## ‰∏â„ÄÅ‰∏∫‰ªÄ‰πà Async Compute Âú®Ê∏≤ÊüìÁÆ°Á∫øÈáå‚ÄúÁúãËµ∑Êù•ÂÉèÂè¶‰∏ÄÊù°Êó∂Èó¥Á∫ø‚Äù

### 1. GPU ‰∏çÊòØ‰∏•Ê†º‰∏≤Ë°åÁöÑ

Âú®‰º†Áªü‚ÄúÂçïÈòüÂàó‚ÄùÂøÉÊô∫Ê®°Âûã‰∏≠Ôºö

```
Shadow ‚Üí GBuffer ‚Üí Lighting ‚Üí PostProcess
```

‰ΩÜÁúüÂÆû GPU ÂÜÖÈÉ®ÊòØÔºö

* ‰∏çÂêåÈò∂ÊÆµ‰ΩøÁî® **ÂÆåÂÖ®‰∏çÂêåÁöÑÊâßË°åÂçïÂÖÉ**
* Â§ßÈáè pipeline bubbles Êú¨Êù•Â∞±Â≠òÂú®

‰æãÂ¶ÇÔºö

| Èò∂ÊÆµ         | ‰∏ªË¶ÅÁì∂È¢à                |
| ---------- | ------------------- |
| Shadow Map | Vertex / Geometry   |
| SSAO       | Texture fetch + ALU |
| TAA        | ALU + LDS           |
| Lighting   | ALU / Tensor / LDS  |

**Ëøô‰∫õËµÑÊ∫êÂπ∂‰∏çÂÆåÂÖ®ÈáçÂè†**„ÄÇ

---

### 2. Async Compute ÁöÑÊ†∏ÂøÉÂä®Êú∫

> **Áî® Compute Work Â°´ÂÖÖ Graphics Pipeline ÁöÑ‚ÄúÁ©∫Ê¥û‚Äù**

ÂÖ∏ÂûãÂú∫ÊôØÔºö

* Graphics Queue Âú®Ôºö

  * Á≠âÂæÖ memory
  * Á≠âÂæÖ raster
  * vertex-heavy„ÄÅpixel-light
* Compute Queue ÂèØ‰ª•ÂêåÊó∂Ôºö

  * Ë∑ë SSAO
  * Ë∑ë SSR
  * Ë∑ë TAA
  * Ë∑ë Culling / LOD / Skinning

‰∫éÊòØ PPT ‰∏äÂ∞±ÁîªÊàê‰∫ÜÔºö

```
Graphics: |---- Shadow ----|---- GBuffer ----|---- Lighting ----|
Compute :       |---- SSAO ----|    |-- TAA --|
```

ËøôÂπ∂‰∏çÊòØ‚ÄúÂºïÊìéÊÉ≥Ë±°Âá∫Êù•ÁöÑ‚ÄùÔºåËÄåÊòØ**ÁúüÂÆûÁ°¨‰ª∂Âπ∂Âèë**„ÄÇ

---

## Âõõ„ÄÅ‰∏∫‰ªÄ‰πàËÇ≤Á¢ßËøô‰∏§Âπ¥ÁâπÂà´Âº∫Ë∞É Async ComputeÔºü

Âõ†‰∏∫‰ªñ‰ª¨ÁöÑÈ°πÁõÆÊª°Ë∂≥‰∫Ü **Async Compute ÊàêÁ´ãÁöÑ‰∏â‰∏™ÂøÖË¶ÅÊù°‰ª∂**Ôºö

### 1. ÊúâÂ§ßÈáè Compute-heavy ÁöÑÂ±èÂπïÁ©∫Èó¥ / ÂêéÂ§ÑÁêÜÁÆóÊ≥ï

‰æãÂ¶ÇÔºö

* SSAO / GTAO
* SSR
* TAA / TSR
* Volumetric Fog
* GPU Culling
* Clustered / Tiled Lighting

Ëøô‰∫õÊú¨Êù•Â∞±**‰∏çÈúÄË¶Å raster pipeline**„ÄÇ

---

### 2. Ê∏≤ÊüìÈò∂ÊÆµÂ≠òÂú®ÊòéÊòæÁöÑËµÑÊ∫ê‰∫íË°•

‰Ω†ÂâçÈù¢ÊèêÂà∞ÁöÑ‰æãÂ≠êÈùûÂ∏∏ÂÖ∏ÂûãÔºö

> Shadow MapÔºàVertex-heavyÔºâ
> SSAOÔºàDepth sampling + ALUÔºâ

* Shadow MapÔºö

  * VS / GS ÂéãÂäõÂ§ß
  * PS ÂæàËΩª
* SSAOÔºö

  * Âá†‰πé‰∏çÁ¢∞ VS
  * ÂêÉ ALU + Cache

**ËµÑÊ∫êÈîôÂ≥∞ = Async Compute ËÉΩÁúüÊ≠£Ë∑ëÊª° GPU**

---

### 3. ÂºïÊìéÂ∑≤ÁªèÈ´òÂ∫¶ Pipeline Âåñ

Async Compute ‰∏çÊòØ‚ÄúÂä†‰∏™ÈòüÂàóÂ∞±Ë°å‚ÄùÔºåÂâçÊèêÊòØÔºö

* Pass ‰πãÈó¥‰æùËµñÊ∏ÖÊô∞
* ËµÑÊ∫êÁîüÂëΩÂë®ÊúüÊòéÁ°Æ
* Barrier / Fence ÁÆ°ÁêÜÊàêÁÜü

ËøôÊ≠£ÊòØ Ubisoft ËøôÁ±ª **Â§öÂπ¥Ëá™Á†îÂºïÊìé + Ë∑®‰∏ñ‰ª£ÁßØÁ¥Ø** ÁöÑ‰ºòÂäø„ÄÇ

---

## ‰∫î„ÄÅAsync Compute ÁúüÊ≠£ÈöæÁöÑÂú∞ÊñπÔºà‰πüÊòØ PPT ‰∏ç‰ºöÁªÜËÆ≤ÁöÑÔºâ

### 1. ÂêåÊ≠•‰∏éËµÑÊ∫ê Hazard

* Compute ÂÜôÁöÑ UAV
* Graphics ËØªÁöÑ SRV

ÈúÄË¶ÅÔºö

* UAV Barrier
* Queue-to-Queue Fence

ÂÅöÈîô‰∫Ü‰∏çÊòØËä±Â±èÔºåËÄåÊòØ **ÈöêÊÄßÊÄßËÉΩÈÄÄÂåñ**„ÄÇ

---

### 2. Â∏¶ÂÆΩ‰∏é Cache ‰∫âÁî®

Async Compute **‰∏ç‰øùËØÅ**Ôºö

* Â∏¶ÂÆΩÁøªÂÄç
* Cache ‰∏çÊäñ

Âú®‰∏Ä‰∫õÂú∫ÊôØ‰∏ãÔºö

* Compute ‰ºöÊää Graphics ÁöÑ L2 / L1 ÂÜ≤Êéâ
* ÂØºËá¥ÊÄªÂ∏ßÊó∂Èó¥‰∏äÂçá

Âõ†Ê≠§ÈúÄË¶ÅÔºö

* Pass Á≤íÂ∫¶ÊéßÂà∂
* ÂêàÁêÜÂàáÂàÜ Dispatch

---

### 3. ‰∏çÂêå GPU Êû∂ÊûÑÂ∑ÆÂºÇÂ∑®Â§ß

* GCNÔºöAsync Compute ÈùûÂ∏∏Âº∫
* RDNAÔºöÈúÄË¶ÅÊõ¥Ë∞®ÊÖé
* NVIDIAÔºöÂπ∂ÂèëËÉΩÂäõÂ≠òÂú®Ôºå‰ΩÜË∞ÉÂ∫¶Á≠ñÁï•‰∏çÂêå

Ëøô‰πüÊòØ‰∏∫‰ªÄ‰πàÂæàÂ§öÂºïÊìéÔºö

* Êúâ Async Compute Ë∑ØÂæÑ
* ‰ΩÜ **Êåâ Vendor / GPU Tier ÂºÄÂÖ≥**

---

## ÂÖ≠„ÄÅ‰∏ÄÂè•ËØùÊÄªÁªì

> **Async Compute Âπ∂‰∏çÊòØ‚ÄúÈ¢ùÂ§ñÁÆóÂäõ‚ÄùÔºåËÄåÊòØËÆ© GPU ÂéüÊú¨Ë¢´Êµ™Ë¥πÁöÑÂπ∂Ë°åËÉΩÂäõÁúüÊ≠£Ë¢´Áî®Ëµ∑Êù•„ÄÇ**

Âú®ËÇ≤Á¢ßÁöÑÊ∏≤ÊüìÁÆ°Á∫øÂõæÈáåÔºåÈÇ£Êù°‚ÄúÁ•ûÁßòÁöÑ AsyncCompute Á∫ø‚Äù‰ª£Ë°®ÁöÑÊòØÔºö

* ‰∏Ä‰∏™Áã¨Á´ãÁöÑÁ°¨‰ª∂ Compute ÈòüÂàó
* Ë¢´Á≤æÂøÉÊåëÈÄâ„ÄÅ‰∏é Graphics ËµÑÊ∫ê‰∫íË°•ÁöÑ‰ªªÂä°
* ÈÄöËøá‰∏•Ê†ºÂêåÊ≠•‰∏éË∞ÉÂ∫¶ÔºåÂÆûÁé∞ÁúüÂÆûÁöÑ GPU Âπ∂Ë°å

Â¶ÇÊûú‰Ω†ÊÑøÊÑèÔºå‰∏ã‰∏ÄÊ≠•Êàë‰ª¨ÂèØ‰ª•Áõ¥Êé•Áî®‰∏Ä‰∏™ **Shadow Map + SSAO ÁöÑÁúüÂÆû GPU Êó∂Èó¥Á∫ø**ÔºåÈÄêÂë®ÊúüÊãÜËß£‰∏∫‰ªÄ‰πàÂÆÉËÉΩ overlapÔºå‰ª•ÂèäÂú®Âì™‰∫õÊÉÖÂÜµ‰∏ãÂÆÉ‰∏ÄÂÆö‰∏çËÉΩ„ÄÇ


---

### üßë‚Äçüíª User

‰æãÂ¶ÇÔºåÂèØ‰ª•Âú®Ê∏≤ÊüìshadowmapÁöÑÊó∂ÂÄôÁî®csÊù•ÂÅöSSAOÔºåÂõ†‰∏∫smÂíåssaoÂÖ∂ÂÆûÂØπGPUËµÑÊ∫êÁöÑË¶ÅÊ±ÇÊòØÂæà‰∏çÂêåÁöÑÔºåÂõ†Ê≠§ÂêåÊó∂ÂÅöÂÖ∂ÂÆûÊõ¥ÂÖÖÂàÜÁöÑÂà©Áî®‰∫ÜGPUÔºåÈÇ£Á°ÆÂÆûÔºåsmÈáçÁÇπÊòØvertexÂ§ÑÁêÜÔºåssao‰∏ªË¶ÅÊòØÂØπdepth textureÈááÊ†∑Ôºå‰∏§ËÄÖË¶ÅÊ±ÇÈùûÂ∏∏‰∫íË°•ÔºåÂêåÊó∂ËÇØÂÆöËÉΩÊèêÂçáÊïàÁéáÔºåÂÖ∑‰ΩìÁªÜËäÇËÉΩ‰∏çËÉΩÊ∑±ÂÖ•ÂàÜÊûê‰∏Ä‰∏ãÔºüËøôÊòØ‰∏Ä‰∏™ÂæàÂÖ∏ÂûãÁöÑAsync Compute and OverlapÈóÆÈ¢ò

---

### ü§ñ Assistant

ËøôÊòØ‰∏Ä‰∏™**ÈùûÂ∏∏Ê†áÂáÜ„ÄÅ‰πüÈùûÂ∏∏‚ÄúÊïôÁßë‰π¶Á∫ß‚ÄùÁöÑ Async Compute overlap Âú∫ÊôØ**„ÄÇ‰Ω†Ëøô‰∏™Áõ¥ËßâÊú¨Ë∫´ÊòØÂØπÁöÑÔºå‰ΩÜË¶ÅÊääÂÆÉ‰ªé‚ÄúÊ¶ÇÂøµÊ≠£Á°Æ‚ÄùÊé®ËøõÂà∞‚ÄúÂ∑•Á®ã‰∏äÁúüÁöÑÂø´‚ÄùÔºåÂøÖÈ°ªÊää **GPU ÁöÑÊâßË°åËµÑÊ∫ê„ÄÅÁì∂È¢à‰ΩçÁΩÆ„ÄÅ‰ª•ÂèäÁúüÂÆûÊó∂Èó¥Á∫ø**ÊãÜÂà∞Ë∂≥Â§üÁªÜ„ÄÇ

‰∏ãÈù¢ÊàëÊåâ **Á°¨‰ª∂ËµÑÊ∫ê ‚Üí ‰∏§‰∏™ pass ÁöÑÂæÆËßÇÁâπÂæÅ ‚Üí ‰∏∫‰ªÄ‰πàËÉΩ overlap ‚Üí ‰ªÄ‰πàÊó∂ÂÄôÂèçËÄå‰∏çË°å ‚Üí Â∑•Á®ãÂÆûÁé∞ÁªÜËäÇ** Ëøô‰∫î‰∏™Â±ÇÊ¨°Êù•ÂàÜÊûê„ÄÇ

---

## ‰∏Ä„ÄÅÂÖàÊòéÁ°Æ‰∏Ä‰∏™ÂÖ≥ÈîÆÂâçÊèêÔºöGPU Âπ∂Ë°å‰∏çÊòØ‚Äú‰∏§‰∏™ kernel ÂêåÊó∂Ë∑ë‚Äù

Async Compute ÊàêÁ´ãÁöÑ**ÁúüÊ≠£Êù°‰ª∂**ÊòØÔºö

> **‰∏§‰∏™‰ªªÂä°ÁöÑÁì∂È¢àËµÑÊ∫ê‰∏çÂêåÔºå‰∏îË∞ÉÂ∫¶Âô®ËÉΩÂú®Âêå‰∏ÄÊó∂Èó¥ÁâáÂÜÖÊääÂÆÉ‰ª¨Êò†Â∞ÑÂà∞‰∏çÂêåÊâßË°åÂçïÂÖÉ**

Âê¶ÂàôÂ∞±Âè™ÊòØÊó∂Èó¥ÁâáËΩÆËΩ¨ÔºåÁúãËµ∑Êù•Âπ∂Ë°åÔºåÂÆûÈôÖ‰∏ä‰∏≤Ë°å„ÄÇ

---

## ‰∫å„ÄÅShadow Map Pass ÁöÑÁúüÂÆûÁ°¨‰ª∂ÁîªÂÉèÔºàGraphics QueueÔºâ

‰ª•Â∏∏ËßÅÁöÑ Directional Shadow Map ‰∏∫‰æãÔºö

### 1. Â∑•‰ΩúË¥üËΩΩÂàÜËß£

* **Vertex Shader**

  * Â§ßÈáè instance
  * World ‚Üí Light View Projection
* **Primitive Assembly / Raster**

  * Ê∑±Â∫¶-only
* **Pixel Shader**

  * ÊûÅÁÆÄÔºàÁîöËá≥Á©∫Ôºâ

### 2. Á°¨‰ª∂Áì∂È¢àÂú®Âì™ÈáåÔºü

| Á°¨‰ª∂ÂçïÂÖÉ                 | Âà©Áî®Áéá    |
| -------------------- | ------ |
| VS / Attribute Fetch | **È´ò**  |
| Raster / Setup       | ‰∏≠      |
| PS ALU               | **ÊûÅ‰Ωé** |
| Texture Units        | Âá†‰πé‰∏çÁî®   |
| LDS                  | ‰∏çÁî®     |
| L2 / DRAM Â∏¶ÂÆΩ         | ‰ΩéÔΩû‰∏≠    |

> **Shadow Map ÊòØ‰∏Ä‰∏™ÂÖ∏ÂûãÁöÑ ‚ÄúÂâçÁ´ØÔºàVertexÔºâÂèóÈôê‚Äù pass**

Âú®Ëøô‰∏ÄÈò∂ÊÆµÔºö

* Â§ßÈáè SM / CU ‰∏≠ÁöÑ **pixel pipe ÊòØÁ©∫ÁöÑ**
* ALU„ÄÅTexture pipeline ÊòéÊòæÈó≤ÁΩÆ

---

## ‰∏â„ÄÅSSAOÔºàCompute ShaderÔºâÁöÑÁúüÂÆûÁ°¨‰ª∂ÁîªÂÉèÔºàCompute QueueÔºâ

‰ª• GTAO / HBAO Á±ª SSAO ‰∏∫‰æãÔºö

### 1. Â∑•‰ΩúË¥üËΩΩÂàÜËß£

* ËæìÂÖ•ÔºöDepth TextureÔºàÂè™ËØªÔºâ
* Ê†∏ÂøÉÊìç‰ΩúÔºö

  * Â§öÊ¨° depth sampling
  * ÈöèÊú∫ÊóãËΩ¨ kernel
  * ALU-heavy accumulation

### 2. Á°¨‰ª∂Áì∂È¢àÂú®Âì™ÈáåÔºü

| Á°¨‰ª∂ÂçïÂÖÉ                | Âà©Áî®Áéá   |
| ------------------- | ----- |
| ALU                 | **È´ò** |
| Texture Units       | **È´ò** |
| LDS / Shared Memory | ‰∏≠     |
| VS / Raster         | ‰∏ç‰ΩøÁî®   |
| Primitive Setup     | ‰∏ç‰ΩøÁî®   |

> **SSAO ÊòØÂÖ∏ÂûãÁöÑ ‚ÄúÂêéÁ´ØÔºàALU + TextureÔºâÂèóÈôê‚Äù compute workload**

---

## Âõõ„ÄÅ‰∏∫‰ªÄ‰πàËøô‰∏§‰∏™ pass ËÉΩ‚ÄúÁúü¬∑Âπ∂Ë°å‚ÄùÔºü

### 1. ËµÑÊ∫ê‰∫íË°•ÔºàËøôÊòØÊúÄÂÖ≥ÈîÆÁöÑ‰∏ÄÁÇπÔºâ

| ËµÑÊ∫ê            | Shadow Map | SSAO   |
| ------------- | ---------- | ------ |
| VS Front-End  | **ÂêÉÊª°**     | ‰∏çÁî®     |
| Raster        | ‰ΩøÁî®         | ‰∏çÁî®     |
| PS ALU        | Á©∫Èó≤         | **ÂêÉÊª°** |
| Texture Units | Á©∫Èó≤         | **ÂêÉÊª°** |
| LDS           | Á©∫Èó≤         | ‰ΩøÁî®     |
| Register File | ‰∏≠          | È´ò      |

> **‰∏§ËÄÖÁ´û‰∫âÁöÑÂè™ÊúâÔºö**
>
> * L2 Cache
> * DRAM Â∏¶ÂÆΩÔºàËÄå‰∏î Shadow Map Ëøò‰∏çÁÆóÈáçÔºâ

Âõ†Ê≠§Ë∞ÉÂ∫¶Âô®ÂèØ‰ª•ÂÅöÂà∞Ôºö

* ‰∏Ä‰∏™ CU Âú®Ë∑ë vertex wave
* ÂêåÊó∂Âè¶‰∏Ä‰∫õ CU Âú®Ë∑ë compute wave
* ÁîöËá≥ **Âêå‰∏Ä‰∏™ CU ÂÜÖ warp / wave ‰∫§ÈîôÊâßË°å**

---

### 2. Á°¨‰ª∂Ë∞ÉÂ∫¶Â±ÇÈù¢ÁöÑÂÆûÈôÖË°å‰∏∫

Âú®ÊîØÊåÅ Async Compute ÁöÑ GPU ‰∏äÔºàGCN / RDNA / Turing+ÔºâÔºö

* Graphics Queue ÂèëÂ∞ÑÔºö

  * VS wavefront
* Compute Queue ÂèëÂ∞ÑÔºö

  * CS wavefront

Á°¨‰ª∂Ë∞ÉÂ∫¶Âô®ÂÅöÁöÑ‰∫ãÊÉÖÊòØÔºö

* **ÊåâËµÑÊ∫ê‰æùËµñËÄåÈùûÈòüÂàóÈ°∫Â∫èË∞ÉÂ∫¶**
* Âú®Âêå‰∏ÄÊó∂Èó¥ slice ÂÜÖÔºö

  * Ëã• pixel pipe idle ‚Üí Ê¥æÂèë compute wave
  * Ëã• ALU ÊúâÁ©∫ ‚Üí Ê¥æÂèë SSAO wave

ËøôÂ∞±ÊòØ PPT ‰∏äÈÇ£Êù°‚ÄúÂπ∂Ë°åÁ∫ø‚ÄùÁöÑÁúüÂÆûÂê´‰πâ„ÄÇ

---

## ‰∫î„ÄÅÁî®‚ÄúÊó∂Èó¥Á∫ø‚ÄùÊèèËø∞‰∏ÄÊ¨°ÁúüÂÆû overlap

ÂÅáËÆæÔºö

* Shadow Map PassÔºö4 msÔºàVS-boundÔºâ
* SSAO ComputeÔºö2 msÔºàALU-boundÔºâ

**Ê≤°Êúâ Async ComputeÔºö**

```
0ms ‚îÄ‚îÄ Shadow Map ‚îÄ‚îÄ 4ms ‚îÄ‚îÄ SSAO ‚îÄ‚îÄ 6ms
```

**Êúâ Async ComputeÔºàÁêÜÊÉ≥ÊÉÖÂÜµÔºâÔºö**

```
0ms ‚îÄ‚îÄ Shadow Map ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 4ms
       ‚îú‚îÄ‚îÄ SSAO (Compute) ‚îÄ‚îÄ‚î§
0ms ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2ms
```

ÊúÄÁªàÔºö

* Â∏ßÊó∂Èó¥Ôºö4 msÔºà‰∏çÊòØ 6 msÔºâ
* SSAO ‚ÄúÂá†‰πéÂÖçË¥π‚Äù

---

## ÂÖ≠„ÄÅ‰ªÄ‰πàÊó∂ÂÄôËøô‰∏™ overlap ‰ºöÂ§±Ë¥•Ôºü

ËøôÊòØÂ∑•Á®ã‰∏≠ÊúÄÂÆπÊòìË∏©ÂùëÁöÑÂú∞Êñπ„ÄÇ

### 1. Â∏¶ÂÆΩÂºÄÂßãÊàê‰∏∫Áì∂È¢à

Â¶ÇÊûúÔºö

* SSAO sampling ÂçäÂæÑÂ§ß
* Depth ÊòØ full-res
* Shadow Map ÊòØÈ´òÂàÜËæ®Áéá cascaded SM

ÈÇ£‰πàÔºö

* ‰∏§ËÄÖÂêåÊó∂ÂÜ≤Âáª L2 / DRAM
* ÂØºËá¥Ôºö

  * Shadow Map VS stall
  * SSAO texture miss

ÁªìÊûúÔºö**‰∏§‰∏™ÈÉΩÊÖ¢**

---

### 2. Barrier ÊîæÈîô‰ΩçÁΩÆ

Â∏∏ËßÅÈîôËØØÔºö

* SSAO ÈúÄË¶Å depth pre-pass
* ‰ΩÜ depth Â∞öÊú™ÂÆåÊàê ‚Üí Âº∫Âà∂ÂÖ®Â±Ä sync

ÁªìÊûúÔºö

```
Graphics: Shadow Map ‚îÄ‚îÄ Barrier ‚îÄ‚îÄ SSAO
Compute :        ÔºàÁ©∫Á≠âÔºâ
```

Async Compute Áõ¥Êé•ÈÄÄÂåñÊàê‰∏≤Ë°å„ÄÇ

---

### 3. Dispatch Á≤íÂ∫¶ËøáÂ§ß

* SSAO ‰∏ÄÊ¨° dispatch Ë¶ÜÁõñÂÖ®Â±è
* wave Êï∞ÈáèÂ§™Â§ö
* Compute Queue Êä¢Âç†ËøáÂº∫

ÁªìÊûúÔºö

* Graphics Queue Ë¢´ starvation
* ÂèçËÄåÂª∂Èïø shadow map Êó∂Èó¥

---

## ‰∏É„ÄÅËÇ≤Á¢ß / ‰∏ÄÁ∫øÂºïÊìéÁöÑÂ∑•Á®ãÂÆûË∑µË¶ÅÁÇπ

‰Ω†Âú® PPT ÈáåÁúãÂà∞ÁöÑ‚ÄúÊºÇ‰∫Æ overlap‚ÄùÔºåËÉåÂêéÈÄöÂ∏∏ÊúâËøô‰∫õÁ≠ñÁï•Ôºö

### 1. ÂàáÂàÜ SSAO

* Tile-based SSAO
* ÂàÜÂ§öÊ¨° dispatch
* ‰∏≠Èó¥ÂèØË¢´Êä¢Âç†

### 2. ÊòæÂºèÈôêÂà∂ Compute Âç†ÊØî

* ÈôêÂà∂ wave Êï∞
* ÊéßÂà∂ LDS / register ‰ΩøÁî®
* ÈÅøÂÖçÂéãÊ≠ª graphics

### 3. ‰∏•Ê†ºÁöÑ Queue Fence ËÆæËÆ°

* SSAO **Âè™ËØª depth**
* ‰∏ç‰æùËµñ shadow map ËæìÂá∫
* barrier Á≤æÁ°ÆÂà∞ subresource

---

## ÂÖ´„ÄÅ‰∏Ä‰∏™ÊÄªÁªìÊÄßÁöÑÂà§Êñ≠Ê†áÂáÜ

‰Ω†ÂèØ‰ª•Áî®ËøôÂè•ËØùÂø´ÈÄüÂà§Êñ≠‰∏Ä‰∏™ Async Compute overlap ÊòØÂê¶‚ÄúÂÄºÂæóÂÅö‚ÄùÔºö

> **Â¶ÇÊûú Graphics pass Ê≠£Âú®ÂêÉ VS / RasterÔºåËÄå Compute pass Ê≠£Âú®ÂêÉ ALU / TextureÔºå‰∏î‰∏§ËÄÖÂá†‰πéÊ≤°ÊúâÂÜôÂêéËØª‰æùËµñÔºåÈÇ£‰πàËøôÊòØ‰∏Ä‰∏™‰∏ÄÁ≠âÂÖ¨Ê∞ëÁ∫ßÁöÑ Async Compute Âú∫ÊôØ„ÄÇ**

Shadow Map + SSAOÔºåÊ≠£ÊòØËøô‰∏™Ê†áÂáÜÊ°à‰æã„ÄÇ

---

Â¶ÇÊûú‰Ω†ÊÑøÊÑèÔºå‰∏ã‰∏ÄÊ≠•ÊàëÂèØ‰ª•Ôºö

* Áî® **AMD GPU ÁöÑ wavefront / CU Ë∞ÉÂ∫¶Ê®°Âûã** ÊãÜ‰∏ÄÊ¨°Êõ¥Â∫ïÂ±ÇÁöÑ overlap
* ÊàñÂØπÊØî **NVIDIA ‰∏ä‰∏∫‰ªÄ‰πàËøô‰∏™ overlap Êî∂ÁõäÊõ¥‰∏çÁ®≥ÂÆö**
* ÊàñÁõ¥Êé•Áªô‰Ω†‰∏Ä‰∏™ **DX12/Vulkan Á∫ßÂà´ÁöÑÂêåÊ≠•‰∏éÈòüÂàóÊèê‰∫§Á§∫ÊÑè**


---

### üßë‚Äçüíª User

About Async Compute and OverlapÔºåa classic mistake is to focus only on SM occupancy (unused warp slots) to identify potential async compute workloads. The GPU is a complex beast and other metrics such as top unit throughputs (SOL) play an equal if not more important role than SM occupancy alone.

Thus, in addition to SM occupancy, you should also consider unit throughputs, register file occupancy, group shared memory, and different datapaths. After the ideal pair is identified, the compute workload is moved to the async queue. It is synchronized with the sync/main queue using fences to ensure the correct execution order.

Question:
1. how to to identify potential async compute workloads?
2. how to synchronize with the sync/main queue using fences with dx12?

---

### ü§ñ Assistant

Your premise is correct and reflects how mature engines actually reason about Async Compute: **SM occupancy is neither necessary nor sufficient**. What matters is *which parts of the GPU are saturated* and *which are idle* over time.

I will answer the two questions separately, at an engineering-practical level rather than a conceptual one.

---

## 1. How to identify potential Async Compute workloads

Think of this as a **resource orthogonality and dependency analysis problem**, not a shader classification problem.

### 1.1 Start from GPU bottleneck classification, not ‚Äúcompute vs graphics‚Äù

For each candidate pass, you want to answer:

> *What hardware units are the limiting factor for this pass at peak load?*

Typical bottleneck classes:

| Bottleneck class           | Dominant limiters                        |
| -------------------------- | ---------------------------------------- |
| Front-end / geometry bound | IA, VS, attribute fetch, primitive setup |
| Raster bound               | Rasterizer, depth/stencil                |
| Pixel ALU bound            | FP/INT ALUs                              |
| Texture bound              | TEX, L1/L2 hit rate                      |
| Memory bound               | DRAM BW, L2                              |
| LDS / shared memory bound  | LDS bandwidth or capacity                |
| Register bound             | Register file pressure ‚Üí wave throttling |

You obtain this from **vendor profilers**, not from occupancy numbers:

* Nsight Graphics / Nsight Compute
* Radeon GPU Profiler (RGP)
* PIX timing captures

If a workload‚Äôs *top stall reason* overlaps heavily with another pass, it is **not** a good Async Compute candidate.

---

### 1.2 Look for *complementary* throughput saturation

A good Async Compute pair looks like this:

| Resource       | Graphics pass | Compute pass |
| -------------- | ------------- | ------------ |
| VS / primitive | High          | None         |
| Raster         | High          | None         |
| Pixel ALU      | Low           | High         |
| Texture        | Low‚Äìmedium    | High         |
| LDS            | Low           | Medium       |
| Registers      | Moderate      | High         |

Classic examples that survive real profiling:

* Shadow map rendering + SSAO / GTAO
* Depth prepass + light list construction
* G-buffer raster + clustered lighting build
* Skinning / culling CS + early graphics passes

Bad examples (despite ‚Äúfree SM slots‚Äù):

* Two memory-bound compute passes
* Compute competing with heavy pixel shading
* Full-res postprocess overlapping bandwidth-heavy passes

---

### 1.3 Explicitly evaluate **shared bottlenecks**

Before moving anything to async, you must verify:

1. **DRAM bandwidth headroom**

   * Async Compute cannot create bandwidth
   * If either pass is BW-bound, overlap hurts

2. **L2 cache contention**

   * Random depth sampling + large vertex streams = cache thrash

3. **Register file pressure**

   * High register usage can reduce active waves and starve graphics

4. **LDS capacity**

   * Large group shared memory allocations reduce concurrent waves

This is why ‚Äúunused warp slots‚Äù alone is misleading:
they often exist *because* another unit is saturated.

---

### 1.4 Dependency analysis: the hidden deal-breaker

A workload is **disqualified** for Async Compute if it has:

* Write-after-read or write-after-write dependencies with the graphics pass
* Frequent UAV writes consumed immediately by graphics
* Frame-critical latency sensitivity (e.g., must finish before visibility)

Ideal async candidates:

* Read-only inputs (SRV)
* Outputs consumed much later in the frame
* Tolerant to partial or tiled execution

---

### 1.5 Practical identification workflow

In production engines, this usually looks like:

1. Capture a GPU frame with everything on the main queue.
2. Identify passes where:

   * Graphics queue shows long idle gaps in certain units.
3. Find compute passes whose stall reasons match those gaps.
4. Temporarily move them to async and re-profile.
5. Keep them async **only if total frame time decreases**.

Async Compute is validated empirically, not theoretically.

---

## 2. How to synchronize Async Compute with the main queue in DX12

DX12 synchronization is explicit and low-level by design. The core tools are:

* **ID3D12Fence**
* **Command queue `Signal` / `Wait`**
* **Resource barriers (for hazards, not execution order)**

### 2.1 The fundamental rule

> **Execution order between queues is undefined unless you enforce it with fences.**

Resource barriers do **not** synchronize queues.

---

### 2.2 Typical Async Compute synchronization pattern

Assume:

* `gfxQueue` ‚Üí main graphics queue
* `computeQueue` ‚Üí async compute queue
* `fence` ‚Üí shared fence object

#### Case A: Compute must start *after* a graphics pass

Example: SSAO needs depth buffer produced by depth prepass.

```cpp
UINT64 fenceValue = ++fenceCounter;

// Graphics queue signals when depth is ready
gfxQueue->Signal(fence, fenceValue);

// Compute queue waits before executing SSAO
computeQueue->Wait(fence, fenceValue);

// Submit SSAO command list
computeQueue->ExecuteCommandLists(1, &ssaoCmdList);
```

Key point:

* The wait is **queue-level**, not command-list-level.
* GPU will not start executing compute work until the signal is reached.

---

#### Case B: Graphics must wait for async compute to finish

Example: Lighting pass consumes SSAO result.

```cpp
UINT64 fenceValue = ++fenceCounter;

// Compute queue signals when SSAO is done
computeQueue->Signal(fence, fenceValue);

// Graphics queue waits before lighting
gfxQueue->Wait(fence, fenceValue);
```

---

### 2.3 Combining with resource barriers

Fence synchronization only guarantees **execution order**, not **memory visibility**.

You still need:

* UAV barriers for UAV writes
* Transition barriers for state changes

Typical pattern:

1. Compute writes UAV
2. Signal fence
3. Graphics waits fence
4. Graphics applies UAV barrier
5. Graphics reads as SRV

---

### 2.4 Avoiding accidental serialization

Common mistakes that kill overlap:

1. **Over-synchronization**

   * Waiting too early instead of just before consumption

2. **Using one fence value for everything**

   * Forces unnecessary global ordering

3. **Large monolithic dispatches**

   * Prevent fine-grained interleaving

High-end engines:

* Use **multiple fence values**
* Synchronize at *pass boundaries*, not frame boundaries

---

### 2.5 Mental model that prevents bugs

Think of DX12 fences as:

> ‚ÄúGPU-side condition variables that gate queue progress.‚Äù

They do not flush caches, do not change resource states, and do not imply barriers.

---

## Summary

**1. Identifying Async Compute workloads**

* Ignore SM occupancy in isolation
* Profile bottlenecks at the *unit throughput* level
* Look for complementary saturation, not idle warps
* Ensure minimal data dependencies and bandwidth contention

**2. DX12 synchronization**

* Use `Signal` / `Wait` on command queues
* Fences define execution order, not memory hazards
* Combine fences with explicit resource barriers
* Synchronize as late and as locally as possible

If you want, the natural next step is to walk through a **real SSAO + shadow map timeline in PIX or RGP**, showing exactly where fences are placed to preserve overlap while avoiding hidden serialization.
