# ä¼˜åŒ–matmul kernelåˆ†å—å‚æ•°

### ğŸ§‘â€ğŸ’» User

ä¼˜åŒ–matmul kernelçš„æ—¶å€™ï¼Œå¦‚ä½•æ ¹æ®æ¶æ„ç»†èŠ‚æ¨ç®—å‡ºç†è®ºä¸Šèƒ½è¾¾åˆ°å³°å€¼çš„åˆ†å—å‚æ•°ã€‚éœ€è¦æ ¹æ®å¯„å­˜å™¨æ–‡ä»¶å¤§å°ï¼Œshared memory size/å¸¦å®½/å»¶è¿Ÿï¼Œå„çº§cacheåŠglobal memoryçš„å¸¦å®½/å»¶è¿Ÿï¼Œæœ‰ä¸€å¥—æ–¹æ³•è®ºï¼Œç¡®è®¤çŸ©é˜µä¹˜åˆ†å—çš„tile m/n/kåŠè½¯æµæ°´çš„çº§æ•°ã€‚èƒ½ä¸èƒ½å±•å¼€è¯´è¯´ï¼Ÿ

---

### ğŸ¤– Assistant

å¥½â€”â€”ä¸‹é¢æŠŠé‚£å¥—**ä»å¯„å­˜å™¨ / shared / å„çº§ cache / global memoryï¼ˆå¸¦å®½ & å»¶è¿Ÿï¼‰å‡ºå‘æ¨å¯¼ tileï¼ˆBM/BN/BKï¼‰å’Œè½¯ä»¶æµæ°´çº§æ•°ï¼ˆpipeline stagesï¼‰**çš„æ–¹æ³•è®ºç³»ç»ŸåŒ–åœ°å±•å¼€ï¼Œç»™å‡ºå…¬å¼ã€æ¨å¯¼æ­¥éª¤ã€å®è·µå¯å‘ä»¥åŠè°ƒå‚ checklistã€‚å°½é‡ç”¨å¯ä»£å…¥æ•°å€¼çš„**ç¬¦å·åŒ–å…¬å¼**ï¼Œä½ å¯ä»¥æŠŠå®é™…ç¡¬ä»¶å‚æ•°ä»£è¿›å»ç®—å‡ºå…·ä½“ç»“æœã€‚

æˆ‘ä¼šæŒ‰è¿™æ ·çš„ç»“æ„æ¥è®²ï¼š

1. æ¦‚å¿µæ¸…å•ï¼ˆè¦ç”¨åˆ°çš„ç¡¬ä»¶é‡ï¼‰
2. ç›®æ ‡ä¸çº¦æŸï¼ˆè¦åŒæ—¶æ»¡è¶³çš„èµ„æº / æ€§èƒ½ç›®æ ‡ï¼‰
3. é€æ­¥æ¨å¯¼ï¼šå®¹é‡çº¦æŸ â†’ å¯„å­˜å™¨çº¦æŸ â†’ å¸¦å®½ / å¼ºåº¦ (operational intensity) â†’ pipeline depthï¼ˆçº§æ•°ï¼‰
4. å…¬å¼ä¸ç¤ºä¾‹ï¼ˆæŠŠæ­¥éª¤åˆæˆæˆå¯ç”¨å…¬å¼ï¼‰
5. å®è·µå»ºè®®ã€å¸¸è§é™·é˜±ä¸è°ƒå‚ checklist

# 1) æ¦‚å¿µæ¸…å•ï¼ˆç¡¬ä»¶é‡ & ç¬¦å·ï¼‰

å…ˆæŠŠå˜é‡åˆ—å‡ºæ¥ï¼ˆç¬¦å·åŒ–ï¼Œä¾¿äºä»£å…¥ï¼‰ï¼š

* çŸ©é˜µä¸ tileï¼š

  * M,N,Kï¼šåŸå§‹ GEMM ç»´åº¦ï¼ˆC[MÃ—N] = A[MÃ—K] Ã— B[KÃ—N]ï¼‰
  * BM, BN, BKï¼šblock/tile å¤§å°ï¼ˆæˆ‘ä»¬è¦æ±‚è§£ï¼‰
* æ•°æ®ç±»å‹ï¼š

  * b = bytes/elementï¼ˆä¾‹å¦‚ FP16 b=2, FP32 b=4, FP8 b=1ï¼‰
* è®¡ç®—èµ„æºï¼ˆper-SM / per-GPUï¼ŒæŒ‰å®é™…ç¡¬ä»¶ä»£å…¥ï¼‰ï¼š

  * FLOPS_peak = GPU çš„ peak FLOPSï¼ˆæ³¨æ„æ··åˆç²¾åº¦è¦çœ‹ tensor-core throughput & accumulate typeï¼‰
  * BW_glob = global memory sustained bandwidthï¼ˆbytes/sï¼‰
  * L_glob = global memory latencyï¼ˆcycles æˆ– nsï¼‰â€”â€” ç”¨äºä¼°ç®—éšè—å»¶è¿Ÿéœ€è¦å¤šå°‘å¹¶å‘
* SM èµ„æºï¼ˆper-SMï¼‰ï¼š

  * S_sh = shared memory available per SMï¼ˆbytesï¼‰
  * R_reg = register file per SMï¼ˆnumber of 32-bit registers OR bytesï¼‰ï¼Œæˆ–ç”¨ R_reg_totalï¼ˆregsï¼‰ä¸ reg_sizeï¼ˆ4 bytesï¼‰åŒºåˆ†
  * W_max = max warps per SMï¼ˆhardware limitï¼‰
  * blocks_max = max blocks per SM
* å®ç°/çº¿ç¨‹æ˜ å°„ï¼š

  * TperBlock = threads per blockï¼ˆé€šå¸¸ 128/256/512ï¼‰
  * warps_per_block = TperBlock / 32
* æ—¶åºç›¸å…³ï¼š

  * T_compute_tile = cycles spent computing one tile (BMÃ—BNÃ—BK work mapped to tensor cores) â€” å¯ä»¥ç”¨ç†è®º FLOPS è½¬æ¢
  * T_load_tile = cycles to load required global data for that tile (taking bandwidth & coalescing into account)
  * L_glob_cycles = latency from issuing global load to it being usable (in cycles)
* å…¶å®ƒï¼š

  * Overhead_shared_bank_conflicts ç­‰æš‚ç”¨ä¸º constant å¦åˆ™ç”¨ç»éªŒå‰Šå‡æœ‰æ•ˆ BW / capacityã€‚

# 2) ç›®æ ‡ä¸çº¦æŸï¼ˆç®€è¿°ï¼‰

ä¼˜åŒ–ç›®æ ‡é€šå¸¸æ˜¯ï¼š**è®© tensor cores / ALUs åœ¨æ•´ä½“ä¸Šæ¥è¿‘å³°å€¼ FLOPS**ã€‚ä¸ºæ­¤å¿…é¡»æ»¡è¶³ï¼š

* æ¯ä¸ª SM ä¸Šæœ‰è¶³å¤Ÿå¹¶å‘ï¼ˆactive warps/blocksï¼‰æ¥éšè— memory latencyï¼Œå¹¶ä¿æŒ tensor cores æœ‰æŒç»­ workã€‚
* æ¯ä¸ª block çš„ A_sub (BMÃ—BK) ä¸ B_sub (BKÃ—BN) ä»¥åŠå¿…è¦çš„ C accumulators èƒ½**fit**åˆ° shared memory + registers ä¸­ï¼ˆæˆ–åˆç†åˆ†é…åˆ° shared/regï¼‰ã€‚
* æ•°æ®æ¬è¿ï¼ˆglobal â†’ shared â†’ regsï¼‰å’Œ compute èƒ½å¤Ÿ**é‡å **ï¼ˆé€šè¿‡ double buffering / software pipeline / async copyï¼‰ã€‚
* æ“ä½œå¼ºåº¦ï¼ˆoperational intensity I = FLOPs / bytes_from_globalï¼‰å°½é‡å¤§ï¼Œä»¥å…è¢« global bandwidth é™åˆ¶ã€‚

å› æ­¤æˆ‘ä»¬åŒæ—¶è¦è€ƒè™‘**å®¹é‡çº¦æŸ**ï¼ˆshared/regï¼‰ä¸**æ€§èƒ½çº¦æŸ**ï¼ˆå¸¦å®½ vs è®¡ç®—ï¼‰ä¸**å¹¶å‘çº¦æŸ**ï¼ˆoccupancyï¼‰ã€‚

# 3) é€æ­¥æ¨å¯¼ï¼ˆæ ¸å¿ƒæ­¥éª¤ï¼‰

### A. å®¹é‡çº¦æŸï¼ˆshared memory + registerï¼‰

ä¸€ä¸ª block å¤„ç†çš„ tile è¦å ç”¨çš„ shared/reg å¤§å°å¿…é¡»å°äºç¡¬ä»¶å…è®¸å€¼ï¼Œå¦åˆ™ä¸èƒ½è·‘ã€‚é¦–å…ˆä¼°ç®—ä¸€ä¸ª block æ‰€éœ€çš„ shared memoryï¼š

* A_tile bytes = BM Ã— BK Ã— b
* B_tile bytes = BK Ã— BN Ã— b
* C_tile bytes (å¦‚æœåœ¨ shared ä¸­ç¼“å­˜ partial C) = BM Ã— BN Ã— b  ï¼ˆæ³¨æ„å¾ˆå¤šå®ç°è®©æ¯çº¿ç¨‹åœ¨å¯„å­˜å™¨é‡Œç´¯åŠ ï¼Œæœ€ç»ˆå†™å› globalï¼Œä¸ä¸€å®šæŠŠ C æ”¾ sharedï¼‰
* Shared_total_per_block â‰ˆ A_tile + B_tile + (optional) C_tile + overhead (alignment, double buffering)

**çº¦æŸ 1ï¼š**

```
A_tile + B_tile + optional_C <= S_sh_alloc_per_block
```

S_sh_alloc_per_block å–å†³äºä½ èƒ½åœ¨ä¸€ä¸ª SM ä¸ŠåŒæ—¶æ¿€æ´»å¤šå°‘ blockï¼ˆblocks_per_smï¼‰ï¼Œä¹Ÿå°±æ˜¯ï¼š

```
S_sh_alloc_per_block = floor(S_sh_total / blocks_per_sm_desired)
```

å¸¸è§åšæ³•ï¼šå…ˆé€‰æ‹© 1 æˆ– 2 blocks_per_smï¼ˆä»¥æé«˜ concurrencyï¼‰ï¼Œè®¡ç®—å…è®¸çš„ S_sh_alloc_per_blockã€‚

**å¯„å­˜å™¨çº¦æŸ**ï¼ˆæ›´å®¹æ˜“æˆä¸ºç“¶é¢ˆï¼‰ï¼š
æ¯ä¸ª thread ä½¿ç”¨çš„å¯„å­˜å™¨æ•°ç›® reg_per_thread å¿…é¡»æ»¡è¶³ï¼š

```
reg_per_thread Ã— TperBlock <= R_reg_total_per_SM / blocks_per_sm_desired
```

ä¼°ç®— reg_per_thread æ¥è‡ªï¼š

* accumulators per thread (number of C elements that thread keeps in reg)
* fragments of A/B loaded into registers for compute (dependent on warp-level fragment sizes)
* temporaries, indices, pointers

å¸¸è§ç­–ç•¥ï¼šå†³å®šæ¯çº¿ç¨‹ç´¯åŠ å¤šå°‘ C å…ƒç´ ï¼ˆcall it c_per_threadï¼‰ï¼Œé‚£å¯„å­˜å™¨éœ€æ±‚åŸºæœ¬ä¸ c_per_thread æˆæ­£æ¯”ã€‚é€šå¸¸å¸Œæœ›æ¯çº¿ç¨‹è‡³å°‘ç»´æŒæ•°ä¸ª C accumulatorsï¼Œä»¥ä¾¿ç”¨å¯„å­˜å™¨æ›¿ä»£ shared å†™è¯»ï¼Œå‡å°‘ shared pressureã€‚

---

### B. Operational Intensityï¼ˆç®—å­å¼ºåº¦ï¼‰â†’ åˆ¤æ–­æ˜¯å¦å¸¦å®½å—é™

ç”¨ roofline/ç®—å­å¼ºåº¦åˆ¤æ–­æ˜¯å¦èƒ½åˆ©ç”¨ç®—åŠ›ï¼š

* FLOPs per tile (F_tile) = 2 Ã— BM Ã— BN Ã— BK ï¼ˆGEMM çš„ä¹˜åŠ è®¡æ•°ï¼‰
* Bytes read from global per tile (D_tile_global) â€” å…³é”®ç‚¹ï¼š**å¦‚æœèƒ½å¤ç”¨ A_tile å’Œ B_tile å¤šæ¬¡ï¼ˆåœ¨ shared ä¸­ï¼‰**ï¼Œé‚£ä¹ˆæ¯ block ä» global è¯»çš„æ¬¡æ•°åªä¸ A_tile/B_tile çš„å¤§å°æœ‰å…³ï¼Œè€Œä¸æ˜¯æ¯æ¬¡ compute éƒ½è¯»ã€‚

æœ€ä¿å®ˆçš„å–æ³•ï¼ˆæ¯ tile åªä» global è¯»ä¸€æ¬¡ A_tile å’Œ B_tileï¼‰ï¼š

```
D_tile_global â‰ˆ (BMÃ—BK + BKÃ—BN + (if read C then BMÃ—BN) ) Ã— b
```

ï¼ˆé€šå¸¸ C åªå†™å›ä¸€æ¬¡ï¼Œè¯»å†™åˆå¹¶å¯¹å¸¦å®½å½±å“å°ï¼‰

ç®—å­å¼ºåº¦ Iï¼š

```
I = F_tile / D_tile_global   (FLOPs / byte)
```

åˆ¤æ–­ï¼š

* å¦‚æœ `I < FLOPS_peak / BW_glob` â†’ memory-boundï¼ˆglobal BW æˆç“¶é¢ˆï¼‰
* å¦‚æœ `I > FLOPS_peak / BW_glob` â†’ compute-boundï¼ˆæˆ–å—æ›´è¿‘çš„å±‚å¦‚ L2/L1 bandwidth é™åˆ¶ï¼‰

å¯é‡å†™ä¸ºé’ˆå¯¹ element bï¼š

```
I = 2*BM*BN*BK / ((BM*BK + BK*BN) * b) = 2*BM*BN / ((BM + BN) * b) * (cancel BK)
```

æ³¨æ„ BK åœ¨åˆ†å­ä¸åˆ†æ¯éƒ½å‡ºç°ï¼Œæœ€å BK åè€Œä¼šéƒ¨åˆ†æŠµæ¶ˆï¼›ä½† BK ä¼šå½±å“ A/B tile å¤§å°ä¸ shared/reg å ç”¨ï¼Œä»è€Œå½±å“èƒ½å¦æˆç«‹ã€‚

æ‰€ä»¥è¦**å¢å¤§ I**ï¼Œå¸¸ç”¨æ–¹æ³•ï¼š

* å¢å¤§ BM,BNï¼ˆæ‰©å¤§è¾“å‡º tileï¼‰ï¼Œå› ä¸º FLOPs scales ~ BMÃ—BN but bytes ~ BMÃ—BK + BKÃ—BNï¼Œæ‰©å¤§ BM/BN æ›´æœ‰åˆ©ï¼ˆç›´åˆ° shared/regé™åˆ¶ï¼‰
* é€‰æ‹©åˆé€‚ BKï¼šBK å¤ªå°ä¼šé™ä½ reuseï¼ˆä½†å‡å°‘ sharedï¼‰ï¼Œå¤ªå¤§ä¼šä½¿ A/B æ— æ³•æ”¾å…¥ shared

---

### C. å¹¶å‘ / Occupancyï¼ˆéšè— latencyï¼‰

è¦æŠŠ global latency éšè—ä½ï¼Œéœ€è¦è¶³å¤Ÿçš„å¹¶å‘å·¥ä½œï¼ˆactive warps / blocksï¼‰ã€‚è¡¡é‡ï¼š

* active_warps_per_SM = (warps_per_block Ã— blocks_per_sm_active)
* ç¡¬ä»¶èƒ½åŒæ—¶æ´»è·ƒçš„ warps æœ€å¤§å€¼æ˜¯ W_max

Latency hiding conditionï¼ˆç²—ç•¥ï¼‰ï¼š

```
active_warps_per_SM Ã— T_compute_tile_per_warp >= L_glob_cycles
```

æ›´å¸¸è§çš„åšæ³•ï¼šç¡®ä¿æœ‰è¶³å¤Ÿçš„ blocks_per_smï¼ˆé€šå¸¸ â‰¥ 2â€“4ï¼‰æ¥ overlap memory opsã€‚è‹¥æ¯ä¸ª tile è®¡ç®—æ—¶é—´å¤ªçŸ­ï¼ˆT_compute_tile smallï¼‰ï¼Œé‚£å°±éœ€è¦æ›´å¤šçš„ pipeline stages/blocksã€‚

**å¦‚ä½•ä¼°ç®— T_compute_tile**ï¼š

```
T_compute_tile â‰ˆ F_tile / FLOPS_per_SM_effective (in FLOPs/cycle)
```

FLOPS_per_SM_effective å¯ä»¥ç”¨ peak but è¦æ³¨æ„ warp-level mapping and instruction throughput (tensor core efficiency).

ç„¶åè®¡ç®—éœ€è¦çš„å¹¶å‘åº¦ S_neededï¼š

```
S_needed ~ ceil(L_glob_cycles / T_compute_tile) + 1
```

è¿™ä¸ pipeline stages çš„æƒ³æ³•ä¸€è‡´ï¼šè¦ overlapping loads for future tiles while computing current tile.

---

### D. è½¯ä»¶æµæ°´ï¼ˆsoftware pipelining / stagesï¼‰è®¾è®¡

è½¯ä»¶æµæ°´çš„ç›®çš„æ˜¯é‡å å¤šä¸ªæ­¥éª¤ï¼šglobal load â†’ L2/L1 â†’ shared copy â†’ compute â†’ write backã€‚å…¸å‹çš„è®¾è®¡æ˜¯ double-buffer æˆ– triple-bufferï¼š

* **2-stage (double-buffer)**ï¼šä¸€ç»„ A/B åœ¨è®¡ç®—ï¼Œå¦ä¸€ç»„åœ¨ prefetchã€‚ä» global åˆ° shared ç”¨ async copyï¼Œcompute overlap copyã€‚é€‚åˆå½“ T_compute_tile â‰¥ L_copy_timeï¼ˆæˆ–æ¥è¿‘ï¼‰æ—¶ã€‚
* **S-stage pipeline**ï¼šæŠŠ long latency chain æ‹†æˆ S æ®µï¼ˆä¾‹å¦‚ fetch from global, wait L2, copy to shared, compute, writebackï¼‰ï¼Œéœ€è¦ S buffersã€‚`S` çš„é€‰æ‹©ç”±ä¸‹é¢çš„å…¬å¼é©±åŠ¨ï¼š

è‹¥ L_total_cycle æ˜¯ä»å‘èµ· global load åˆ° load å®Œæˆå¯ç”¨çš„æ€»å»¶è¿Ÿï¼ˆä»¥ cyclesï¼‰ï¼Œä¸” T_compute_tile æ˜¯æ¯ä¸ª tile çš„ compute timeï¼ˆcyclesï¼‰ï¼Œåˆ™æœ€ä½éœ€è¦çš„å¹¶è¡Œ tiles æ•°ï¼ˆå³ pipeline depthï¼‰ï¼š

```
S_min = ceil(L_total_cycle / T_compute_tile) + 1
```

è§£é‡Šï¼šå¦‚æœä¸€ä¸ª tile çš„ compute æ—¶é—´å¯ä»¥â€œè¦†ç›–â€L_total_cycle çš„ä¸€éƒ¨åˆ†ï¼Œé‚£å°±éœ€è¦ S_min tiles åŒæ—¶å¤„äº pipeline çš„ä¸åŒé˜¶æ®µæ¥å®Œå…¨éšè—é‚£æ®µå»¶è¿Ÿã€‚å¸¸è§å®ç°é‡Œ L_total_cycle åŒ…å« global memory latency + TMA overhead + any memcopy latencyã€‚

å®è·µä¸Šï¼Œå¾ˆå¤šé«˜æ€§èƒ½å®ç°ä¼šé€‰æ‹© S = 2 æˆ– 3ï¼Œå¦‚æœ global latency å¾ˆé«˜æˆ– T_compute_tile å¾ˆå°ï¼ˆtile å°ï¼‰ï¼Œå°±éœ€è¦æ›´é«˜ Sï¼ˆ4â€“8ï¼‰ã€‚ä½† S çš„å¢åŠ ä¼šå¢åŠ  shared / register çš„ buffering éœ€æ±‚ï¼ˆæ¯ä¸ª stage éƒ½éœ€è¦ bufferï¼‰ï¼Œå› æ­¤ S ä¸èƒ½æ— é™å¤§â€”â€”å›åˆ°å®¹é‡çº¦æŸã€‚

---

# 4) æŠŠå®ƒä»¬åˆèµ·æ¥ï¼šå¯æ‰§è¡Œçš„æ¨ç®—æµç¨‹ï¼ˆstep-by-stepï¼‰

ç»™å‡ºä¸€ä¸ªå·¥ç¨‹å¸ˆå¯ä»¥ç›´æ¥æ‰§è¡Œçš„æµç¨‹ï¼ˆæŠŠç¡¬ä»¶æ•°å€¼ä»£å…¥ï¼‰ï¼š

**æ­¥éª¤ 0ï¼šæ”¶é›†ç¡¬ä»¶å‚æ•°**ï¼ˆä»£å…¥å®é™…å€¼ï¼‰

* S_sh_totalï¼ŒR_reg_totalï¼ˆregsï¼‰ï¼ŒW_maxï¼Œblocks_maxï¼ŒBW_globï¼ˆbytes/sï¼‰ï¼ŒL_glob_cyclesï¼ˆcyclesï¼‰ï¼ŒFLOPS_peak (FLOPs/s) æˆ– per-SM FLOPS
* é€‰æ‹©æ•°æ®ç±»å‹ b

**æ­¥éª¤ 1ï¼šé€‰ä¸€ä¸ª candidate BMÃ—BN å¸¦æ¥çš„åˆå§‹å¼ºåº¦**

* é€‰æ‹©åˆå§‹ BKï¼ˆå¸¸è§ 32/64/128ï¼‰ã€‚é€‰ BK å— shared/reg é™åˆ¶ã€‚
* è®¡ç®— F_tile = 2*BM*BN*BK
* è®¡ç®— D_tile = (BM*BK + BK*BN) * b
* ç®—å­å¼ºåº¦ I = F_tile / D_tile

**æ­¥éª¤ 2ï¼šæ£€æŸ¥å¸¦å®½çº¦æŸï¼ˆæ˜¯å¦ memory-boundï¼‰**

* ä¸´ç•Œå¼ºåº¦ I_crit = FLOPS_peak / BW_glob
* å¦‚æœ I < I_critï¼šè¯´æ˜ global BW å°†é™åˆ¶æ€§èƒ½ï¼Œéœ€å¢å¤§ BM/BN æˆ–é™ç²¾åº¦ï¼ˆå‡å°‘ bï¼‰æˆ–å¢åŠ  BK çš„ reuseï¼ˆæ³¨æ„ BK å½±å“ sharedï¼‰
* å¦‚æœ I > I_critï¼šè¯´æ˜å¯èƒ½ compute-bound æˆ–æ›´è¿‘å±‚ï¼ˆL2ï¼‰å¸¦å®½æˆä¸ºé™åˆ¶ â€” ç»§ç»­ä¸‹æ­¥

**æ­¥éª¤ 3ï¼šå…±äº«å†…å­˜ / å¯„å­˜å™¨é¢„ç®—**

* è®¡ç®— A_tile + B_tile + optional C_tile <= S_sh_alloc_per_block

  * S_sh_alloc_per_block = floor(S_sh_total / blocks_per_sm_desired)
* ä¼°ç®— reg_per_threadï¼šé¦–å…ˆå†³å®šæ¯çº¿ç¨‹ç´¯åŠ å¤šå°‘ C å…ƒç´ ï¼ˆc_per_threadï¼‰ï¼Œä»¥åŠä¸ºåŠ è½½ A/B fragments éœ€è¦å¤šå°‘å¯„å­˜å™¨ã€‚ç²—ç•¥ä¼°ï¼š

  ```
  reg_per_thread â‰ˆ c_per_thread + a_frag_regs + b_frag_regs + overhead
  ```

  éªŒè¯ reg_per_thread Ã— TperBlock â‰¤ R_reg_total_per_SM / blocks_per_sm_desired

**æ­¥éª¤ 4ï¼šå¹¶å‘ & latency hiding â†’ pipeline depth**

* ä¼°ç®— T_compute_tile_cycles = F_tile / FLOPS_per_SM_effective
* S_min = ceil(L_total_cycle / T_compute_tile_cycles) + 1
* é€‰æ‹© blocks_per_sm (â‰¥ S_min / warps_per_block ç­‰)ï¼Œä¿è¯ occupancyï¼š

  * warps_active = warps_per_block Ã— blocks_per_sm
  * warps_active â‰¤ W_max
* ç¡®è®¤ä½¿ç”¨ S_min stages çš„ bufferingï¼ˆshared/regï¼‰ä»æ»¡è¶³å®¹é‡çº¦æŸï¼ˆå› ä¸ºæ¯ stage éœ€è¦ bufferï¼‰

**æ­¥éª¤ 5ï¼šè¿­ä»£è°ƒèŠ‚**

* å¦‚æœå®¹é‡/å¯„å­˜å™¨è¶…é™ï¼Œå‡å° BM/BN æˆ– BK æˆ–å‡å°‘ c_per_threadï¼ˆå¯„å­˜å™¨æ¢ sharedï¼‰ï¼Œæˆ–è€…é™ä½ blocks_per_sm
* å¦‚æœ I < I_critï¼ˆmemory-boundï¼‰ï¼Œä¼˜å…ˆå¢åŠ  BM æˆ– BNï¼ˆæ‰©å¤§è¾“å‡º tileï¼‰ï¼Œæˆ–é‡‡ç”¨æ›´ aggressive reuseï¼ˆblock åˆ’åˆ†ç­–ç•¥ï¼‰ï¼Œæˆ–æ”¹ç”¨ lower-precision
* åœ¨æ¯è½®è°ƒæ•´åï¼Œé‡æ–°è®¡ç®—ä¸Šé¢çš„æ‰€æœ‰çº¦æŸï¼Œç›´åˆ°æ‰¾å‡ºæ»¡è¶³æ‰€æœ‰çº¦æŸçš„æœ€å¤§ BM/BN/BK ä¸ pipeline S

---

# 5) å…¬å¼æ±‡æ€»ï¼ˆä¾¿äºç›´æ¥ä»£å…¥è®¡ç®—ï¼‰

* F_tile = 2 Ã— BM Ã— BN Ã— BK  ï¼ˆFLOPsï¼‰

* D_tile_global â‰ˆ (BMÃ—BK + BKÃ—BN) Ã— b  ï¼ˆbytes from global per tileï¼‰

* I = F_tile / D_tile_global = 2Ã—BMÃ—BNÃ—BK / ((BMÃ—BK + BKÃ—BN)Ã—b)

* æ¡ä»¶æ˜¯å¦ memory-bound:

  ```
  memory_bound if I < FLOPS_peak / BW_glob
  ```

* shared constraint:

  ```
  A_bytes + B_bytes + C_bytes <= floor(S_sh_total / blocks_per_sm)
  ```

* register constraint:

  ```
  reg_per_thread Ã— TperBlock <= floor(R_reg_total / blocks_per_sm)
  ```

* latency hiding / pipeline depth:

  ```
  S_min = ceil(L_total_cycle / T_compute_tile) + 1
  T_compute_tile (cycles) â‰ˆ F_tile / FLOPS_per_SM_effective
  ```

ï¼ˆæ³¨ï¼šFLOPS_per_SM_effective = FLOPS_peak_per_SM Ã— expected_tensor_core_utilization_factorï¼‰

---

# 6) æ•°å€¼ç¤ºä¾‹ï¼ˆä¸¾ä¸€ä¸ªæŠ½è±¡çš„ã€Œä»£å…¥ç¤ºä¾‹ã€å¸®åŠ©ç†è§£ â€” ä½¿ç”¨å‡è®¾æ•°å€¼ï¼Œéç‰¹å®šå¡ï¼‰

å‡è®¾ï¼ˆç¤ºä¾‹ï¼Œä»…æ¼”ç¤ºæµç¨‹ï¼‰ï¼š

* b = 2 bytes (FP16)
* S_sh_total = 256 KB = 262144 bytes
* R_reg_total = 65536 registers (32-bit each)
* BW_glob = 1 TB/s = 1e12 bytes/s ï¼ˆæ³¨æ„ï¼šåªæ˜¯æ¼”ç¤ºï¼‰
* FLOPS_peak = 50 TFLOPS = 5e13 FLOPs/sï¼ˆæ¼”ç¤ºï¼‰
* Tclock = 1 GHz â†’ 1 cycle = 1 ns
* L_total_cycle (global) = 500 cyclesï¼ˆç¤ºæ„ï¼‰
* choose BM=128, BN=128, BK=32

  * F_tile = 2 * 128 * 128 * 32 = 1,048,576 FLOPs (~1.05e6)
  * D_tile = (128*32 + 32*128) * 2 = (4096 + 4096) * 2 = 16384 bytes = 16 KB
  * I = 1.048e6 / 16384 â‰ˆ 64 FLOPs/byte
* I_crit = FLOPS_peak / BW_glob = 5e13 / 1e12 = 50 FLOPs/byte

  * å› æ­¤ I (64) > I_crit (50) â†’ **ä¸æ˜¯ global BW ç“¶é¢ˆ**ï¼ˆå¯èƒ½ compute-bound æˆ– L2é™å®šï¼‰
* T_compute_tile â‰ˆ F_tile / FLOPS_per_SM_effective

  * å‡è®¾æ¯ SM effective FLOPS å¯¹åº”åˆ°è¿™ä¸ª block çš„ share æ˜¯ 500 GFLOPSï¼ˆç¤ºæ„ï¼‰ï¼ŒT_compute_tile â‰ˆ 1.048e6 / 5e8 = 0.0021 s? Wait å•ä½ä¸å¯¹ â€”â€” ç”¨ cycles æ›´ç›´è§‚ï¼š
  * FLOPS_per_cycle_per_SM = 500 GFLOPS / 1 GHz = 500 FLOPs/cycle â†’ T_compute_tile â‰ˆ 1.048e6 / 500 â‰ˆ 2096 cycles
* S_min = ceil(L_total_cycle / T_compute_tile) + 1 = ceil(500 / 2096) + 1 = 1 + 1 = 2 â†’ double buffering è¶³å¤Ÿ
* Shared usage per block:

  * A = 128*32*2 = 8192 bytes (8 KB)
  * B = same = 8 KB
  * total â‰ˆ 16 KB (plus buffers) â†’ S_sh_total 256 KB æ”¯æŒå¾ˆå¤š blocks
* reg estimate: å‡è®¾ reg_per_thread â‰ˆ 32 regs, TperBlock = 256 â†’ 8192 regs per block â†’ R_reg_total 65536 å¯æ”¯æ’‘ 8 blocks per SMï¼ˆå— W_max é™åˆ¶ï¼‰
* occupancy OK.

ç¤ºä¾‹è¯´æ˜ï¼šåœ¨è¿™äº›å‡è®¾ä¸‹ (128,128,32) æ˜¯å¯è¡Œä¸” double-buffer è¶³å¤Ÿã€‚ç°å®ä¸­æŠŠå…·ä½“å¡çš„ BWã€FLOPSã€L_total_cycleã€reg total ç²¾ç¡®ä»£å…¥å³å¯å¾—åˆ°æ›´å‡†ç¡®ç»“è®ºã€‚

---

# 7) å®è·µå»ºè®®ã€heuristics ä¸ checklistï¼ˆå¿«é€Ÿä¸Šæ‰‹ï¼‰

* ä¼˜å…ˆåš**ç¬¦å·åŒ–ä¼°ç®—**ï¼ˆä¸Šé¢æµç¨‹ï¼‰æ¥æ’æ‰æ˜æ˜¾ä¸å¯èƒ½çš„ tileï¼ˆä¾‹å¦‚ä¼šè¶… shared/regï¼‰ã€‚
* å¸¸ç”¨èµ·ç‚¹ tileï¼šBM=BN=128ï¼ŒBK=32 / 64ï¼ˆå¯¹ FP16/FP8 å¾ˆå¸¸è§ï¼‰ã€‚ç„¶åæŒ‰ä¸Šé¢å…¬å¼æ£€æŸ¥ Iã€shared/regã€S_minã€‚
* å¯„å­˜å™¨ä¼˜å…ˆçº§ï¼šè‹¥å¯„å­˜å™¨æˆä¸ºç“¶é¢ˆï¼ŒæŠŠéƒ¨åˆ† C accum æ”¾ sharedï¼ˆä»£ä»·ï¼šæ›´å¤š sharedï¼‰ï¼Œæˆ–è€…å‡å° c_per_threadï¼ˆæ¯çº¿ç¨‹ç´¯åŠ æ›´å°‘ï¼‰ï¼Œç„¶åå¢åŠ  thread æ•°/warp mappingã€‚
* è½¯ä»¶æµæ°´ stagesï¼š

  * å¦‚æœ T_compute_tile â‰« L_total_cycleï¼ŒS=2 å°±å¤Ÿï¼ˆdouble bufferï¼‰ã€‚
  * å¦‚æœ T_compute_tile â‰² L_total_cycleï¼Œéœ€è¦ S>2ï¼›S è¶Šé«˜ç”¨äºé®æ©è¶Šå¤š latencyï¼Œä½† buffer æˆæœ¬å¢é«˜ã€‚
  * å®é™…ä¸Šï¼Œä½¿ç”¨ `cp.async`/TMA + double-buffer + 2â€“3 stage å¸¸èƒ½ç»™å¾ˆå¤§æ”¶ç›Šã€‚
* ä¼˜åŒ– memory path çš„å¯¹é½ä¸ coalescingï¼šä¿è¯ global loads coalescedï¼ˆA/B çš„è®¿é—®æ¨¡å¼æŒ‰ warp/seg é…ç½®ï¼‰ï¼Œå‡å°‘ L2 thrashingã€‚
* é¿å… shared bank conflictsï¼špad shared rows/cols ä»¥é¿å…å†²çªã€‚
* Autotuneï¼šåœ¨å¤šä¸ªåˆç† tile ä¸Šè·‘å¾®åŸºå‡†ï¼ˆæµ‹ throughputã€bandwidth utilã€SM utilizationï¼‰å¹¶é€‰æ‹©æœ€ä½³ã€‚è®¸å¤šå®ç°ï¼ˆCUTLASSï¼‰å°±æ˜¯è¿™ä¹ˆåšçš„ã€‚
* è‹¥åšé‡åŒ–ï¼ˆQ4/K ç­‰ï¼‰ï¼šæŠŠè§£å‹ï¼è½¬ FP16 çš„å¼€é”€çº³å…¥ D_tile_globalï¼ˆå³ä» global è¯»å…¥åéœ€è¦è½¬æ¢çš„ä»£ä»·ï¼‰ï¼›æœ€ä¼˜æ˜¯æŠŠ dequant + matmul + requant èåˆï¼Œé¿å…å¤šæ¬¡å†™å›ï¼è¯»å‡ºã€‚

---

# 8) å¸¸è§è¯¯åŒºä¸é™·é˜±

* **åªçœ‹å…±äº«å†…å­˜å®¹é‡ï¼Œä¸çœ‹å¯„å­˜å™¨**ï¼šå¯„å­˜å™¨å¾€å¾€æ›´å…ˆæˆä¸ºç“¶é¢ˆï¼Œå¯¼è‡´ç¼–è¯‘å™¨æ’å…¥ spill åˆ° local memoryï¼Œæ€§èƒ½æš´è·Œã€‚ä¸€å®šå…ˆæ£€æŸ¥ reg_per_thread Ã— threads_per_blockã€‚
* **å¿½è§†å®é™… sustained bandwidth ä¸ç†è®ºå¸¦å®½å·®**ï¼šç”¨ sustained BWï¼ˆbenchmark æµ‹åˆ°çš„ï¼‰è€Œä¸æ˜¯æ ‡ç§°å€¼ã€‚
* **å¿½è§† L2 / L1 å¸¦å®½ / äº‰ç”¨**ï¼šå¦‚æœå¤šä¸ª block åŒæ—¶ä»åŒä¸€è¡Œè¯»å–ï¼Œä¼šäº§ç”Ÿ L2/L1 å†²çªï¼Œé™ä½å®é™… reuseã€‚
* **tile å°ºå¯¸ä¸æ˜¯è¶Šå¤§è¶Šå¥½**ï¼šå°½ç®¡å¢å¤§ BM/BN æé«˜ç®—å­å¼ºåº¦ï¼Œä½†ä¼šçˆ†æ‰ shared/reg/occupancyï¼Œä»è€Œé™ä½ overall throughputã€‚

---

# 9) å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥ç›´æ¥å¸®ä½ åšä¸¤ä»¶äº‹ï¼ˆé€‰å…¶ä¸€æˆ–éƒ½åšï¼‰

* ç»™æˆ‘ä½ ç›®æ ‡ GPU çš„å‡ ä¸ªç¡¬ä»¶å‚æ•°ï¼ˆS_sh_totalã€R_reg_totalã€BW_globã€FLOPS_peakã€L_glob_cyclesï¼‰ï¼Œæˆ‘æŠŠä¸Šé¢çš„æµç¨‹ç”¨ä¸€ä¸ªå°è¡¨æ ¼/è„šæœ¬è·‘å‡ºä¸€ç»„å€™é€‰ (BM,BN,BK) + æ¨è pipeline stages å¹¶ç»™å‡ºæ¯ä¸ªå€™é€‰çš„ Iã€shared usageã€reg usageã€S_minã€‚ï¼ˆæˆ‘ä¼šç»™å‡ºå…·ä½“æ•°å€¼å’Œæ¨èï¼‰
* æˆ–è€…æˆ‘ç›´æ¥å†™ä¸€æ®µ pseudo-code / CUDA kernel skeletonï¼ˆå¸¦ double/triple bufferingã€cp.async çš„ä¼ªå®ç°ç»“æ„ï¼‰ï¼ŒæŠŠ buffer å¸ƒå±€ã€warp-to-fragment mappingã€å¯„å­˜å™¨åˆ†é…å»ºè®®éƒ½å†™å‡ºæ¥ï¼Œä¾¿äºä½ ç§»æ¤åˆ° CUTLASS æˆ–è‡ªå·±å®ç°ã€‚

ä½ æƒ³å…ˆè¦å“ªä¸€ç§ï¼Ÿï¼ˆæˆ‘ä¸ä¼šç­‰å¾…ä½ å»åšé¢å¤–äº‹æƒ… â€”â€” å¦‚æœä½ æŠŠç¡¬ä»¶å‚æ•°è´´ä¸Šæ¥æˆ‘ç«‹åˆ»æŠŠæ•°å€¼ä»£å…¥å¹¶ç»™å‡ºå…·ä½“å€™é€‰ï¼›å¦‚æœä½ ä¸è´´ï¼Œæˆ‘å°±ç»™ä¸€ä¸ªé€šç”¨çš„ parametric è¡¨æ ¼ + kernel skeletonã€‚ï¼‰


---

### ğŸ§‘â€ğŸ’» User

æ ¹æ®è¿™å¥—æ–¹æ³•è®ºï¼Œæ˜¯å¦å¯ä»¥å¥—ç”¨åˆ°å…¶ä»–compute bound/memory bound kernelä¸Šï¼Ÿ

---

### ğŸ¤– Assistant

**ç­”æ¡ˆæ˜¯è‚¯å®šçš„ã€‚**

è¿™å¥—æ–¹æ³•è®ºçš„æ ¸å¿ƒæœ¬è´¨æ˜¯**èµ„æºçº¦æŸä¸‹çš„æ€§èƒ½å»ºæ¨¡ï¼ˆResource-Constrained Performance Modelingï¼‰**ï¼Œå®ƒç»“åˆäº† **Roofline Modelï¼ˆç®—åŠ›/å¸¦å®½æƒè¡¡ï¼‰** å’Œ **Little's Lawï¼ˆå»¶è¿Ÿéšè—ï¼‰**ã€‚è¿™ä¸ä»…ä»…é€‚ç”¨äºçŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰ï¼Œè€Œæ˜¯é€‚ç”¨äºå‡ ä¹æ‰€æœ‰**è¿½æ±‚æè‡´æ€§èƒ½çš„ GPU Kernel**ï¼ŒåŒ…æ‹¬ Compute-boundï¼ˆè®¡ç®—å¯†é›†å‹ï¼‰å’Œ Memory-boundï¼ˆè®¿å­˜å¯†é›†å‹ï¼‰ã€‚

åªè¦ Kernel æ¶‰åŠæ•°æ®çš„**æ¬è¿ï¼ˆGlobal $\to$ Shared $\to$ Regï¼‰**å’Œ**å¤„ç†ï¼ˆALU/TensorCoreï¼‰**ï¼Œè¿™å¥—é€»è¾‘å®Œå…¨é€šç”¨ã€‚

ä¸‹é¢æˆ‘å°†è¿™å¥—æ–¹æ³•è®ºæŠ½è±¡å‡ºæ¥ï¼Œå±•ç¤ºå¦‚ä½•â€œå¥—ç”¨â€åˆ°ä¸åŒç±»å‹çš„ Kernel ä¸Šï¼ˆå¦‚ FlashAttentionã€å·ç§¯ã€LayerNorm/Softmax ç­‰ï¼‰ã€‚

---

### ä¸€ã€ é€šç”¨æ–¹æ³•è®ºçš„æŠ½è±¡ï¼ˆUniversal Formulaï¼‰

ä¸è®ºä»€ä¹ˆ Kernelï¼Œä¼˜åŒ–æ­¥éª¤éƒ½å¯ä»¥æŠ½è±¡ä¸ºæ±‚è§£ä»¥ä¸‹ä¸ç­‰å¼ç»„ï¼š

1.  **å®¹é‡çº¦æŸï¼ˆCapacityï¼‰ï¼šèƒ½å¡å¾—è¿›å—ï¼Ÿ**
    $$ \text{SMem\_Usage}(\text{Tile}) + \text{Reg\_Spill\_Risk} \le \text{Hardware\_Limit} $$
    *   å†³å®šäº† Tile çš„ä¸Šé™ã€‚
2.  **å¼ºåº¦çº¦æŸï¼ˆIntensityï¼‰ï¼šå¸¦å®½å¤Ÿåƒå—ï¼Ÿ**
    $$ \frac{\text{Work\_per\_Tile}}{\text{Bytes\_Load\_per\_Tile}} \ge \frac{\text{Peak\_FLOPS}}{\text{Peak\_Bandwidth}} $$
    *   å¯¹äº **Compute-bound**ï¼šé€šè¿‡å¢å¤§ Tile æˆ–å¢åŠ  Reuse æ¥æå‡å·¦è¾¹ï¼Œç›´åˆ°å¤§äºå³è¾¹ã€‚
    *   å¯¹äº **Memory-bound**ï¼šå·¦è¾¹é€šå¸¸å›ºå®šï¼ˆæ— æ³•å¤ç”¨ï¼‰ï¼Œç›®æ ‡è½¬å˜ä¸ºâ€œå¦‚ä½•è·‘æ»¡å¸¦å®½â€ã€‚
3.  **å»¶è¿Ÿçº¦æŸï¼ˆLatencyï¼‰ï¼šæµæ°´çº¿å¤Ÿæ·±å—ï¼Ÿ**
    $$ \text{Concurrency} \times \text{Work\_Time} \ge \text{Latency} $$
    *   å†³å®šäº†éœ€è¦çš„ Active Warps æ•°é‡æˆ–è½¯ä»¶æµæ°´ï¼ˆPrefetchï¼‰çš„çº§æ•°ã€‚

---

### äºŒã€ å¥—ç”¨åˆ° Compute-Bound Kernelï¼ˆè®¡ç®—å¯†é›†å‹ï¼‰

è¿™ç±» Kernel çš„ç‰¹ç‚¹æ˜¯æœ‰å¤§é‡çš„**æ•°æ®å¤ç”¨ï¼ˆData Reuseï¼‰**ã€‚æœ€å…¸å‹çš„ä¾‹å­æ˜¯ **å·ç§¯ï¼ˆConvolutionï¼‰** å’Œ **FlashAttention**ã€‚

#### 1. å·ç§¯ (Convolution / Implicit GEMM)
å·ç§¯æœ¬è´¨ä¸Šæ˜¯ç‰¹æ®Šçš„çŸ©é˜µä¹˜ï¼Œæˆ–è€…è¯´æ»‘åŠ¨çª—å£è®¡ç®—ã€‚

*   **Tiling æ˜ å°„ï¼š**
    *   GEMM çš„ $M/N/K$ å¯¹åº”å·ç§¯çš„ $N \times H \times W$ï¼ˆè¾“å‡ºåƒç´ æ•°ï¼‰ã€$C_{out}$ï¼ˆè¾“å‡ºé€šé“ï¼‰ã€$C_{in} \times K_h \times K_w$ï¼ˆè¾“å…¥ä½“ç§¯ï¼‰ã€‚
    *   æˆ‘ä»¬éœ€è¦ç¡®å®šï¼šä¸€æ¬¡è®¡ç®—å¤šå°‘ä¸ªè¾“å‡ºåƒç´ ï¼ˆ$Tile\_HW$ï¼‰ï¼Œå¤šå°‘ä¸ªè¾“å‡ºé€šé“ï¼ˆ$Tile\_C_{out}$ï¼‰ã€‚
*   **å¥—ç”¨æ–¹æ³•è®ºï¼š**
    *   **å®¹é‡ï¼š** è¾“å…¥ Feature Map çš„ Tile éœ€è¦åŠ è½½åˆ° Shared Memoryã€‚å¦‚æœå·ç§¯æ ¸è¾ƒå¤§ï¼ˆå¦‚ $7 \times 7$ï¼‰ï¼ŒHaloï¼ˆé‡å åŒºåŸŸï¼‰ä¼šå ç”¨å¤§é‡ Sharedï¼Œé™åˆ¶äº† Tile å¤§å°ã€‚
    *   **Reuseï¼š** å¢å¤§ $Tile\_C_{out}$ å’Œ $Tile\_HW$ å¯ä»¥å¤ç”¨åŠ è½½è¿›æ¥çš„ Input Tileã€‚
    *   **ç»“è®ºï¼š** å‚æ•°æ¨å¯¼é€»è¾‘ä¸ GEMM å®Œå…¨ä¸€è‡´ï¼Œåªæ˜¯ Shared Memory çš„è®¡ç®—å…¬å¼å˜äº†ï¼ˆéœ€è¦åŒ…å« Halo åŒºåŸŸï¼‰ã€‚

#### 2. FlashAttention (SDPA)
è¿™æ˜¯ç›®å‰æœ€ç«çš„ Compute-bound ä¼˜åŒ–æ¡ˆä¾‹ã€‚

*   **Tiling æ˜ å°„ï¼š**
    *   $Q, K, V$ çŸ©é˜µã€‚
    *   å¤–å±‚å¾ªç¯åˆ‡åˆ† $Q$ï¼ˆå—å¤§å° $B_r$ï¼‰ï¼Œå†…å±‚å¾ªç¯åŠ è½½ $K, V$ï¼ˆå—å¤§å° $B_c$ï¼‰ã€‚
*   **å¥—ç”¨æ–¹æ³•è®ºï¼š**
    *   **å®¹é‡çº¦æŸï¼ˆæœ€å…³é”®ï¼‰ï¼š** ä¸ºäº†é¿å… HBM è®¿é—®ï¼Œ$K, V$ çš„ Tile å¿…é¡»å¸¸é©» SRAMï¼ˆShared Memoryï¼‰ã€‚
        $$ B_c \times d \times \text{bytes} \le \text{SMem\_Size} $$
        è¿™æ˜¯å†³å®š $B_c$ï¼ˆKV block sizeï¼‰çš„ç¡¬æ€§æ¡ä»¶ã€‚
    *   **å¯„å­˜å™¨çº¦æŸï¼š** æ¯ä¸ªçº¿ç¨‹éœ€è¦ç»´æŠ¤ $O$ï¼ˆOutputï¼‰å’Œ $l, m$ï¼ˆç»Ÿè®¡é‡ï¼‰çš„ç´¯åŠ å™¨ã€‚å¦‚æœ $d$ï¼ˆhead dimensionï¼‰å¾ˆå¤§ï¼ˆå¦‚ 128 æˆ– 256ï¼‰ï¼Œå¯„å­˜å™¨ä¼šæº¢å‡ºï¼Œé™åˆ¶äº† $B_r$ï¼ˆQuery block sizeï¼‰ã€‚
    *   **è½¯ä»¶æµæ°´ï¼š** åŒæ ·éœ€è¦ Prefetch ä¸‹ä¸€å— $K, V$ åˆ°å¯„å­˜å™¨/Sharedï¼Œä»¥éšè— Softmax å’Œ Matmul çš„è®¡ç®—å»¶è¿Ÿã€‚

---

### ä¸‰ã€ å¥—ç”¨åˆ° Memory-Bound Kernelï¼ˆè®¿å­˜å¯†é›†å‹ï¼‰

è¿™ç±» Kernelï¼ˆå¦‚ **Element-wise Add, LayerNorm, Softmax, Reduction**ï¼‰çš„ç®—æœ¯å¼ºåº¦ï¼ˆArithmetic Intensityï¼‰é€šå¸¸å¾ˆä½ä¸”å›ºå®šï¼ˆæ— æ³•é€šè¿‡ Tiling å¢åŠ å¤ç”¨ï¼‰ã€‚

**æ­¤æ—¶æ–¹æ³•è®ºçš„ç›®æ ‡å‘ç”Ÿå˜åŒ–ï¼šä»â€œæœ€å¤§åŒ–è®¡ç®—åˆ©ç”¨ç‡â€å˜ä¸ºâ€œæœ€å¤§åŒ–å†…å­˜å¸¦å®½åˆ©ç”¨ç‡â€ã€‚**

#### 1. å‘é‡åŠ æ³• / Activation (Element-wise)
*   **ç‰¹ç‚¹ï¼š** è¯» 1 ä¸ªæ•°ï¼Œç®— 1 æ¬¡ï¼Œå†™ 1 ä¸ªæ•°ã€‚$I \approx 1/2$ (FLOPs/Byte)ï¼Œè¿œä½äºä¸´ç•Œç‚¹ã€‚
*   **å¥—ç”¨æ–¹æ³•è®ºï¼š**
    *   **å®¹é‡çº¦æŸï¼š** Shared Memory é€šå¸¸ä¸ç”¨ï¼ˆç›´æ¥ Reg to Globalï¼‰ï¼Œä½†å¯„å­˜å™¨é™åˆ¶äº†**å±•å¼€å› å­ï¼ˆUnroll Factorï¼‰**ã€‚
    *   **å»¶è¿Ÿçº¦æŸï¼ˆæ ¸å¿ƒï¼‰ï¼š** ä¸ºäº†è·‘æ»¡å¸¦å®½ï¼Œå¿…é¡»æœ‰è¶³å¤Ÿçš„ **In-flight Memory Requests**ï¼ˆåœ¨é€”å†…å­˜è¯·æ±‚ï¼‰ã€‚
    *   **æ¨ç®—å‚æ•°ï¼š** æˆ‘ä»¬ä¸æ±‚ $M/N/K$ï¼Œè€Œæ˜¯æ±‚ **æ¯ä¸ªçº¿ç¨‹å¤„ç†çš„å…ƒç´ ä¸ªæ•° (ItemsPerThread)** å’Œ **å‘é‡åŒ–åŠ è½½å®½åº¦ (VectorWidth)**ã€‚
        *   å…¬å¼ï¼š
            $$ \text{Active\_Warps} \times \text{ItemsPerThread} \times \text{VectorWidth} \ge \frac{\text{Latency} \times \text{Bandwidth}}{\text{Frequency}} $$
        *   è¿™å‘Šè¯‰æˆ‘ä»¬ï¼šå¦‚æœ Latency å¾ˆé«˜ï¼Œè€Œ Active Warps å—é™äºå¯„å­˜å™¨æ•°é‡ä¸Šä¸å»ï¼Œä½ å°±å¿…é¡»å¢åŠ  **ItemsPerThread**ï¼ˆå³ ILPï¼ŒInstruction Level Parallelismï¼‰ï¼Œè®©æ¯ä¸ªçº¿ç¨‹ä¸€æ¬¡å‘ 4 ä¸ªã€8 ä¸ª load æŒ‡ä»¤ï¼Œæ‰èƒ½å¡«æ»¡å†…å­˜æµæ°´çº¿ã€‚

#### 2. Reduction / Softmax / LayerNorm
*   **ç‰¹ç‚¹ï¼š** éœ€è¦åœ¨ Block å†…éƒ¨è¿›è¡Œæ•°æ®äº¤æ¢ï¼ˆShuffle æˆ– Shared Mem Reductionï¼‰ã€‚
*   **å¥—ç”¨æ–¹æ³•è®ºï¼š**
    *   **å®¹é‡çº¦æŸï¼š** Tile Sizeï¼ˆé€šå¸¸æ˜¯ 1Dï¼‰ä¸èƒ½è¶…è¿‡ Shared Memory å¤§å°ã€‚
    *   **å¸¦å®½/å»¶è¿Ÿï¼š**
        *   å…³é”®å‚æ•°æ˜¯ **Block Sizeï¼ˆçº¿ç¨‹æ•°ï¼‰** å’Œ **Grid Size**ã€‚
        *   å¦‚æœæ˜¯å¤šçº§ Reductionï¼ˆBlock Reduce -> Grid Reduceï¼‰ï¼Œç¬¬ä¸€çº§ Kernel æ˜¯ Memory-boundã€‚
        *   æ¨ç®—ï¼šæ¯ä¸ª Block å¤„ç†çš„æ•°æ®é‡åº”è¶³å¤Ÿå¤§ï¼Œä»¥åˆ†æ‘Šå¯åŠ¨ Overheadï¼Œä½†åˆè¦è¶³å¤Ÿå°ä»¥ fit è¿› Shared Memory è¿›è¡Œå¿«é€Ÿå½’çº¦ã€‚
    *   **Reuse åˆ†æï¼š** æ¯”å¦‚ LayerNormï¼Œéœ€è¦è¯» $x$ï¼Œç®— mean/varï¼Œå†è¯» $x$ ç®— normã€‚
        *   ä¼˜åŒ–ç‚¹ï¼šèƒ½å¦æŠŠ $x$ å­˜åœ¨å¯„å­˜å™¨é‡Œå¤ç”¨ï¼Œé¿å…è¯»ä¸¤æ¬¡ Global Memoryï¼Ÿ
        *   æ¨ç®—ï¼š$ \text{Regs\_per\_Thread} \ge \text{Elements\_per\_Thread} $ã€‚å¦‚æœå¯„å­˜å™¨å¤Ÿï¼Œå°±åœ¨å¯„å­˜å™¨é‡Œåšï¼›å¦‚æœä¸å¤Ÿï¼Œåªèƒ½è¯»ä¸¤æ¬¡ Globalï¼ˆé€€åŒ–å¸¦å®½ï¼‰ã€‚

---

### å››ã€ æ€»ç»“ï¼šå¦‚ä½•è¿ç§»è¿™å¥—â€œå‚æ•°æ¨ç®—â€é€»è¾‘

å½“ä½ é¢å¯¹ä¸€ä¸ªæ–°çš„ Kernel æ—¶ï¼Œè¯·æŒ‰ä»¥ä¸‹è¡¨æ ¼è¿›è¡Œâ€œå®Œå½¢å¡«ç©ºâ€ï¼š

| æ­¥éª¤ | Matmul / Compute-bound | Memory-bound (Element-wise/Reduction) |
| :--- | :--- | :--- |
| **1. ç¡®å®šç“¶é¢ˆèµ„æº** | TensorCore / FMA | Global Memory Bandwidth |
| **2. æ ¸å¿ƒå˜é‡** | Tile Size ($B_M, B_N, B_K$) | ItemsPerThread, VectorWidth, BlockSize |
| **3. å®¹é‡çº¦æŸ** | $A_{tile} + B_{tile} \le \text{SMem}$<br>Accumulators $\le \text{Regs}$ | Input Chunk $\le \text{SMem}$ (For reduction)<br>Temp Variables $\le \text{Regs}$ |
| **4. å¼ºåº¦/å¸¦å®½æ£€æŸ¥** | $\frac{FLOPS}{Bytes} > \text{Peak\_Ratio}$ ?<br>è‹¥å¦ï¼Œå¢å¤§ Tile | æ— æ³•æ”¹å˜å¼ºåº¦ã€‚<br>ç¡®ä¿ Load æŒ‡ä»¤å¤Ÿå¤šä»¥å¡«æ»¡ Busã€‚ |
| **5. å»¶è¿Ÿéšè—** | Pipeline Stages (Prefetch)<br>Double Buffering | Unrolling (ILP)<br>Batch Loading (Vectorized Load) |
| **6. è¾“å‡ºå‚æ•°** | æœ€ä½³ $B_M, B_N, B_K$, Stage æ•° | æœ€ä½³ Grid Size, Block Size, Unroll å› å­ |

### ç»“è®º
**è¿™å¥—æ–¹æ³•è®ºæ˜¯é«˜æ€§èƒ½è®¡ç®—çš„â€œç‰©ç†å­¦â€**ã€‚
åªè¦ä½ æ˜¯åœ¨é€šè¿‡æ˜¾å¼çš„å†…å­˜å±‚çº§ï¼ˆGlobal/Shared/Regï¼‰æ¥ç®¡ç†æ•°æ®æµåŠ¨ï¼Œè¿™å¥—åŸºäº**å¸¦å®½-å»¶è¿Ÿç§¯ï¼ˆBandwidth-Delay Productï¼‰**å’Œ**èµ„æºå®¹é‡ï¼ˆCapacityï¼‰**çš„æ¨ç®—é€»è¾‘å°±æ°¸è¿œé€‚ç”¨ã€‚

åŒºåˆ«ä»…åœ¨äºï¼š
*   **è®¡ç®—å¯†é›†å‹**æ˜¯åœ¨è§£ä¸€ä¸ª**â€œå¦‚ä½•åˆ‡å—ä»¥æœ€å¤§åŒ–é‡ç”¨â€**çš„å‡ ä½•é¢˜ã€‚
*   **è®¿å­˜å¯†é›†å‹**æ˜¯åœ¨è§£ä¸€ä¸ª**â€œå¦‚ä½•è°ƒåº¦æŒ‡ä»¤ä»¥å¡æ»¡ç®¡é“â€**çš„æ’é˜Ÿè®ºé¢˜ã€‚