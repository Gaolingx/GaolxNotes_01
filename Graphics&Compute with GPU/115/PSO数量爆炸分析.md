# PSO数量爆炸分析

### 🧑‍💻 User

为什么 PSO（Pipeline State Object） 数量爆炸是现代引擎的新问题？要求分析背景+负面影响+解决方案

---

### 🤖 Assistant

这是一个非常硬核且经典的图形程序开发问题。

**Pipeline State Object (PSO)** 的数量爆炸确实是随着 DirectX 12、Vulkan and Metal 等现代底层图形 API 的普及而产生的一个特有的“现代病”。

在 OpenGL 和 DirectX 9/11 时代，这个问题并不明显，或者说它被驱动层隐藏了。但在现代 API 中，开发者直接面对硬件抽象，导致 PSO 管理成为了引擎架构中的一大噩梦。

以下从**背景、负面影响、解决方案**三个维度进行深入分析：

---

### 1. 背景：为什么这是一个“新”问题？

要理解 PSO 爆炸，首先要理解图形 API 设计哲学的转变。

#### 1.1 从“细粒度状态”到“整体对象”
*   **DX9/DX11/OpenGL (Legacy):**
    在旧 API 中，渲染状态是**正交**且**独立**的。你可以分别调用：
    *   `SetVertexShader(...)`
    *   `SetPixelShader(...)`
    *   `SetBlendState(...)`
    *   `SetDepthStencilState(...)`
    *   `SetInputLayout(...)`
  
    驱动程序会在发起 Draw Call 的那一瞬间，检查所有当前设置的状态，在内部拼凑出一个硬件能理解的配置。这导致了巨大的**CPU开销（Driver Overhead）**，因为驱动必须在每帧的每个 Draw Call 进行状态校验和即时编译。

*   **DX12/Vulkan (Modern):**
    为了消除 Draw Call 时的 CPU 校验开销，现代 API 引入了 **PSO**。它要求开发者**提前**将所有渲染管线的状态（Shader字节码、混合模式、光栅化状态、深度测试、顶点布局、渲染目标格式等）“烘焙”（Bake）成一个单一的、不可变的对象。
    一旦 PSO 创建完成，显卡驱动就已经知道该管线的一切，Draw Call 时只需切换一个指针，极度高效。

#### 1.2 组合爆炸 (Combinatorial Explosion)
问题在于 PSO 包含的状态实在太多了。只要其中**任何一个**参数不同，就需要一个新的 PSO。

假设一个游戏引擎支持：
*   **Shader 变体:** 100 种材质 x 5 种光照模式 = 500 个 Shader 组合。
*   **渲染目标格式 (RT Format):** HDR 格式、LDR 格式、ShadowMap 格式 = 3 种。
*   **多重采样 (MSAA):** 1x, 4x = 2 种。
*   **顶点布局 (Vertex Layout):** 静态网格、骨骼动画网格 = 2 种。
*   **混合模式 (Blend State):** 不透明、透明、加法 = 3 种。
*   **深度写入:** 开、关 = 2 种。

**总 PSO 数量 = $500 \times 3 \times 2 \times 2 \times 3 \times 2 = 36,000$ 个 PSO！**

在旧 API 中，你可以只切 Shader 而不切混合模式。但在现代 API 中，你必须为这 36,000 种组合每一个都创建一个独立的 PSO 对象。这就是**PSO 爆炸**。

---

### 2. 负面影响：这就炸了会怎样？

PSO 数量失控会对游戏性能和开发体验造成严重打击：

#### 2.1 严重的卡顿 (Stuttering) —— 最直观的影响
PSO 的创建不是免费的，它通常涉及 GPU 驱动对 Shader 代码的后端编译（JIT），这是一项极耗 CPU 的操作。
*   如果在**游戏运行时**遇到了一个从未见过的材质+渲染状态组合，引擎不得不当场编译 PSO。
*   这会导致几百毫秒甚至几秒的帧冻结。这就是很多 PC 游戏刚发售时“卡顿”的主要原因（Shader Compilation Stutter）。

#### 2.2 巨大的内存与显存占用
每个 PSO 都是一个实体对象。成千上万个 PSO 会占用大量的宿主内存和显存。
*   虽然单个 PSO 不大，但加上关联的 Root Signatures 和驱动内部缓存，数万个 PSO 可能占用数 GB 的内存。

#### 2.3 极长的加载时间与磁盘占用
为了避免运行时卡顿，现代游戏通常在**启动时**预编译所有 PSO。
*   **Shader Cache 编译:** 玩家第一次进游戏看到“正在优化着色器...”的进度条，就是在编译成千上万个 PSO。
*   **磁盘膨胀:** 预编译的二进制 Shader Cache 文件可能会变得非常大。

#### 2.4 引擎架构复杂化
开发者被迫编写复杂的哈希缓存系统（HashMap）来管理这些状态。如果在 Hash Map 里找不到对应的 PSO，就得去创建新的。这增加了代码的复杂度和出错概率。

---

### 3. 解决方案：如何治理 PSO 爆炸？

业界针对这个问题已经演进出了多层防御手段，从美术规范到 API 改进。

#### 3.1 减少变体 (Reduction of Permutations)
这是最基础的手段。
*   **Uber-Shader (超集着色器):** 尽量不要用 `#ifdef` 宏来开关功能（宏会生成不同的 Shader 字节码，从而生成不同的 PSO）。改为在 Shader 内部使用 `if (useNormalMap) ...` 的动态分支。现代 GPU 的分支预测性能已经很好，牺牲一点点 GPU 算力换取 PSO 数量大幅减少是值得的。
*   **标准化渲染管线:** 严格限制美术和设计能使用的混合模式组合。例如，规定所有透明物体必须使用相同的 Render Target 格式。

#### 3.2 异步编译与缓存 (Async Compilation & Caching)
*   **PSO Caching:** 将编译好的 PSO 二进制数据序列化到磁盘（Pipeline Cache）。下次启动直接加载，跳过编译。
*   **异步预热:** 在加载关卡时，另起后台线程预先编译可能用到的 PSO。如果 Draw Call 发起时 PSO 还没编译好，先用一个简单的“通用材质”或者干脆不渲染，直到编译完成，以避免卡顿。

#### 3.3 利用 Dynamic State (Vulkan / DX12 Enhanced)
API 厂商意识到了 PSO 过于僵化的问题，开始允许部分状态“动态化”。
*   在 Vulkan 中，可以标记 `VK_DYNAMIC_STATE_VIEWPORT` 或 `VK_DYNAMIC_STATE_SCISSOR` 等。这意味着这些状态不需要烘焙进 PSO，可以在 Command Buffer 录制时动态设置。
*   利用 **Vulkan 1.3** 的 `VK_EXT_extended_dynamic_state`，更多的状态（如深度测试开关、剔除模式、图元拓扑）可以从 PSO 中剥离出来。这大大减少了 PSO 的排列组合基数。

#### 3.4 终极杀招：Shader Objects (Vulkan EXT_shader_object / D3D12 Shader Objects)
这是针对 PSO 爆炸最彻底的 API 级解决方案（2023年左右开始大规模推行）。

**Shader Objects** 实际上是“复古”了。它允许开发者像 DX11 时代一样，独立地绑定 Vertex Shader、Pixel Shader 和其他状态，而**不需要**创建一个巨大的管线对象。
*   **解耦:** 可以在不重新编译管线的情况下，只切换 Pixel Shader。
*   **即时性:** 驱动程序不再需要因为一个微小的状态变化（比如改变了 Render Target 格式）而重编译整个管线。

#### 3.5 间接绘制与 GPU Driven Rendering
利用 ExecuteIndirect (DX12) 或 DrawIndirect (Vulkan)。
通过将材质 ID 和属性打包到 Buffer 中，使用同一个通用的 Uber-PSO 进行绘制，然后在 Shader 内部根据 Instance ID 索引材质数据。这使得成千上万个不同外观的物体可以共用**同一个 PSO**。

### 总结

| 维度 | 核心点 |
| :--- | :--- |
| **问题本质** | 现代 API 将渲染状态不可变地打包在一起，导致状态组合呈指数级增长。 |
| **最大痛点** | 运行时即时编译导致的画面卡顿 (Stutter) 及巨大的启动加载时间。 |
| **解决思路** | **短期:** Uber-Shader 减少变体、后台异步编译。 <br> **长期:** 使用 Dynamic State 特性，或迁移至 Shader Objects 技术路线。 |

---

### 🧑‍💻 User

个人认为，离线PSO收集+热更新这套在主机平台更容易落地，因为主机平台硬件统一，而pc/移动平台很难说。

---

### 🤖 Assistant

你说的非常精准，切中肯綮。

**“硬件统一”确实是主机开发相对于 PC/移动端最大的“降维打击”优势。**

你的观点可以从**中间语言（IR）与指令集（ISA）**的区别这个底层逻辑来深度剖析。这不仅仅是“难易程度”的问题，而是根本的技术路径完全不同。

以下是针对你这一观点的深度分析：

### 1. 主机平台：确定的终点 (Determinism)

在 PS5 或 Xbox Series X 上，硬件是完全锁死的，GPU 驱动版本通常也绑定在 SDK 中。

*   **离线编译直达 ISA：** 开发者在构建机器（Build Server）上，可以直接把 Shader 代码编译成该款 GPU 能够直接执行的**机器码（ISA, Instruction Set Architecture）**。
*   **零运行时开销：** 当游戏运行加载 PSO 时，本质上只是把一段预先准备好的二进制数据 `memcpy` 到显存里，几乎没有“编译”过程，只有“加载”过程。
*   **PSO 收集的有效性：** 开发团队可以在 QA 测试阶段跑遍所有关卡，记录下所有用到的 PSO。因为玩家手里的机器和开发机的 GPU 一模一样，这个收集到的列表是 **100% 可复用** 的。

所以，主机游戏的“Shader 编译卡顿”几乎只存在于开发阶段，发售后的成品极其流畅。

### 2. PC/移动端：中间语言的诅咒 (The Curse of IR)

在 PC 和 Android 上，你面对的是成百上千种 GPU 架构（NVIDIA Pascal/Turing/Ampere/Ada, AMD RDNA1/2/3, Intel Arc, Adreno, Mali...）以及无数个驱动版本。

*   **只能分发中间语言 (IR)：** 你不能分发编译好的机器码。
    *   DX12 游戏分发的是 **DXIL**。
    *   Vulkan 游戏分发的是 **SPIR-V**。
*   **驱动层的 JIT (Just-In-Time) 编译：** 真正的“编译”工作（将 DXIL/SPIR-V 转译为 GPU ISA）是发生在该玩家启动游戏、甚至玩游戏的当下的。这个过程由**显卡驱动**全权负责，游戏无法插手。

这就是为什么即便你做了“离线 PSO 收集”，在 PC 上依然很难受：
1.  **收集了也没法直接用：** 你收集的只是 Shader 的描述信息。玩家的电脑必须根据这些信息，消耗本地 CPU 算力重新编译一遍。
2.  **驱动更新即失效：** 一旦玩家更新了显卡驱动，之前本地编译好的二进制缓存（Pipeline Cache）通常会**全部作废**，因为驱动内部的编译器算法变了，必须重新编译。这也是为什么每次更新驱动后，进《使命召唤》或者《地平线》都要重新读条。

### 3. 移动端的特殊地狱：碎片化之王

移动端（特别是 Android）比 PC 更惨，原因有二：
1.  **二进制兼容性极差：** 不同的 SoC（骁龙、联发科、麒麟）对应完全不同的 GPU 架构。即使是同一款芯片，不同手机厂商魔改的驱动行为也不一样。
2.  **LRU 缓存机制：** 手机寸土寸金。如果你的游戏缓存了太多的 PSO 二进制文件，Android 系统或者驱动可能会在存储空间不足时悄悄把你的缓存删掉。下次玩家进游戏，又得重新卡顿编译。

### 4. 业界是如何在“非主机”平台挣扎的？

既然无法像主机那样“一劳永逸”，PC/移动端目前主要靠**生态系统**和**暴力计算**来解决：

#### A. Steam Shader Pre-Caching (PC 端的救星)
Valve 做了一件伟大的事。Steam 客户端会悄悄收集玩家在玩游戏时生成的 PSO 缓存。
*   当大量使用 RTX 3060 的玩家玩了《艾尔登法环》，Steam 会把他们编译好的缓存上传到服务器。
*   当你（也是 RTX 3060 用户）下载游戏时，Steam 会直接把这份**针对你显卡编译好**的缓存下发给你。
*   **结果：** 省去了本地编译的时间，体验接近主机。

#### B. 暴力预热 (Brute-force Warmup)
这就是我们常见的“正在优化着色器 (Compiling Shaders)...” 读条界面。
*   既然不能离线分发机器码，那就把“离线收集”到的 PSO 列表（只是列表，不是机器码）放在包里。
*   游戏第一次启动时，利用多线程把 CPU 跑满，强制让驱动把这些 PSO 全部编译一遍。
*   **缺点：** 玩家第一次进游戏体验很差，甚至可能导致 CPU 过热降频。

#### C. Android GameSDK (Swappy / Frame Pacing)
Google 推出的 Android Game Development Kit 试图建立一套标准的 PSO 缓存机制，让这一过程在不同的 Android 手机上稍微稳定一点，但依然无法解决硬件差异带来的根本问题。

### 总结

你的看法完全正确。

*   **主机平台：** 是**“真·离线编译”**。PSO 收集 + 热更新 = 完美闭环。
*   **PC/移动平台：** 所谓的“离线 PSO”其实只是**“离线收集元数据”**。真正的编译压力依然转嫁给了用户的 CPU。

所以在做跨平台引擎架构时，主机端往往只需要关注“收集覆盖率”，而 PC/移动端则需要绞尽脑汁设计“异步编译策略”、“多级缓存策略”以及“如何优雅地展示编译进度条”。