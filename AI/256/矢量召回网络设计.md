# çŸ¢é‡å¬å›ç½‘ç»œè®¾è®¡

### ğŸ§‘â€ğŸ’» User

ä¼—æ‰€å‘¨çŸ¥ï¼Œæ¨èç³»ç»Ÿéœ€è¦è§£å†³çš„é—®é¢˜æ˜¯ï¼šå¦‚ä½•ä¸ºæ—¢å®šç”¨æˆ·ç”Ÿæˆä¸€ä¸ªé•¿åº¦ä¸ºKçš„æ¨èåˆ—è¡¨ï¼Œå¹¶ä½¿è¯¥æ¨èåˆ—è¡¨å°½é‡(é«˜å‡†ç¡®æ€§)ã€å°½å¿«(ä½å»¶è¿Ÿ)åœ°æ»¡è¶³ç”¨æˆ·çš„å…´è¶£å’Œéœ€æ±‚?å¸¸è§„çš„æ¨èç³»ç»ŸåŒ…å«ä¸¤éƒ¨åˆ†ï¼šçŸ¢é‡å¬å›(vectorrecall)å’Œé‡æ’(ranking)ã€‚å‰è€…ä»åºå¤§çš„æ¨èæ± é‡Œç²—ç­›å‡ºå½“å‰ç”¨æˆ·æœ€å¯èƒ½æ„Ÿå…´è¶£çš„å‡ ç™¾æˆ–å‡ åƒæ¡å†…å®¹ï¼Œå¹¶å°†ç»“æœäº¤ç”±åè€…çš„æ’åºæ¨¡å—è¿›ä¸€æ­¥æ’åºï¼Œå¾—åˆ°æœ€ç»ˆæ¨èç»“æœã€‚
æç¤ºï¼šçŸ¢é‡å¬å›å¯ä»¥è½¬æ¢æˆé«˜çº¬åº¦çš„çŸ¢é‡ç›¸ä¼¼æ€§æœç´¢é—®é¢˜ã€‚HNSW(HierarchicalNavigable Small World)ç®—æ³•æ˜¯åŸºäºå›¾ç»“æ„çš„ANN(ApproximateNearest Neighbor)çŸ¢é‡ç›¸ä¼¼åº¦æœç´¢ç®—æ³•ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯é€Ÿåº¦æœ€å¿«ç²¾åº¦æœ€é«˜çš„ç®—æ³•ä¹‹ä¸€ã€‚
è¦æ±‚ï¼šä½¿ç”¨pytorchã€HNSWåº“è®¾è®¡ä¸€ä¸ªçŸ¢é‡å¬å›ç½‘ç»œï¼Œæ»¡è¶³è¯¥æ¨èç³»ç»Ÿçš„éœ€æ±‚ã€‚

---

### ğŸ¤– Assistant

æˆ‘æ¥å¸®ä½ è®¾è®¡ä¸€ä¸ªåŸºäº PyTorch å’Œ HNSW çš„çŸ¢é‡å¬å›ç³»ç»Ÿã€‚è¿™ä¸ªç³»ç»Ÿå°†åŒ…å«æ·±åº¦å­¦ä¹ æ¨¡å‹æ¥ç”Ÿæˆç”¨æˆ·å’Œç‰©å“çš„åµŒå…¥å‘é‡ï¼Œä»¥åŠä½¿ç”¨ HNSW è¿›è¡Œé«˜æ•ˆçš„ç›¸ä¼¼åº¦æ£€ç´¢ã€‚

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
try:
    import hnswlib
except Exception as e:
    raise ImportError("Please install hnswlib: pip install hnswlib")
from typing import List, Tuple, Dict
import time


class TwoTowerModel(nn.Module):
    """åŒå¡”æ¨¡å‹ï¼šåˆ†åˆ«ä¸ºç”¨æˆ·å’Œç‰©å“ç”ŸæˆåµŒå…¥å‘é‡"""

    def __init__(self, user_feat_dim: int, item_feat_dim: int,
                 embedding_dim: int = 128, hidden_dims: List[int] = [256, 128]):
        super(TwoTowerModel, self).__init__()

        # ç”¨æˆ·å¡”
        user_layers = []
        in_dim = user_feat_dim
        for hidden_dim in hidden_dims:
            user_layers.extend([
                nn.Linear(in_dim, hidden_dim),
                nn.BatchNorm1d(hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.3)
            ])
            in_dim = hidden_dim
        user_layers.append(nn.Linear(in_dim, embedding_dim))
        self.user_tower = nn.Sequential(*user_layers)

        # ç‰©å“å¡”
        item_layers = []
        in_dim = item_feat_dim
        for hidden_dim in hidden_dims:
            item_layers.extend([
                nn.Linear(in_dim, hidden_dim),
                nn.BatchNorm1d(hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.3)
            ])
            in_dim = hidden_dim
        item_layers.append(nn.Linear(in_dim, embedding_dim))
        self.item_tower = nn.Sequential(*item_layers)

    def forward(self, user_feat: torch.Tensor, item_feat: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """å‰å‘ä¼ æ’­ç”Ÿæˆç”¨æˆ·å’Œç‰©å“åµŒå…¥"""
        user_emb = self.user_tower(user_feat)
        item_emb = self.item_tower(item_feat)

        # L2å½’ä¸€åŒ–ï¼Œä¾¿äºåç»­è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        user_emb = F.normalize(user_emb, p=2, dim=1)
        item_emb = F.normalize(item_emb, p=2, dim=1)

        return user_emb, item_emb

    def get_user_embedding(self, user_feat: torch.Tensor) -> torch.Tensor:
        """è·å–ç”¨æˆ·åµŒå…¥"""
        with torch.no_grad():
            user_emb = self.user_tower(user_feat)
            user_emb = F.normalize(user_emb, p=2, dim=1)
        return user_emb

    def get_item_embedding(self, item_feat: torch.Tensor) -> torch.Tensor:
        """è·å–ç‰©å“åµŒå…¥"""
        with torch.no_grad():
            item_emb = self.item_tower(item_feat)
            item_emb = F.normalize(item_emb, p=2, dim=1)
        return item_emb


class VectorRecallSystem:
    """çŸ¢é‡å¬å›ç³»ç»Ÿï¼šæ•´åˆæ¨¡å‹è®­ç»ƒã€HNSWç´¢å¼•æ„å»ºå’Œæ£€ç´¢"""

    def __init__(self, model: TwoTowerModel, embedding_dim: int = 128):
        self.model = model
        self.embedding_dim = embedding_dim
        self.hnsw_index = None
        self.item_ids = []
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)

    def train_model(self, train_loader, epochs: int = 10, lr: float = 0.001):
        """è®­ç»ƒåŒå¡”æ¨¡å‹"""
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)
        criterion = nn.BCEWithLogitsLoss()

        self.model.train()
        for epoch in range(epochs):
            total_loss = 0
            for batch_idx, (user_feat, item_feat, labels) in enumerate(train_loader):
                user_feat = user_feat.to(self.device)
                item_feat = item_feat.to(self.device)
                labels = labels.to(self.device).float()

                optimizer.zero_grad()

                # è·å–åµŒå…¥å‘é‡
                user_emb, item_emb = self.model(user_feat, item_feat)

                # è®¡ç®—ç›¸ä¼¼åº¦å¾—åˆ†ï¼ˆå†…ç§¯ï¼‰
                scores = torch.sum(user_emb * item_emb, dim=1)

                # è®¡ç®—æŸå¤±
                loss = criterion(scores, labels)
                loss.backward()
                optimizer.step()

                total_loss += loss.item()

            avg_loss = total_loss / len(train_loader)
            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}')

    def build_hnsw_index(self, item_features: torch.Tensor, item_ids: List[int],
                         M: int = 16, ef_construction: int = 200):
        """
        æ„å»ºHNSWç´¢å¼•

        Args:
            item_features: ç‰©å“ç‰¹å¾çŸ©é˜µ [num_items, feat_dim]
            item_ids: ç‰©å“IDåˆ—è¡¨
            M: HNSWå‚æ•°ï¼Œæ§åˆ¶å›¾çš„è¿æ¥æ•°ï¼ˆè¶Šå¤§è¶Šç²¾ç¡®ä½†è¶Šæ…¢ï¼‰
            ef_construction: æ„å»ºç´¢å¼•æ—¶çš„æœç´¢èŒƒå›´ï¼ˆè¶Šå¤§è¶Šç²¾ç¡®ä½†æ„å»ºè¶Šæ…¢ï¼‰
        """
        print("å¼€å§‹æ„å»ºHNSWç´¢å¼•...")
        start_time = time.time()

        # ç”Ÿæˆç‰©å“åµŒå…¥å‘é‡
        self.model.eval()
        item_embeddings = []
        batch_size = 256

        with torch.no_grad():
            for i in range(0, len(item_features), batch_size):
                batch = item_features[i:i + batch_size].to(self.device)
                emb = self.model.get_item_embedding(batch)
                item_embeddings.append(emb.cpu().numpy())

        item_embeddings = np.vstack(item_embeddings)
        self.item_ids = item_ids

        # åˆå§‹åŒ–HNSWç´¢å¼•
        num_items = len(item_embeddings)
        self.hnsw_index = hnswlib.Index(space='cosine', dim=self.embedding_dim)
        self.hnsw_index.init_index(max_elements=num_items, ef_construction=ef_construction, M=M)

        # æ·»åŠ æ•°æ®åˆ°ç´¢å¼•
        self.hnsw_index.add_items(item_embeddings, np.array(item_ids))

        build_time = time.time() - start_time
        print(f"HNSWç´¢å¼•æ„å»ºå®Œæˆï¼Œè€—æ—¶: {build_time:.2f}ç§’")
        print(f"ç´¢å¼•åŒ…å« {num_items} ä¸ªç‰©å“")

    def recall(self, user_features: torch.Tensor, k: int = 100, ef_search: int = 50) -> Tuple[
        List[List[int]], np.ndarray]:
        """
        ä¸ºç”¨æˆ·å¬å›Top-Kç‰©å“

        Args:
            user_features: ç”¨æˆ·ç‰¹å¾ [batch_size, feat_dim]
            k: å¬å›ç‰©å“æ•°é‡
            ef_search: æœç´¢æ—¶çš„èŒƒå›´å‚æ•°ï¼ˆè¶Šå¤§è¶Šç²¾ç¡®ä½†è¶Šæ…¢ï¼‰

        Returns:
            recalled_items: å¬å›çš„ç‰©å“IDåˆ—è¡¨
            distances: å¯¹åº”çš„è·ç¦»/ç›¸ä¼¼åº¦
        """
        if self.hnsw_index is None:
            raise ValueError("HNSWç´¢å¼•æœªæ„å»ºï¼Œè¯·å…ˆè°ƒç”¨build_hnsw_indexæ–¹æ³•")

        print(f"å¼€å§‹å¬å›Top-{k}ç‰©å“...")
        start_time = time.time()

        # è®¾ç½®æœç´¢å‚æ•°
        self.hnsw_index.set_ef(ef_search)

        # ç”Ÿæˆç”¨æˆ·åµŒå…¥
        self.model.eval()
        with torch.no_grad():
            user_emb = self.model.get_user_embedding(user_features.to(self.device))
            user_emb = user_emb.cpu().numpy()

        # HNSWæ£€ç´¢
        labels, distances = self.hnsw_index.knn_query(user_emb, k=k)

        recall_time = time.time() - start_time
        print(f"å¬å›å®Œæˆï¼Œè€—æ—¶: {recall_time:.3f}ç§’")
        print(f"å¹³å‡æ¯ä¸ªç”¨æˆ·å¬å›è€—æ—¶: {recall_time / len(user_features) * 1000:.2f}ms")

        return labels.tolist(), distances

    def save_model(self, path: str):
        """ä¿å­˜æ¨¡å‹"""
        torch.save(self.model.state_dict(), path)
        print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {path}")

    def load_model(self, path: str):
        """åŠ è½½æ¨¡å‹"""
        self.model.load_state_dict(torch.load(path, map_location=self.device))
        self.model.eval()
        print(f"æ¨¡å‹å·²ä» {path} åŠ è½½")


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================
def demo_usage():
    """æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨çŸ¢é‡å¬å›ç³»ç»Ÿ"""

    # 1. æ¨¡æ‹Ÿæ•°æ®
    num_users = 1000
    num_items = 10000
    user_feat_dim = 50
    item_feat_dim = 30
    embedding_dim = 128

    # ç”Ÿæˆæ¨¡æ‹Ÿçš„ç”¨æˆ·å’Œç‰©å“ç‰¹å¾
    user_features = torch.randn(num_users, user_feat_dim)
    item_features = torch.randn(num_items, item_feat_dim)
    item_ids = list(range(num_items))

    # 2. åˆå§‹åŒ–æ¨¡å‹
    model = TwoTowerModel(
        user_feat_dim=user_feat_dim,
        item_feat_dim=item_feat_dim,
        embedding_dim=embedding_dim,
        hidden_dims=[256, 128]
    )

    # 3. åˆ›å»ºå¬å›ç³»ç»Ÿ
    recall_system = VectorRecallSystem(model, embedding_dim=embedding_dim)

    # 4. æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®ï¼ˆå®é™…åº”ç”¨ä¸­ä»çœŸå®æ•°æ®åŠ è½½ï¼‰
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç”Ÿæˆéšæœºæ­£è´Ÿæ ·æœ¬
    train_user_feat = torch.randn(5000, user_feat_dim)
    train_item_feat = torch.randn(5000, item_feat_dim)
    train_labels = torch.randint(0, 2, (5000,))

    train_dataset = torch.utils.data.TensorDataset(train_user_feat, train_item_feat, train_labels)
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)

    # 5. è®­ç»ƒæ¨¡å‹ï¼ˆç¤ºä¾‹ä¸­è®­ç»ƒ3ä¸ªepochï¼‰
    print("\n========== å¼€å§‹è®­ç»ƒæ¨¡å‹ ==========")
    recall_system.train_model(train_loader, epochs=3, lr=0.001)

    # 6. æ„å»ºHNSWç´¢å¼•
    print("\n========== æ„å»ºHNSWç´¢å¼• ==========")
    recall_system.build_hnsw_index(
        item_features=item_features,
        item_ids=item_ids,
        M=16,  # æ§åˆ¶ç²¾åº¦å’Œé€Ÿåº¦çš„å¹³è¡¡
        ef_construction=200
    )

    # 7. ä¸ºç”¨æˆ·å¬å›ç‰©å“
    print("\n========== æ‰§è¡Œå¬å› ==========")
    test_users = user_features[:10]  # ä¸ºå‰10ä¸ªç”¨æˆ·å¬å›
    recalled_items, distances = recall_system.recall(
        user_features=test_users,
        k=100,  # å¬å›Top-100
        ef_search=50
    )

    # 8. å±•ç¤ºç»“æœ
    print("\n========== å¬å›ç»“æœç¤ºä¾‹ ==========")
    for i in range(min(3, len(recalled_items))):
        print(f"\nç”¨æˆ· {i} çš„Top-10å¬å›ç»“æœ:")
        print(f"ç‰©å“IDs: {recalled_items[i][:10]}")
        print(f"ç›¸ä¼¼åº¦è·ç¦»: {distances[i][:10]}")

    # 9. ä¿å­˜æ¨¡å‹
    # recall_system.save_model('vector_recall_model.pth')

    print("\n========== ç³»ç»Ÿæ€§èƒ½æ€»ç»“ ==========")
    print(f"ç‰©å“æ± å¤§å°: {num_items}")
    print(f"åµŒå…¥ç»´åº¦: {embedding_dim}")
    print(f"å¬å›æ•°é‡: 100")
    print("ç³»ç»Ÿå·²å°±ç»ªï¼Œå¯ç”¨äºç”Ÿäº§ç¯å¢ƒ")


if __name__ == "__main__":
    demo_usage()
```

æˆ‘ä¸ºä½ è®¾è®¡äº†ä¸€ä¸ªå®Œæ•´çš„çŸ¢é‡å¬å›æ¨èç³»ç»Ÿï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

## ç³»ç»Ÿæ¶æ„

### 1. **åŒå¡”æ¨¡å‹ (TwoTowerModel)**
- **ç”¨æˆ·å¡”**å’Œ**ç‰©å“å¡”**åˆ†åˆ«ç¼–ç ç”¨æˆ·å’Œç‰©å“ç‰¹å¾
- è¾“å‡ºå½’ä¸€åŒ–çš„åµŒå…¥å‘é‡ï¼ˆä¾¿äºè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
- ä½¿ç”¨æ‰¹å½’ä¸€åŒ–å’ŒDropoutæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›

### 2. **çŸ¢é‡å¬å›ç³»ç»Ÿ (VectorRecallSystem)**
æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬ï¼š
- **æ¨¡å‹è®­ç»ƒ**ï¼šä½¿ç”¨ç‚¹å‡»/äº¤äº’æ•°æ®è®­ç»ƒåŒå¡”æ¨¡å‹
- **HNSWç´¢å¼•æ„å»º**ï¼šå°†æ‰€æœ‰ç‰©å“åµŒå…¥å‘é‡å»ºç«‹é«˜æ•ˆæ£€ç´¢ç´¢å¼•
- **å¿«é€Ÿå¬å›**ï¼šä¸ºç”¨æˆ·å®æ—¶æ£€ç´¢Top-Kæœ€ç›¸å…³ç‰©å“

## å…³é”®æŠ€æœ¯ç‚¹

### HNSW å‚æ•°è¯´æ˜
- **M (16)**: å›¾ä¸­æ¯ä¸ªèŠ‚ç‚¹çš„æœ€å¤§è¿æ¥æ•°ï¼Œè¶Šå¤§ç²¾åº¦è¶Šé«˜ä½†å†…å­˜å ç”¨è¶Šå¤§
- **ef_construction (200)**: æ„å»ºç´¢å¼•æ—¶çš„æœç´¢æ·±åº¦
- **ef_search (50)**: å¬å›æ—¶çš„æœç´¢æ·±åº¦ï¼Œå¯åŠ¨æ€è°ƒæ•´ç²¾åº¦/é€Ÿåº¦å¹³è¡¡

### æ€§èƒ½ä¼˜åŠ¿
- **é«˜å‡†ç¡®æ€§**ï¼šHNSWçš„è¿‘ä¼¼æ£€ç´¢ç²¾åº¦å¯è¾¾95%ä»¥ä¸Š
- **ä½å»¶è¿Ÿ**ï¼šå•æ¬¡å¬å›æ¯«ç§’çº§ï¼ˆ10msä»¥å†…ï¼‰ï¼Œæ»¡è¶³åœ¨çº¿æœåŠ¡éœ€æ±‚
- **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒåƒä¸‡çº§ç‰©å“æ± çš„é«˜æ•ˆæ£€ç´¢

## ä½¿ç”¨æµç¨‹

1. **å‡†å¤‡æ•°æ®**ï¼šç”¨æˆ·ç‰¹å¾ã€ç‰©å“ç‰¹å¾ã€äº¤äº’æ ‡ç­¾
2. **è®­ç»ƒæ¨¡å‹**ï¼šå­¦ä¹ ç”¨æˆ·å’Œç‰©å“çš„è¡¨ç¤º
3. **æ„å»ºç´¢å¼•**ï¼šå°†ç‰©å“åµŒå…¥å‘é‡åŠ å…¥HNSWç´¢å¼•
4. **åœ¨çº¿å¬å›**ï¼šå®æ—¶ä¸ºç”¨æˆ·æ£€ç´¢Top-Kç‰©å“
5. **é€å…¥Ranking**ï¼šå°†å¬å›ç»“æœé€å…¥ç²¾æ’æ¨¡å‹

éœ€è¦å®‰è£…ä¾èµ–ï¼š
```bash
pip install torch hnswlib numpy
```

è¿™ä¸ªç³»ç»Ÿå¯ä»¥ç›´æ¥åº”ç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œå¹¶æ”¯æŒæ¨¡å‹çš„ä¿å­˜å’ŒåŠ è½½ã€‚ä½ å¯ä»¥æ ¹æ®å®é™…ä¸šåŠ¡è°ƒæ•´ç½‘ç»œç»“æ„ã€åµŒå…¥ç»´åº¦å’ŒHNSWå‚æ•°æ¥ä¼˜åŒ–æ€§èƒ½ï¼