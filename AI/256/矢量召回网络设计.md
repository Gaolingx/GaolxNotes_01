# çŸ¢é‡å¬å›ç½‘ç»œè®¾è®¡

### ğŸ§‘â€ğŸ’» User

ä¼—æ‰€å‘¨çŸ¥ï¼Œæ¨èç³»ç»Ÿéœ€è¦è§£å†³çš„é—®é¢˜æ˜¯ï¼šå¦‚ä½•ä¸ºæ—¢å®šç”¨æˆ·ç”Ÿæˆä¸€ä¸ªé•¿åº¦ä¸ºKçš„æ¨èåˆ—è¡¨ï¼Œå¹¶ä½¿è¯¥æ¨èåˆ—è¡¨å°½é‡(é«˜å‡†ç¡®æ€§)ã€å°½å¿«(ä½å»¶è¿Ÿ)åœ°æ»¡è¶³ç”¨æˆ·çš„å…´è¶£å’Œéœ€æ±‚?å¸¸è§„çš„æ¨èç³»ç»ŸåŒ…å«ä¸¤éƒ¨åˆ†ï¼šçŸ¢é‡å¬å›(vectorrecall)å’Œé‡æ’(ranking)ã€‚å‰è€…ä»åºå¤§çš„æ¨èæ± é‡Œç²—ç­›å‡ºå½“å‰ç”¨æˆ·æœ€å¯èƒ½æ„Ÿå…´è¶£çš„å‡ ç™¾æˆ–å‡ åƒæ¡å†…å®¹ï¼Œå¹¶å°†ç»“æœäº¤ç”±åè€…çš„æ’åºæ¨¡å—è¿›ä¸€æ­¥æ’åºï¼Œå¾—åˆ°æœ€ç»ˆæ¨èç»“æœã€‚
æç¤ºï¼šçŸ¢é‡å¬å›å¯ä»¥è½¬æ¢æˆé«˜çº¬åº¦çš„çŸ¢é‡ç›¸ä¼¼æ€§æœç´¢é—®é¢˜ã€‚HNSW(HierarchicalNavigable Small World)ç®—æ³•æ˜¯åŸºäºå›¾ç»“æ„çš„ANN(ApproximateNearest Neighbor)çŸ¢é‡ç›¸ä¼¼åº¦æœç´¢ç®—æ³•ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯é€Ÿåº¦æœ€å¿«ç²¾åº¦æœ€é«˜çš„ç®—æ³•ä¹‹ä¸€ã€‚
è¦æ±‚ï¼šä½¿ç”¨pytorchã€HNSWåº“è®¾è®¡ä¸€ä¸ªçŸ¢é‡å¬å›ç½‘ç»œï¼Œæ»¡è¶³è¯¥æ¨èç³»ç»Ÿçš„éœ€æ±‚ã€‚

---

### ğŸ¤– Assistant

# åŸºäºPyTorchå’ŒHNSWçš„çŸ¢é‡å¬å›ç³»ç»Ÿ

## ç³»ç»Ÿæ¶æ„æ¦‚è¿°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     çŸ¢é‡å¬å›ç³»ç»Ÿæ¶æ„                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   ç”¨æˆ·ç‰¹å¾    â”‚    â”‚   ç‰©å“ç‰¹å¾    â”‚    â”‚   äº¤äº’æ•°æ®    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                   â”‚                   â”‚               â”‚
â”‚         â–¼                   â–¼                   â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚              åŒå¡”æ¨¡å‹ (Two-Tower Model)              â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚       â”‚
â”‚  â”‚  â”‚    ç”¨æˆ·å¡”        â”‚     â”‚    ç‰©å“å¡”        â”‚        â”‚       â”‚
â”‚  â”‚  â”‚  (User Tower)   â”‚     â”‚  (Item Tower)   â”‚        â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚       â”‚
â”‚  â”‚           â”‚                       â”‚                 â”‚       â”‚
â”‚  â”‚           â–¼                       â–¼                 â”‚       â”‚
â”‚  â”‚    ç”¨æˆ·å‘é‡ (128d)          ç‰©å“å‘é‡ (128d)          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚              HNSW ç´¢å¼• (Faiss/hnswlib)              â”‚       â”‚
â”‚  â”‚         é«˜æ•ˆè¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ (ANN Search)              â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚              Top-K å€™é€‰ç‰©å“åˆ—è¡¨                      â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## å®Œæ•´ä»£ç å®ç°

```python
"""
åŸºäºPyTorchå’ŒHNSWçš„çŸ¢é‡å¬å›ç³»ç»Ÿ
ç”¨äºæ¨èç³»ç»Ÿçš„å¬å›é˜¶æ®µ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
import hnswlib
from typing import List, Tuple, Dict, Optional
import time
from dataclasses import dataclass
from collections import defaultdict


# ==================== é…ç½®ç±» ====================
@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®"""
    user_feature_dim: int = 64          # ç”¨æˆ·ç‰¹å¾ç»´åº¦
    item_feature_dim: int = 64          # ç‰©å“ç‰¹å¾ç»´åº¦
    embedding_dim: int = 128            # åµŒå…¥å‘é‡ç»´åº¦
    hidden_dims: List[int] = None       # éšè—å±‚ç»´åº¦
    dropout_rate: float = 0.2           # Dropoutç‡
    num_users: int = 10000              # ç”¨æˆ·æ•°é‡
    num_items: int = 100000             # ç‰©å“æ•°é‡
    
    def __post_init__(self):
        if self.hidden_dims is None:
            self.hidden_dims = [256, 128]


@dataclass
class HNSWConfig:
    """HNSWç´¢å¼•é…ç½®"""
    space: str = 'cosine'               # è·ç¦»åº¦é‡: 'l2', 'ip', 'cosine'
    ef_construction: int = 200          # æ„å»ºæ—¶çš„efå‚æ•°
    M: int = 16                         # æ¯ä¸ªèŠ‚ç‚¹çš„è¿æ¥æ•°
    ef_search: int = 100                # æœç´¢æ—¶çš„efå‚æ•°
    num_threads: int = 4                # å¹¶è¡Œçº¿ç¨‹æ•°


# ==================== æ•°æ®é›†ç±» ====================
class RecommendationDataset(Dataset):
    """æ¨èç³»ç»Ÿæ•°æ®é›†"""
    
    def __init__(self, 
                 user_features: torch.Tensor,
                 item_features: torch.Tensor,
                 interactions: List[Tuple[int, int, float]]):
        """
        Args:
            user_features: ç”¨æˆ·ç‰¹å¾çŸ©é˜µ [num_users, user_feature_dim]
            item_features: ç‰©å“ç‰¹å¾çŸ©é˜µ [num_items, item_feature_dim]
            interactions: äº¤äº’åˆ—è¡¨ [(user_id, item_id, label), ...]
        """
        self.user_features = user_features
        self.item_features = item_features
        self.interactions = interactions
        
    def __len__(self):
        return len(self.interactions)
    
    def __getitem__(self, idx):
        user_id, item_id, label = self.interactions[idx]
        return {
            'user_id': user_id,
            'item_id': item_id,
            'user_feature': self.user_features[user_id],
            'item_feature': self.item_features[item_id],
            'label': torch.tensor(label, dtype=torch.float32)
        }


# ==================== åŒå¡”æ¨¡å‹ ====================
class TowerNetwork(nn.Module):
    """å¡”ç½‘ç»œåŸºç±»"""
    
    def __init__(self, 
                 input_dim: int, 
                 hidden_dims: List[int], 
                 output_dim: int,
                 dropout_rate: float = 0.2):
        super().__init__()
        
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.BatchNorm1d(hidden_dim),
                nn.ReLU(),
                nn.Dropout(dropout_rate)
            ])
            prev_dim = hidden_dim
        
        layers.append(nn.Linear(prev_dim, output_dim))
        self.network = nn.Sequential(*layers)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return F.normalize(self.network(x), p=2, dim=-1)


class UserTower(nn.Module):
    """ç”¨æˆ·å¡”"""
    
    def __init__(self, config: ModelConfig):
        super().__init__()
        
        # ç”¨æˆ·IDåµŒå…¥
        self.user_embedding = nn.Embedding(
            config.num_users, 
            config.embedding_dim // 2
        )
        
        # ç”¨æˆ·ç‰¹å¾å¤„ç†ç½‘ç»œ
        self.feature_network = TowerNetwork(
            input_dim=config.user_feature_dim,
            hidden_dims=[128],
            output_dim=config.embedding_dim // 2,
            dropout_rate=config.dropout_rate
        )
        
        # èåˆç½‘ç»œ
        self.fusion_network = TowerNetwork(
            input_dim=config.embedding_dim,
            hidden_dims=config.hidden_dims,
            output_dim=config.embedding_dim,
            dropout_rate=config.dropout_rate
        )
        
    def forward(self, 
                user_ids: torch.Tensor, 
                user_features: torch.Tensor) -> torch.Tensor:
        """
        Args:
            user_ids: ç”¨æˆ·ID [batch_size]
            user_features: ç”¨æˆ·ç‰¹å¾ [batch_size, user_feature_dim]
        Returns:
            ç”¨æˆ·å‘é‡ [batch_size, embedding_dim]
        """
        # è·å–ç”¨æˆ·IDåµŒå…¥
        id_emb = self.user_embedding(user_ids)
        
        # å¤„ç†ç”¨æˆ·ç‰¹å¾
        feat_emb = self.feature_network(user_features)
        
        # æ‹¼æ¥å¹¶èåˆ
        combined = torch.cat([id_emb, feat_emb], dim=-1)
        user_vector = self.fusion_network(combined)
        
        return user_vector


class ItemTower(nn.Module):
    """ç‰©å“å¡”"""
    
    def __init__(self, config: ModelConfig):
        super().__init__()
        
        # ç‰©å“IDåµŒå…¥
        self.item_embedding = nn.Embedding(
            config.num_items, 
            config.embedding_dim // 2
        )
        
        # ç‰©å“ç‰¹å¾å¤„ç†ç½‘ç»œ
        self.feature_network = TowerNetwork(
            input_dim=config.item_feature_dim,
            hidden_dims=[128],
            output_dim=config.embedding_dim // 2,
            dropout_rate=config.dropout_rate
        )
        
        # èåˆç½‘ç»œ
        self.fusion_network = TowerNetwork(
            input_dim=config.embedding_dim,
            hidden_dims=config.hidden_dims,
            output_dim=config.embedding_dim,
            dropout_rate=config.dropout_rate
        )
        
    def forward(self, 
                item_ids: torch.Tensor, 
                item_features: torch.Tensor) -> torch.Tensor:
        """
        Args:
            item_ids: ç‰©å“ID [batch_size]
            item_features: ç‰©å“ç‰¹å¾ [batch_size, item_feature_dim]
        Returns:
            ç‰©å“å‘é‡ [batch_size, embedding_dim]
        """
        # è·å–ç‰©å“IDåµŒå…¥
        id_emb = self.item_embedding(item_ids)
        
        # å¤„ç†ç‰©å“ç‰¹å¾
        feat_emb = self.feature_network(item_features)
        
        # æ‹¼æ¥å¹¶èåˆ
        combined = torch.cat([id_emb, feat_emb], dim=-1)
        item_vector = self.fusion_network(combined)
        
        return item_vector


class TwoTowerModel(nn.Module):
    """åŒå¡”å¬å›æ¨¡å‹"""
    
    def __init__(self, config: ModelConfig):
        super().__init__()
        self.config = config
        self.user_tower = UserTower(config)
        self.item_tower = ItemTower(config)
        self.temperature = nn.Parameter(torch.tensor(0.07))
        
    def forward(self, 
                user_ids: torch.Tensor,
                user_features: torch.Tensor,
                item_ids: torch.Tensor,
                item_features: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        Returns:
            user_vectors: ç”¨æˆ·å‘é‡
            item_vectors: ç‰©å“å‘é‡
            similarity: ç›¸ä¼¼åº¦åˆ†æ•°
        """
        user_vectors = self.user_tower(user_ids, user_features)
        item_vectors = self.item_tower(item_ids, item_features)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = torch.sum(user_vectors * item_vectors, dim=-1)
        similarity = similarity / self.temperature.abs()
        
        return user_vectors, item_vectors, similarity
    
    def get_user_embedding(self, 
                           user_ids: torch.Tensor, 
                           user_features: torch.Tensor) -> torch.Tensor:
        """è·å–ç”¨æˆ·åµŒå…¥å‘é‡"""
        return self.user_tower(user_ids, user_features)
    
    def get_item_embedding(self, 
                           item_ids: torch.Tensor, 
                           item_features: torch.Tensor) -> torch.Tensor:
        """è·å–ç‰©å“åµŒå…¥å‘é‡"""
        return self.item_tower(item_ids, item_features)


# ==================== HNSWç´¢å¼•ç®¡ç†å™¨ ====================
class HNSWIndexManager:
    """HNSWç´¢å¼•ç®¡ç†å™¨"""
    
    def __init__(self, 
                 dim: int, 
                 config: HNSWConfig,
                 max_elements: int = 1000000):
        """
        Args:
            dim: å‘é‡ç»´åº¦
            config: HNSWé…ç½®
            max_elements: æœ€å¤§å…ƒç´ æ•°é‡
        """
        self.dim = dim
        self.config = config
        self.max_elements = max_elements
        self.index = None
        self.id_to_item = {}  # å†…éƒ¨IDåˆ°ç‰©å“IDçš„æ˜ å°„
        self.item_to_id = {}  # ç‰©å“IDåˆ°å†…éƒ¨IDçš„æ˜ å°„
        
    def build_index(self, 
                    item_vectors: np.ndarray, 
                    item_ids: np.ndarray) -> None:
        """
        æ„å»ºHNSWç´¢å¼•
        
        Args:
            item_vectors: ç‰©å“å‘é‡çŸ©é˜µ [num_items, dim]
            item_ids: ç‰©å“IDæ•°ç»„ [num_items]
        """
        num_items = len(item_ids)
        
        # åˆå§‹åŒ–ç´¢å¼•
        self.index = hnswlib.Index(space=self.config.space, dim=self.dim)
        self.index.init_index(
            max_elements=max(num_items, self.max_elements),
            ef_construction=self.config.ef_construction,
            M=self.config.M
        )
        
        # è®¾ç½®å¹¶è¡Œçº¿ç¨‹æ•°
        self.index.set_num_threads(self.config.num_threads)
        
        # æ„å»ºIDæ˜ å°„
        for i, item_id in enumerate(item_ids):
            self.id_to_item[i] = item_id
            self.item_to_id[item_id] = i
        
        # æ·»åŠ å‘é‡åˆ°ç´¢å¼•
        print(f"Building HNSW index for {num_items} items...")
        start_time = time.time()
        
        self.index.add_items(item_vectors, np.arange(num_items))
        
        build_time = time.time() - start_time
        print(f"Index built in {build_time:.2f} seconds")
        
        # è®¾ç½®æœç´¢å‚æ•°
        self.index.set_ef(self.config.ef_search)
        
    def search(self, 
               query_vectors: np.ndarray, 
               k: int = 100) -> Tuple[np.ndarray, np.ndarray]:
        """
        æœç´¢æœ€ç›¸ä¼¼çš„kä¸ªç‰©å“
        
        Args:
            query_vectors: æŸ¥è¯¢å‘é‡ [num_queries, dim]
            k: è¿”å›çš„ç‰©å“æ•°é‡
            
        Returns:
            item_ids: ç‰©å“ID [num_queries, k]
            distances: è·ç¦»/ç›¸ä¼¼åº¦ [num_queries, k]
        """
        if self.index is None:
            raise ValueError("Index not built. Call build_index first.")
        
        # æ‰§è¡Œæœç´¢
        internal_ids, distances = self.index.knn_query(query_vectors, k=k)
        
        # è½¬æ¢ä¸ºç‰©å“ID
        item_ids = np.vectorize(lambda x: self.id_to_item[x])(internal_ids)
        
        return item_ids, distances
    
    def add_items(self, 
                  item_vectors: np.ndarray, 
                  item_ids: np.ndarray) -> None:
        """
        å¢é‡æ·»åŠ ç‰©å“åˆ°ç´¢å¼•
        """
        if self.index is None:
            raise ValueError("Index not built. Call build_index first.")
        
        start_idx = len(self.id_to_item)
        for i, item_id in enumerate(item_ids):
            internal_id = start_idx + i
            self.id_to_item[internal_id] = item_id
            self.item_to_id[item_id] = internal_id
        
        internal_ids = np.arange(start_idx, start_idx + len(item_ids))
        self.index.add_items(item_vectors, internal_ids)
    
    def save_index(self, path: str) -> None:
        """ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶"""
        if self.index is not None:
            self.index.save_index(path)
            
    def load_index(self, path: str) -> None:
        """ä»æ–‡ä»¶åŠ è½½ç´¢å¼•"""
        self.index = hnswlib.Index(space=self.config.space, dim=self.dim)
        self.index.load_index(path)
        self.index.set_ef(self.config.ef_search)


# ==================== æŸå¤±å‡½æ•° ====================
class SampledSoftmaxLoss(nn.Module):
    """é‡‡æ ·SoftmaxæŸå¤±ï¼ˆIn-batch Negativesï¼‰"""
    
    def __init__(self, temperature: float = 0.07):
        super().__init__()
        self.temperature = temperature
        
    def forward(self, 
                user_vectors: torch.Tensor, 
                item_vectors: torch.Tensor,
                labels: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        è®¡ç®—In-batch Negativeé‡‡æ ·æŸå¤±
        
        Args:
            user_vectors: [batch_size, dim]
            item_vectors: [batch_size, dim]
            labels: å¯é€‰çš„æ ‡ç­¾ï¼Œé»˜è®¤ä½¿ç”¨å¯¹è§’çº¿ä½œä¸ºæ­£æ ·æœ¬
        """
        batch_size = user_vectors.size(0)
        
        # è®¡ç®—æ‰€æœ‰ç”¨æˆ·-ç‰©å“å¯¹çš„ç›¸ä¼¼åº¦
        similarity_matrix = torch.matmul(
            user_vectors, item_vectors.t()
        ) / self.temperature
        
        # åˆ›å»ºæ ‡ç­¾ï¼ˆå¯¹è§’çº¿ä¸ºæ­£æ ·æœ¬ï¼‰
        if labels is None:
            labels = torch.arange(batch_size, device=user_vectors.device)
        
        # äº¤å‰ç†µæŸå¤±
        loss = F.cross_entropy(similarity_matrix, labels)
        
        return loss


class TripletLoss(nn.Module):
    """ä¸‰å…ƒç»„æŸå¤±"""
    
    def __init__(self, margin: float = 0.2):
        super().__init__()
        self.margin = margin
        
    def forward(self, 
                anchor: torch.Tensor,
                positive: torch.Tensor,
                negative: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—ä¸‰å…ƒç»„æŸå¤±
        """
        pos_dist = 1 - F.cosine_similarity(anchor, positive)
        neg_dist = 1 - F.cosine_similarity(anchor, negative)
        
        loss = F.relu(pos_dist - neg_dist + self.margin)
        return loss.mean()


# ==================== å¬å›ç³»ç»Ÿä¸»ç±» ====================
class VectorRecallSystem:
    """çŸ¢é‡å¬å›ç³»ç»Ÿ"""
    
    def __init__(self,
                 model_config: ModelConfig,
                 hnsw_config: HNSWConfig,
                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):
        """
        åˆå§‹åŒ–å¬å›ç³»ç»Ÿ
        """
        self.model_config = model_config
        self.hnsw_config = hnsw_config
        self.device = device
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = TwoTowerModel(model_config).to(device)
        
        # åˆå§‹åŒ–HNSWç´¢å¼•
        self.index_manager = HNSWIndexManager(
            dim=model_config.embedding_dim,
            config=hnsw_config,
            max_elements=model_config.num_items
        )
        
        # å­˜å‚¨ç‰©å“ä¿¡æ¯
        self.item_features = None
        self.item_ids = None
        
    def train(self,
              train_dataset: Dataset,
              val_dataset: Optional[Dataset] = None,
              epochs: int = 10,
              batch_size: int = 256,
              learning_rate: float = 1e-3,
              weight_decay: float = 1e-5) -> Dict[str, List[float]]:
        """
        è®­ç»ƒåŒå¡”æ¨¡å‹
        
        Returns:
            è®­ç»ƒå†å²è®°å½•
        """
        train_loader = DataLoader(
            train_dataset, 
            batch_size=batch_size, 
            shuffle=True,
            num_workers=4,
            pin_memory=True
        )
        
        optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=learning_rate,
            weight_decay=weight_decay
        )
        
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=epochs
        )
        
        criterion = SampledSoftmaxLoss()
        
        history = {'train_loss': [], 'val_loss': []}
        
        for epoch in range(epochs):
            self.model.train()
            total_loss = 0
            num_batches = 0
            
            for batch in train_loader:
                user_ids = batch['user_id'].to(self.device)
                item_ids = batch['item_id'].to(self.device)
                user_features = batch['user_feature'].to(self.device)
                item_features = batch['item_feature'].to(self.device)
                
                optimizer.zero_grad()
                
                user_vectors, item_vectors, _ = self.model(
                    user_ids, user_features, item_ids, item_features
                )
                
                loss = criterion(user_vectors, item_vectors)
                loss.backward()
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
                
                optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
            
            avg_loss = total_loss / num_batches
            history['train_loss'].append(avg_loss)
            
            scheduler.step()
            
            print(f"Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}")
            
            # éªŒè¯
            if val_dataset is not None:
                val_loss = self._validate(val_dataset, batch_size, criterion)
                history['val_loss'].append(val_loss)
                print(f"  Val Loss: {val_loss:.4f}")
        
        return history
    
    def _validate(self, 
                  val_dataset: Dataset, 
                  batch_size: int,
                  criterion: nn.Module) -> float:
        """éªŒè¯æ¨¡å‹"""
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
        
        self.model.eval()
        total_loss = 0
        num_batches = 0
        
        with torch.no_grad():
            for batch in val_loader:
                user_ids = batch['user_id'].to(self.device)
                item_ids = batch['item_id'].to(self.device)
                user_features = batch['user_feature'].to(self.device)
                item_features = batch['item_feature'].to(self.device)
                
                user_vectors, item_vectors, _ = self.model(
                    user_ids, user_features, item_ids, item_features
                )
                
                loss = criterion(user_vectors, item_vectors)
                total_loss += loss.item()
                num_batches += 1
        
        return total_loss / num_batches
    
    def build_item_index(self,
                         item_ids: np.ndarray,
                         item_features: torch.Tensor,
                         batch_size: int = 1024) -> None:
        """
        æ„å»ºç‰©å“å‘é‡ç´¢å¼•
        
        Args:
            item_ids: ç‰©å“IDæ•°ç»„
            item_features: ç‰©å“ç‰¹å¾çŸ©é˜µ
        """
        self.item_features = item_features
        self.item_ids = item_ids
        
        self.model.eval()
        all_item_vectors = []
        
        with torch.no_grad():
            for i in range(0, len(item_ids), batch_size):
                batch_ids = torch.tensor(
                    item_ids[i:i+batch_size], 
                    dtype=torch.long,
                    device=self.device
                )
                batch_features = item_features[i:i+batch_size].to(self.device)
                
                item_vectors = self.model.get_item_embedding(
                    batch_ids, batch_features
                )
                all_item_vectors.append(item_vectors.cpu().numpy())
        
        item_vectors = np.vstack(all_item_vectors)
        
        # æ„å»ºHNSWç´¢å¼•
        self.index_manager.build_index(item_vectors, item_ids)
    
    def recall(self,
               user_ids: np.ndarray,
               user_features: torch.Tensor,
               k: int = 100) -> Tuple[np.ndarray, np.ndarray]:
        """
        ä¸ºç”¨æˆ·å¬å›Top-Kç‰©å“
        
        Args:
            user_ids: ç”¨æˆ·IDæ•°ç»„
            user_features: ç”¨æˆ·ç‰¹å¾çŸ©é˜µ
            k: å¬å›ç‰©å“æ•°é‡
            
        Returns:
            recalled_items: å¬å›çš„ç‰©å“ID [num_users, k]
            scores: ç›¸ä¼¼åº¦åˆ†æ•° [num_users, k]
        """
        self.model.eval()
        
        with torch.no_grad():
            user_ids_tensor = torch.tensor(
                user_ids, dtype=torch.long, device=self.device
            )
            user_features = user_features.to(self.device)
            
            user_vectors = self.model.get_user_embedding(
                user_ids_tensor, user_features
            )
            user_vectors = user_vectors.cpu().numpy()
        
        # HNSWæœç´¢
        recalled_items, distances = self.index_manager.search(user_vectors, k)
        
        # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
        if self.hnsw_config.space == 'cosine':
            scores = 1 - distances  # cosineè·ç¦»è½¬ç›¸ä¼¼åº¦
        elif self.hnsw_config.space == 'l2':
            scores = 1 / (1 + distances)  # L2è·ç¦»è½¬ç›¸ä¼¼åº¦
        else:  # inner product
            scores = distances
        
        return recalled_items, scores
    
    def save(self, model_path: str, index_path: str) -> None:
        """ä¿å­˜æ¨¡å‹å’Œç´¢å¼•"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'model_config': self.model_config,
            'hnsw_config': self.hnsw_config
        }, model_path)
        
        self.index_manager.save_index(index_path)
        
    def load(self, model_path: str, index_path: str) -> None:
        """åŠ è½½æ¨¡å‹å’Œç´¢å¼•"""
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.index_manager.load_index(index_path)


# ==================== è¯„ä¼°æŒ‡æ ‡ ====================
class RecallEvaluator:
    """å¬å›æ•ˆæœè¯„ä¼°å™¨"""
    
    @staticmethod
    def calculate_recall_at_k(
        recalled_items: np.ndarray,
        ground_truth: Dict[int, List[int]],
        user_ids: np.ndarray,
        k_list: List[int] = [10, 50, 100]
    ) -> Dict[str, float]:
        """
        è®¡ç®—Recall@K
        
        Args:
            recalled_items: å¬å›ç»“æœ [num_users, max_k]
            ground_truth: ç”¨æˆ·çœŸå®äº¤äº’ç‰©å“ {user_id: [item_ids]}
            user_ids: ç”¨æˆ·IDæ•°ç»„
            k_list: Kå€¼åˆ—è¡¨
        """
        results = {}
        
        for k in k_list:
            hits = 0
            total = 0
            
            for i, user_id in enumerate(user_ids):
                if user_id in ground_truth:
                    true_items = set(ground_truth[user_id])
                    pred_items = set(recalled_items[i, :k])
                    hits += len(true_items & pred_items)
                    total += len(true_items)
            
            results[f'Recall@{k}'] = hits / total if total > 0 else 0
        
        return results
    
    @staticmethod
    def calculate_hit_rate(
        recalled_items: np.ndarray,
        ground_truth: Dict[int, List[int]],
        user_ids: np.ndarray,
        k_list: List[int] = [10, 50, 100]
    ) -> Dict[str, float]:
        """
        è®¡ç®—Hit Rate@K
        """
        results = {}
        
        for k in k_list:
            hits = 0
            
            for i, user_id in enumerate(user_ids):
                if user_id in ground_truth:
                    true_items = set(ground_truth[user_id])
                    pred_items = set(recalled_items[i, :k])
                    if len(true_items & pred_items) > 0:
                        hits += 1
            
            results[f'HitRate@{k}'] = hits / len(user_ids)
        
        return results


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================
def generate_synthetic_data(
    num_users: int = 10000,
    num_items: int = 100000,
    num_interactions: int = 500000,
    user_feature_dim: int = 64,
    item_feature_dim: int = 64
) -> Tuple[torch.Tensor, torch.Tensor, List[Tuple[int, int, float]]]:
    """ç”Ÿæˆåˆæˆæ•°æ®ç”¨äºæ¼”ç¤º"""
    
    # ç”Ÿæˆç”¨æˆ·ç‰¹å¾
    user_features = torch.randn(num_users, user_feature_dim)
    
    # ç”Ÿæˆç‰©å“ç‰¹å¾
    item_features = torch.randn(num_items, item_feature_dim)
    
    # ç”Ÿæˆäº¤äº’æ•°æ®
    interactions = []
    for _ in range(num_interactions):
        user_id = np.random.randint(0, num_users)
        item_id = np.random.randint(0, num_items)
        label = 1.0  # æ­£æ ·æœ¬
        interactions.append((user_id, item_id, label))
    
    return user_features, item_features, interactions


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºå®Œæ•´çš„å¬å›ç³»ç»Ÿæµç¨‹"""
    
    print("=" * 60)
    print("çŸ¢é‡å¬å›ç³»ç»Ÿ - åŸºäºPyTorchå’ŒHNSW")
    print("=" * 60)
    
    # é…ç½®
    model_config = ModelConfig(
        user_feature_dim=64,
        item_feature_dim=64,
        embedding_dim=128,
        hidden_dims=[256, 128],
        num_users=10000,
        num_items=100000
    )
    
    hnsw_config = HNSWConfig(
        space='cosine',
        ef_construction=200,
        M=16,
        ef_search=100
    )
    
    # ç”Ÿæˆæ•°æ®
    print("\n[1] ç”Ÿæˆåˆæˆæ•°æ®...")
    user_features, item_features, interactions = generate_synthetic_data(
        num_users=model_config.num_users,
        num_items=model_config.num_items,
        user_feature_dim=model_config.user_feature_dim,
        item_feature_dim=model_config.item_feature_dim
    )
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    split_idx = int(len(interactions) * 0.9)
    train_interactions = interactions[:split_idx]
    val_interactions = interactions[split_idx:]
    
    train_dataset = RecommendationDataset(
        user_features, item_features, train_interactions
    )
    val_dataset = RecommendationDataset(
        user_features, item_features, val_interactions
    )
    
    # åˆå§‹åŒ–å¬å›ç³»ç»Ÿ
    print("\n[2] åˆå§‹åŒ–å¬å›ç³»ç»Ÿ...")
    recall_system = VectorRecallSystem(model_config, hnsw_config)
    
    # è®­ç»ƒæ¨¡å‹
    print("\n[3] è®­ç»ƒåŒå¡”æ¨¡å‹...")
    history = recall_system.train(
        train_dataset,
        val_dataset,
        epochs=5,
        batch_size=512,
        learning_rate=1e-3
    )
    
    # æ„å»ºç‰©å“ç´¢å¼•
    print("\n[4] æ„å»ºHNSWç‰©å“ç´¢å¼•...")
    item_ids = np.arange(model_config.num_items)
    recall_system.build_item_index(item_ids, item_features)
    
    # å¬å›æµ‹è¯•
    print("\n[5] æ‰§è¡Œå¬å›æµ‹è¯•...")
    test_user_ids = np.arange(100)  # æµ‹è¯•100ä¸ªç”¨æˆ·
    test_user_features = user_features[:100]
    
    start_time = time.time()
    recalled_items, scores = recall_system.recall(
        test_user_ids, 
        test_user_features, 
        k=100
    )
    recall_time = time.time() - start_time
    
    print(f"  å¬å›100ä¸ªç”¨æˆ·çš„Top-100ç‰©å“è€—æ—¶: {recall_time*1000:.2f}ms")
    print(f"  å¹³å‡æ¯ä¸ªç”¨æˆ·å¬å›è€—æ—¶: {recall_time*1000/100:.2f}ms")
    
    # å±•ç¤ºç»“æœ
    print("\n[6] å¬å›ç»“æœç¤ºä¾‹ (ç”¨æˆ·0):")
    print(f"  Top-10ç‰©å“ID: {recalled_items[0, :10]}")
    print(f"  Top-10ç›¸ä¼¼åº¦: {scores[0, :10]}")
    
    print("\n" + "=" * 60)
    print("ç³»ç»Ÿè¿è¡Œå®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
```

## ç³»ç»Ÿç‰¹ç‚¹

### 1. åŒå¡”æ¶æ„ä¼˜åŠ¿

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åŒå¡”æ¨¡å‹ä¼˜åŠ¿                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  âœ“ ç¦»çº¿è®¡ç®—ç‰©å“å‘é‡ï¼Œåœ¨çº¿åªéœ€è®¡ç®—ç”¨æˆ·å‘é‡                    â”‚
â”‚  âœ“ ç”¨æˆ·å¡”å’Œç‰©å“å¡”ç‹¬ç«‹ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤                        â”‚
â”‚  âœ“ æ”¯æŒå¢é‡æ›´æ–°ç‰©å“ç´¢å¼•                                     â”‚
â”‚  âœ“ é€‚åˆå¤§è§„æ¨¡æ¨èåœºæ™¯                                       â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. HNSWç®—æ³•ç‰¹æ€§

| ç‰¹æ€§ | æè¿° |
|------|------|
| æ—¶é—´å¤æ‚åº¦ | O(log N) æœç´¢ |
| ç©ºé—´å¤æ‚åº¦ | O(N * M) |
| å¬å›ç‡ | å¯è¾¾99%+ |
| å»¶è¿Ÿ | æ¯«ç§’çº§ |

### 3. ä¾èµ–å®‰è£…

```bash
pip install torch numpy hnswlib
```

è¿™ä¸ªç³»ç»Ÿå®ç°äº†å®Œæ•´çš„çŸ¢é‡å¬å›æµç¨‹ï¼ŒåŒ…æ‹¬åŒå¡”æ¨¡å‹è®­ç»ƒã€HNSWç´¢å¼•æ„å»ºå’Œé«˜æ•ˆå¬å›åŠŸèƒ½ã€‚