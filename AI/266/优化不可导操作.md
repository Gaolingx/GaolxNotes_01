# ä¼˜åŒ–ä¸å¯å¯¼æ“ä½œ

### ğŸ§‘â€ğŸ’» User

æ·±åº¦å­¦ä¹ ä¸­çš„ç»å¤§å¤šæ•°æ¨¡å‹éƒ½æ˜¯é æ±‚å¯¼æ¢¯åº¦ä¸‹é™æ¥è¿›è¡Œå‚æ•°æ›´æ–°. ä½†æ˜¯å¦‚æœé‡åˆ°ä¸å¯æ±‚å¯¼çš„æ“ä½œè¯¥æ€ä¹ˆåŠ? è¿™æ—¶å€™å¦‚ä½•ä¼˜åŒ–æˆ‘ä»¬çš„æ¨¡å‹å‘¢ï¼Ÿ

---

### ğŸ¤– Assistant

å¥½é—®é¢˜ â€” åœ¨å®é™…æ¨¡å‹é‡Œâ€œéå¯å¯¼æ“ä½œâ€å¾ˆå¸¸è§ï¼ˆç¦»æ•£é€‰æ‹©ã€argmaxã€é‡‡æ ·ã€é‡åŒ–ã€æ¸²æŸ“å™¨ã€æ’åºã€é»‘ç›’è¯„ä¼°å‡½æ•°â€¦â€¦ï¼‰ï¼Œä½†å¤§å¤šæ•°è®­ç»ƒæµç¨‹ä¾èµ–æ¢¯åº¦ã€‚ä¸‹é¢æŠŠå¸¸ç”¨ç­–ç•¥æŒ‰ç±»åˆ«åˆ—æ¸…æ¥šï¼Œç»™å‡ºå…¬å¼ã€ä¼˜ç¼ºç‚¹ã€å®æˆ˜å»ºè®®å’Œå¸¸è§é™·é˜±â€”â€”ä½ å¯ä»¥ç›´æ¥æŒ‘ç€ç”¨ã€‚

# å¿«é€Ÿç»“è®ºï¼ˆè¦ç‚¹ï¼‰

1. **ä¼˜å…ˆæŠŠä¸å¯å¯¼é¡¹å˜æˆå¯å¯¼çš„è¿ç»­æ¾å¼›ï¼ˆreparam. / relaxationï¼‰**ï¼Œè¿™æ˜¯æœ€ç¨³å®šã€é«˜æ•ˆçš„åšæ³•ã€‚
2. å¦‚æœå¿…é¡»ç¦»æ•£/é»‘ç›’è¾“å‡ºï¼Œä¼˜å…ˆç”¨**å¯é‡å‚æ•°åŒ–ï¼ˆreparameterizationï¼‰**æˆ–**ä½æ–¹å·®çš„ä¼°è®¡å™¨**ï¼ˆæ¯”å¦‚å¸¦ baseline çš„ score-function / æ”¿ç­–æ¢¯åº¦å˜ç§ï¼‰è€Œä¸æ˜¯ç›´æ¥æœ‰é™å·®åˆ†æˆ–ç›²ç”¨ STEã€‚
3. **ç›´é€šä¼°è®¡ï¼ˆSTEï¼‰**å¯åšå·¥ç¨‹åŒ–å¿«é€Ÿæ–¹æ¡ˆï¼Œä½†å¸¦åä¸”å¯èƒ½ä¸ç¨³å®šï¼Œé€‚ç”¨äºé‡åŒ–/äºŒå€¼åŒ–çš„å·¥ç¨‹å®è·µã€‚
4. å¯¹äºçœŸæ­£çš„é»‘ç®±ç›®æ ‡ï¼ˆæ¯”å¦‚æŸä¸ªå¤æ‚éå¯¼å‡ºæ¸²æŸ“å™¨è¿”å›çš„ rewardï¼‰ï¼Œè€ƒè™‘**å¼ºåŒ–å­¦ä¹  / é»‘ç›’ä¼˜åŒ–ï¼ˆCMA-ESã€è´å¶æ–¯ä¼˜åŒ–ï¼‰**ã€‚

---

# æ–¹æ³•æ±‡æ€»ï¼ˆæ¯é¡¹å«å…³é”®å…¬å¼ / ç”¨ä¾‹ / æ³¨æ„ï¼‰

### 1) è¿ç»­æ¾å¼›ï¼ˆContinuous relaxationï¼‰

æŠŠç¦»æ•£æ“ä½œæ›¿æ¢ä¸ºå¯å¾®çš„è¿‘ä¼¼ã€‚

* ä¾‹ï¼š`argmax` â†’ softmax / soft-argmaxï¼›top-k â†’ SoftTopKã€NeuralSortï¼›ç½®æ¢çŸ©é˜µ â†’ Sinkhornï¼ˆSinkhorn å±€éƒ¨å¯å¾®ï¼‰ã€‚
* ä¼˜ç‚¹ï¼šæ¢¯åº¦ä½æ–¹å·®ã€æ˜“ç”¨ç°æœ‰ä¼˜åŒ–å™¨ã€‚
* ç¼ºç‚¹ï¼šæ˜¯è¿‘ä¼¼ï¼Œå¯èƒ½éœ€è¦é€€ç«ï¼ˆtemperatureâ†’0ï¼‰æ¥é€¼è¿‘ç¦»æ•£è¡Œä¸ºï¼Œè®­ç»ƒåå¯èƒ½éœ€åšç¦»æ•£åŒ–å¾®è°ƒã€‚

### 2) å¯é‡å‚æ•°åŒ–æŠ€å·§ï¼ˆReparameterization trickï¼‰

å½“éšæœºå˜é‡ z ~ pÎ¸(z) å¯å†™æˆ z = g(Îµ; Î¸)ï¼ˆÎµ æ˜¯æ— å‚æ•°å™ªå£°ï¼‰ï¼Œåˆ™
[
\nabla_\theta \mathbb{E}*{z\sim p*\theta}[f(z)] = \mathbb{E}*{\epsilon}[\nabla*\theta f(g(\epsilon;\theta))]
]

* æ ‡å‡†ä¾‹å­ï¼šæ­£æ€åˆ†å¸ƒï¼ˆVAEï¼‰ã€‚
* ç¦»æ•£å˜é‡çš„è¿ç»­è¿‘ä¼¼ï¼š**Gumbel-Softmax / Concrete**ï¼š
  [
  y_i = \frac{\exp((\log \alpha_i + g_i)/\tau)}{\sum_j \exp((\log \alpha_j + g_j)/\tau)}
  ]
  å…¶ä¸­ (g_i) æ˜¯ Gumbel å™ªå£°ï¼ŒÏ„ æ˜¯æ¸©åº¦ã€‚Ï„ â†’ 0 è¶‹è¿‘ç¦»æ•£ï¼Œä¸€èˆ¬è®­ç»ƒæ—¶åšé€€ç«ã€‚
* ä¼˜ç‚¹ï¼šé€šå¸¸æ–¹å·®å°ã€ç¨³å®šã€‚
* æ³¨æ„ï¼šGumbel-Softmax æ˜¯è¿‘ä¼¼ï¼ˆå½“Ï„>0æ—¶æœ‰åï¼‰ï¼Œä¼šåœ¨æç«¯ç¦»æ•£ä¸Šè¡¨ç°å·®ï¼Œéœ€è¦è°ƒæ¸©åº¦å’Œ/æˆ–åœ¨è®­ç»ƒæœ«æœŸç”¨ STEã€‚

### 3) åˆ†æ•°å‡½æ•°ä¼°è®¡å™¨ / REINFORCEï¼ˆscore-functionï¼‰

å½“ä¸èƒ½ reparameterize æ—¶ï¼Œç”¨ score-functionï¼š
[
\nabla_\theta \mathbb{E}*{z\sim p*\theta}[f(z)] = \mathbb{E}*{z}[f(z) \nabla*\theta \log p_\theta(z)]
]
å¸¸ç”¨æŠ€å·§ï¼š**baseline** (b) å‡ä½æ–¹å·®ï¼š
[
\mathbb{E}[(f(z)-b)\nabla_\theta\log p_\theta(z)]
]

* ä¼˜ç‚¹ï¼šé€šç”¨ï¼ˆå¯¹ä»»ä½•å¯é‡‡æ ·åˆ†å¸ƒé€‚ç”¨ï¼‰ã€‚
* ç¼ºç‚¹ï¼šæ–¹å·®å¤§ï¼Œæ”¶æ•›æ…¢ã€‚éœ€è¦ baselineã€æ§åˆ¶å˜é‡ã€å¤šæ ·æœ¬æˆ–è‡ªé€‚åº”åŸºçº¿ï¼ˆlearned criticï¼‰ã€‚
* å˜ç§ï¼šREBARã€RELAXã€VIMCOï¼ˆé’ˆå¯¹å¤šæ ·æœ¬ï¼‰ç­‰ï¼Œç”¨è¿ç»­æ¾å¼›åšæ§åˆ¶å˜é‡æ¥æ˜¾è‘—é™æ–¹å·®ã€‚

### 4) ç›´é€šä¼°è®¡ï¼ˆStraight-Through Estimatorï¼ŒSTEï¼‰

å‰å‘ä½¿ç”¨ç¦»æ•£æ“ä½œï¼ˆä¾‹å¦‚é‡åŒ–æˆ– one-hotï¼‰ï¼Œåå‘æŠŠæ¢¯åº¦å½“ä½œé€šè¿‡è¿ç»­è¿‘ä¼¼ï¼ˆä¾‹å¦‚æ’ç­‰æ˜ å°„æˆ– softmaxï¼‰ä¼ æ’­ï¼š

* å‰å‘ï¼š (y = \text{one_hot}(\arg\max \text{logits}))
* åå‘ï¼š (\frac{\partial L}{\partial \text{logits}} \approx \frac{\partial L}{\partial y_{\text{soft}}})
* å¸¸ç”¨äºï¼šé‡åŒ–ç½‘ç»œæƒé‡/æ¿€æ´»ï¼ˆäºŒå€¼ç½‘ç»œã€é‡åŒ–è®­ç»ƒï¼‰ï¼Œè®­ç»ƒé€Ÿåº¦å¿«ï¼Œå·¥ç¨‹ä¸Šå¾ˆå¸¸è§ï¼ˆBengio ç­‰ï¼‰ã€‚
* é£é™©ï¼š**æœ‰åæ¢¯åº¦**ï¼Œå¯èƒ½å¯¼è‡´ä¸æ”¶æ•›æˆ–æ¬¡ä¼˜è§£ã€‚ç”¨ä½œå·¥ç¨‹æŠ€å·§æ—¶é€šå¸¸é…åˆå­¦ä¹ ç‡å’Œæ‰¹é‡ç»Ÿè®¡çš„å°å¿ƒè°ƒæ•´ã€‚

### 5) å­æ¢¯åº¦ / å¹¿ä¹‰æ¢¯åº¦ï¼ˆSubgradient / Clarke gradientï¼‰

å¯¹æŸäº›éå…‰æ»‘ä½†å‡¸ï¼ˆæˆ–å±€éƒ¨å¯è¡¨ç¤ºä¸ºåˆ†æ®µçº¿æ€§ï¼‰çš„å‡½æ•°å¯ä»¥ä½¿ç”¨å­æ¢¯åº¦æ–¹æ³•ï¼ˆä¾‹å¦‚ ReLUã€L1ã€maxï¼‰ã€‚ç°ä»£ autodiff æ¡†æ¶é€šå¸¸åœ¨ä¸è¿ç»­ç‚¹è¿”å›æŸä¸ªå­æ¢¯åº¦ã€‚

* ä¼˜ç‚¹ï¼šä¸éœ€è¦æ”¹æ¨¡å‹ç»“æ„ã€‚
* æ³¨æ„ï¼šåœ¨éå‡¸/å¤æ‚ç®—å­ä¸Šä¸æ€»æ˜¯å¯è¡Œï¼Œä¸”æ•°å€¼è¡Œä¸ºä¾èµ–äºå®ç°ç»†èŠ‚ã€‚

### 6) é»‘ç›’ / æ— æ¢¯åº¦ä¼˜åŒ–ï¼ˆEvolutionary / Bayesianï¼‰

å½“æ¨¡å‹æˆ–ç›®æ ‡å®Œå…¨ä¸å¯å¯¼ï¼ˆæˆ–é‡‡æ ·æˆæœ¬ä½ã€ç»´åº¦ä¸é«˜ï¼‰ï¼š

* é»‘ç›’æ–¹æ³•ï¼šCMA-ESã€é—ä¼ ç®—æ³•ã€æ¨¡æ‹Ÿé€€ç«ã€è´å¶æ–¯ä¼˜åŒ–ï¼ˆå¯¹è¶…å‚ã€æ¶æ„æœç´¢æœ‰ç”¨ï¼‰ã€‚
* ä¼˜ç‚¹ï¼šå¯¹éå‡¸ã€éå…‰æ»‘ã€å™ªå£°ç›®æ ‡å¥å£®ã€‚
* ç¼ºç‚¹ï¼šæ ·æœ¬æ•ˆç‡ä½ï¼Œä¸é€‚åˆå¤§è§„æ¨¡æ¨¡å‹å‚æ•°ç›´æ¥ä¼˜åŒ–ï¼ˆå‚æ•°é‡å¤§æ—¶ä»£ä»·é«˜ï¼‰ã€‚

### 7) æœ‰ç›‘ç£/æ›¿ä»£æŸå¤±ï¼ˆSurrogate lossï¼‰

ç›®æ ‡ä¸æ˜¯å¯å¾®ï¼ˆä¾‹å¦‚ç›´æ¥ä¼˜åŒ– accuracyã€F1ã€NDCG ç­‰ï¼‰ï¼Œå¸¸ç”¨å¯å¾®ä»£ç†ï¼ˆcross-entropyã€hingeã€smooth approximationsï¼‰æˆ–å…ˆç”¨ä»£ç†è®­ç»ƒå†é’ˆå¯¹åŸå§‹æŒ‡æ ‡ç”¨ RL å¾®è°ƒï¼ˆpolicy gradient å¾®è°ƒï¼‰ã€‚

* å®è·µï¼šåœ¨ä¿¡æ¯æ£€ç´¢å’Œæ’åºä¸­å¸¸ç”¨å¯å¾® surrogateï¼Œå†ç”¨ç­–ç•¥æ¢¯åº¦å¯¹å®é™…è¯„ä¼°æŒ‡æ ‡è¿›è¡Œ fine-tuneã€‚

### 8) æ„å»ºå¯å¾®ä»£ç†/æ¨¡æ‹Ÿå™¨ï¼ˆDifferentiable surrogate / differentiable simulatorï¼‰

æŠŠé»‘ç›’æ›¿æ¢ä¸ºå¯å¾®çš„è¿‘ä¼¼å™¨ï¼ˆmetamodelã€ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿå™¨ã€å¾®åˆ†æ¸²æŸ“å™¨ï¼‰ï¼Œå¹¶å¯¹ surrogate è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼Œå†æŠŠç»“æœ transfer åˆ°çœŸå®ç³»ç»Ÿæˆ–ç”¨ RL/fine-tune æ ¡æ­£ã€‚

---

# å®æˆ˜å»ºè®®ï¼ˆæ€ä¹ˆé€‰ï¼‰

1. **èƒ½ reparameterize å°±å…ˆè¯• reparam. + baselineï¼ˆæœ€ç¨³ï¼‰ã€‚**
2. **å¦‚æœæ˜¯ç¦»æ•£é€‰æ‹©ï¼ˆåˆ†ç±»ã€one-hotï¼‰ï¼Œå…ˆç”¨ Gumbel-Softmax æˆ– softmax+æ¸©åº¦å†é€€ç«ï¼›** è‹¥éœ€è¦ä¸¥æ ¼ç¦»æ•£è¾“å‡ºï¼Œå†ç”¨ STE åšæœ€åå¾®è°ƒï¼ˆæ³¨æ„ç›‘æ§åå·®ï¼‰ã€‚
3. **ç›®æ ‡æ˜¯ä¸å¯å¾®è¯„ä¼°ï¼ˆæ¯”å¦‚ç‚¹å‡»ç‡ã€ç”¨æˆ·æŒ‡æ ‡ï¼‰â†’ å¼ºåŒ–å­¦ä¹ ï¼ˆpolicy gradient / actor-criticï¼‰æˆ–ç”¨ä¸€ä¸ªå¯å¾®ä»£ç† + RL å¾®è°ƒã€‚**
4. **é‡åŒ–/äºŒå€¼åŒ–ï¼ˆå·¥ç¨‹å®è·µï¼‰â†’ STEï¼ˆé…åˆé‡åŒ–æ„ŸçŸ¥è®­ç»ƒå’Œåå¤„ç†å¾®è°ƒï¼‰ã€‚**
5. **è‹¥æ ·æœ¬/è®¡ç®—é¢„ç®—å…è®¸ä¸”ç›®æ ‡æ˜¯é»‘ç›’å°ç»´å‚æ•°â†’ ä½¿ç”¨ CMA-ES / è´å¶æ–¯ä¼˜åŒ–ã€‚**

---

# å°ç¤ºä¾‹ï¼ˆä¼ªä»£ç ï¼‰

REINFORCE çš„æ ¸å¿ƒï¼š

```python
# z ~ p_theta(z)
z = sample(p_theta)
loss = f(z)            # å¯èƒ½æ˜¯éå¾®åˆ†çš„ reward
grad = (f(z) - baseline) * grad_log_prob(z)  # monte-carlo estimate
theta += -lr * grad
```

Gumbel-Softmaxï¼ˆåˆ†ç±»çš„å¯å¾®è¿‘ä¼¼ï¼‰ï¼š

```python
g = -log(-log(U))      # U~Uniform(0,1)
y = softmax((logits + g)/tau)
# use y in forward; backprop flows through y
```

STEï¼ˆé‡åŒ–ï¼‰çš„å¸¸è§ trickï¼š

* å‰å‘é‡åŒ–ï¼ˆround/one-hotï¼‰ï¼Œåå‘ç”¨ identity æˆ– clip çš„å¯¼æ•°ï¼›
* é…åˆå­¦ä¹ ç‡è¡°å‡ã€æ¢¯åº¦è£å‰ªå’ŒåŠ¨é‡å¯æé«˜ç¨³å®šæ€§ã€‚

---

# å¸¸è§è¯¯åŒºä¸æ³¨æ„

* **åˆ«æŠŠ STE å½“ä½œæ— ä»£ä»·çš„â€œçœŸå®â€æ¢¯åº¦**ï¼šå®ƒæœ‰åï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒå¤±è´¥/å­¦ä¸åˆ°çœŸæ­£ç›®æ ‡è¡Œä¸ºã€‚
* **REINFORCE æ–¹å·®å¾ˆå¤§**ï¼šå¿…é¡»ç”¨ baseline / control variate / å¤šæ ·æœ¬æˆ–æ›´å…ˆè¿›çš„å˜ä½“ï¼ˆRELAX/REBARï¼‰æ¥é™æ–¹å·®ã€‚
* **æ¸©åº¦é€€ç«å¾ˆå…³é”®**ï¼šç”¨ Gumbel-Softmax ç­‰æ–¹æ³•æ—¶éœ€è°ƒæ¸©åº¦ç­–ç•¥ï¼Œå¤ªå¤§åå·®å¤ªå°å­¦ä¹ å›°éš¾ã€‚
* **åˆ«å¿½è§†å·¥ç¨‹åŒ–å¾®è°ƒ**ï¼šå¾ˆå¤šæ–¹æ³•å…ˆç”¨è¿ç»­ä»£ç†è®­ç»ƒï¼Œå†æŠŠç¦»æ•£åŒ–æ”¾åˆ°åæœŸ fine-tuneï¼Œæ˜¯å¸¸è§å®è·µï¼ˆä¾‹å¦‚é‡åŒ–æ„ŸçŸ¥è®­ç»ƒåå†éƒ¨ç½²ï¼‰ã€‚
* **æŸ¥çœ‹æ•°å€¼ç¨³å®šæ€§**ï¼šé‡‡æ ·æ¬¡æ•°ã€æ‰¹é‡å¤§å°ã€å­¦ä¹ ç‡å¯¹è¿™äº›æ–¹æ³•å½±å“æå¤§ï¼Œç›‘æ§æ¢¯åº¦æ–¹å·®å’ŒæŒ‡æ ‡æ”¶æ•›ã€‚

---

å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥ï¼š

* é’ˆå¯¹ä½ å½“å‰é‡åˆ°çš„**å…·ä½“ä¸å¯å¯¼æ“ä½œ**ï¼ˆæ¯”å¦‚ top-kã€quantizeã€ç¡¬æ³¨æ„åŠ›ã€æ¸²æŸ“å™¨ã€æ’åºæŒ‡æ ‡ç­‰ï¼‰ç»™å‡ºæ›´ç²¾ç¡®çš„å®ç°å»ºè®®å’Œå°æ®µä»£ç ï¼›
* æˆ–è€…æŠŠä¸Šé¢çš„æ–¹æ³•æŒ‰â€œæ˜“å®ç°â†’ç¨³å¥â†’æœ€ä¼˜â€é¡ºåºï¼Œç»™å‡ºä¸€ä»½è°ƒå‚ checklistï¼ˆtemperatureã€baseline å½¢å¼ã€é‡‡æ ·æ¬¡æ•°ã€é€€ç« schedule ç­‰ï¼‰ã€‚

è¦ä¸è¦æŠŠä½ ç°åœ¨é‡åˆ°çš„ä¸å¯å¯¼æ“ä½œè´´å‡ºæ¥ï¼Ÿæˆ‘ç›´æ¥ç»™å…·ä½“å®ç°å’Œè°ƒå‚å»ºè®®ã€‚


---

### ğŸ§‘â€ğŸ’» User

Gumbel-Softmaxåœ¨moeè·¯ç”±è®­ç»ƒä¸­å¾ˆå¸¸ç”¨ï¼Œå¯¹äºMoEæ¨¡å‹ï¼Œå®ƒçš„routerçš„top-kæ“ä½œæ˜¯ä¸å¯å¾®åˆ†çš„ï¼Œå®ƒå¦‚ä½•å®ç°æ¢¯åº¦çš„åå‘ä¼ æ’­ï¼Ÿ

---

### ğŸ¤– Assistant

ç®€çŸ­ç­”æ¡ˆå…ˆç»™ç»“è®ºï¼šåœ¨ MoE çš„è·¯ç”±ï¼ˆrouterï¼‰é‡Œï¼Œ`top-k` æ˜¯ä¸å¯å¾®çš„â€”â€”æ‰€ä»¥å¸¸ç”¨çš„æ–¹æ³•æ˜¯æŠŠâ€œç¡¬çš„ top-kâ€æ›¿æ¢æˆ**å¯å¾®çš„è¿ç»­æ¾å¼› / å¯é‡å‚æ•°åŒ–é‡‡æ ·ï¼ˆGumbel-Softmax / Gumbel-Top-k / top-k relaxationsï¼‰**ï¼Œæˆ–è€…åœ¨å‰å‘ç”¨ç¡¬é€‰æ‹©ä½†åå‘ç”¨**ç›´é€šä¼°è®¡ï¼ˆSTEï¼‰**ï¼Œæ›´ä¸¥è°¨çš„åœºæ™¯ä¼šç”¨åŸºäº control-variates çš„ä½æ–¹å·®æ— åä¼°è®¡ï¼ˆREBAR/RELAXï¼‰æ¥é™ä½æ–¹å·®å¹¶ä¿ç•™æ— åæ€§ã€‚ä¸‹é¢æŠŠæœºåˆ¶ã€å…¬å¼ã€å¸¸ç”¨å˜ä½“å’Œå·¥ç¨‹å®æˆ˜ç»†èŠ‚è®²æ¸…æ¥šã€‚

---

# 1) åŸºæœ¬æœºåˆ¶ï¼šGumbel-Softmaxï¼ˆè¿ç»­æ¾å¼›ï¼‰

Gumbel-Softmaxï¼ˆåˆå Concreteï¼‰æŠŠç¦»æ•£ one-hot é‡‡æ ·æ›¿æ¢ä¸ºå¯å¯¼çš„å‘é‡ã€‚åšæ³•æ˜¯ï¼šå¯¹æ¯ä¸ªä¸“å®¶ i å¯¹åº”çš„ logit ( \alpha_i ) åŠ ä¸Š Gumbel å™ªå£° (g_i)ï¼Œå†åšå¸¦æ¸©åº¦ Ï„ çš„ softmaxï¼š
[
s_i = \frac{\log\alpha_i + g_i}{\tau},\qquad
y_i = \frac{\exp(s_i)}{\sum_j \exp(s_j)}.
]
å½“ Ï„â†’0 æ—¶ (y) è¶‹è¿‘ one-hotï¼›è®­ç»ƒæ—¶ç”¨ Ï„>0ï¼ˆå¹¶å¸¸åšé€€ç«ï¼‰ä»¥è®©æ¢¯åº¦ç¨³å®šã€‚Gumbel-Softmax çš„å…³é”®ç‚¹æ˜¯**å¯é‡å‚æ•°åŒ–**ï¼Œå› æ­¤å¯ä»¥æŠŠæ¢¯åº¦é€šè¿‡ (y) åä¼ å› router çš„ logitsã€‚([arXiv][1])

åœ¨ MoE ä¸­æŠŠ `top-k` æ”¹ä¸ºâ€œå¯¹ logits åŠ  Gumbel å™ªå£°å†åš softmax/relaxationâ€åï¼Œä½ ä¼šå¾—åˆ°ä¸€ç»„ç¨ å¯†/æ¥è¿‘ç¨€ç–çš„æƒé‡ (y)ï¼Œç”¨å®ƒä»¬å»åŠ æƒï¼ˆæˆ–éƒ¨åˆ†åŠ æƒåå† dispatchï¼‰å„ä¸“å®¶çš„è¾“å…¥ï¼Œä»è€Œå®ç°ç«¯åˆ°ç«¯çš„æ¢¯åº¦æµã€‚([Eric X. Liu's Personal Page][2])

---

# 2) ä» 1â†’kï¼ˆGumbel-Top-k / å¯é‡å‚æ•°åŒ–å­é›†é‡‡æ ·ï¼‰

Gumbel-Max å¯ä»¥æ‰©å±•åˆ° top-kï¼ˆGumbel-Top-kï¼‰ï¼šå¯¹ logits åŠ  Gumbel å™ªå£°åå– k ä¸ªæœ€å¤§é¡¹å¯ä»¥è§†ä¸ºæ— æ›¿æ¢é‡‡æ ·ã€‚è¦åœ¨è®­ç»ƒä¸­åå‘ä¼ æ’­ï¼Œéœ€è¦æŠŠè¿™ä¸€æ­¥åšè¿ç»­æ¾å¼›ï¼ˆå¦‚ RelaxedTopK / differentiable top-k relaxations / reparameterizable subset samplingï¼‰ã€‚ç›¸å…³å·¥ä½œç»™å‡ºäº†æŠŠ top-k å˜æˆå¯å¾®è¿‘ä¼¼çš„æ–¹æ³•å¹¶è¯æ˜äº†å¯é‡å‚æ•°åŒ–æ¢¯åº¦ã€‚å¸¸ç”¨å¼•ç”¨æœ‰ Kool et al.ï¼ˆGumbel-Top-kï¼‰ä»¥åŠ Xie & Ermonã€ä»¥åŠåç»­çš„ top-k relaxations æ–‡çŒ®ã€‚([arXiv][3])

å®æ“ä¸¤ç§åšæ³•å¸¸è§ï¼š

* **è½¯åˆ†é…ï¼ˆsoft routingï¼‰**ï¼šç›´æ¥ç”¨ Gumbel-Softmax çš„ (y)ï¼ˆç¨ å¯†å‘é‡ï¼Œæ¥è¿‘ç¨€ç–ï¼‰ï¼ŒæŒ‰æƒé‡æŠŠ token åˆ†é…åˆ°æ‰€æœ‰ä¸“å®¶ï¼ˆè®¡ç®—é‡å¤§ä½†æ¢¯åº¦å¹²å‡€ï¼‰ï¼›
* **ç¡¬ top-k + åå‘ç”¨è½¯æ¢¯åº¦ï¼ˆSTEï¼‰**ï¼šå‰å‘ç¡¬é€‰æ‹© k ä¸ªä¸“å®¶ä»¥èŠ‚çº¦è®¡ç®—ï¼å†…å­˜ï¼Œåå‘æŠŠæ¢¯åº¦å½“ä½œæµç»å¯¹åº”çš„è½¯ (y)ï¼ˆæˆ–ç›´æ¥æŠŠ argmax å½“æ’ç­‰æ˜ å°„ï¼‰ï¼Œå³ Straight-Throughã€‚ä¸¤è€…æ˜¯å·¥ç¨‹å¸¸ç”¨æŠ˜è¡·ã€‚([NeurIPS Papers][4])

---

# 3) ç›´é€šä¼°è®¡ï¼ˆSTEï¼‰ä¸å·¥ç¨‹å®è·µ

STE çš„åšæ³•ï¼šå‰å‘ç”¨ç¡¬çš„ top-k maskï¼ˆèŠ‚çœè®¡ç®—ï¼Œæ–¹ä¾¿å®ç° capacity é™åˆ¶ï¼‰ï¼Œåå‘æŠŠ mask çš„æ¢¯åº¦æ›¿æ¢æˆè½¯æ¾å¼›ï¼ˆå¦‚ softmax æˆ– Gumbel-Softmax çš„æ¢¯åº¦ï¼‰ã€‚ä¼˜ç‚¹æ˜¯å®ç°ç®€å•ã€æ•ˆç‡é«˜ï¼Œæ˜¯å¾ˆå¤šå¤§è§„æ¨¡ MoEï¼ˆåŒ…æ‹¬å·¥ç¨‹å®ç°ï¼‰å¸¸ç”¨çš„ trickï¼›ç¼ºç‚¹æ˜¯**æœ‰å**ï¼Œå¯èƒ½å¼•å…¥è®­ç»ƒä¸ç¨³å®šæˆ–æ¬¡ä¼˜è§£ï¼Œéœ€è¦é…åˆå…¶ä»–ç¨³å®šæ‰‹æ®µï¼ˆload balancingã€æ¸©åº¦ç­–ç•¥ã€æ¢¯åº¦è£å‰ªç­‰ï¼‰ã€‚æœ‰å·¥ä½œå¯¹æ¯”è¿‡ ST-Gumbelã€REINFORCEã€DSelect-k ç­‰ï¼Œå¹¶æŠ¥å‘Šäº†ä¸åŒæ–¹æ³•åœ¨æ”¶æ•›/æ€§èƒ½ä¸Šçš„å·®å¼‚ã€‚([arXiv][5])

Switch/GShard/Feedus ç­‰å¤§è§„æ¨¡ MoE å®ç°ä½¿ç”¨ noisy top-k / top-1 æˆ– top-2 ç­–ç•¥å¹¶é…åˆè¾…åŠ©è´Ÿè½½å¹³è¡¡æŸå¤±ï¼ˆaux load-balance lossï¼‰ï¼Œè¿™ä¹Ÿå½±å“ router çš„æ¢¯åº¦è·¯å¾„ â€”â€” æ³¨æ„å¾ˆå¤š load-balance é¡¹æ˜¯åœ¨ soft logits / probs ä¸Šè®¡ç®—çš„ï¼Œä»è€Œé—´æ¥ç»™ router æä¾›å…‰æ»‘æ¢¯åº¦ä¿¡å·ã€‚([arXiv][6])

---

# 4) å¦‚æœè¦ã€Šæ— åä¸”ä½æ–¹å·®ã€‹â€”â€”REBAR / RELAXï¼ˆcontrol variateï¼‰

Gumbel-Softmax ç»™å‡º**æœ‰åä½†ä½æ–¹å·®**çš„æ¢¯åº¦ä¼°è®¡ï¼›è‹¥ä½ æƒ³è¦**æ— åä¸”ä½æ–¹å·®**çš„ä¼°è®¡ï¼ˆä½†ä»˜å‡ºå®ç°å¤æ‚åº¦ï¼‰ï¼Œå¯ç”¨ REBAR / RELAX é‚£ç±»æŠŠ score-functionï¼ˆREINFORCEï¼‰å’Œè¿ç»­æ¾å¼›ç»“åˆçš„ control-variate æŠ€æœ¯ï¼ˆå®ƒä»¬åˆ©ç”¨ relaxations ä½œ control variate æ¥å¤§å¹…é™æ–¹å·®ï¼Œç†è®ºä¸Šå¯æ¢å¤æ— åæˆ–è¿‘ä¼¼æ— åï¼‰ã€‚è¿™äº›æ–¹æ³•åœ¨ç†è®ºä¸Šå¾ˆå¥½ï¼Œä½†åœ¨å¤§è§„æ¨¡ MoE ä¸Šå·¥ç¨‹å®ç°å’Œè°ƒå‚æ›´éš¾ã€‚([arXiv][7])

---

# 5) ä¸€äº›å·¥ç¨‹ç»†èŠ‚ / æ¨èå®è·µï¼ˆMoE è·¯ç”±åœºæ™¯ï¼‰

* ä¼˜å…ˆå°è¯• **Gumbel-Softmaxï¼ˆæˆ– Gumbel-Top-k çš„è¿ç»­ relaxationï¼‰** + æ¸©åº¦é€€ç«ï¼šå®¹æ˜“å®ç°ä¸”æ¢¯åº¦ç¨³å®šã€‚ç›‘æ§ Ï„ è°ƒåº¦ï¼ˆä¾‹å¦‚ä» 1 â†’ 0.1 â†’ 0.01ï¼‰ã€‚([arXiv][1])
* å¦‚æœå¿…é¡»ä¸¥æ ¼ç¨€ç–ä»¥èŠ‚çº¦è®¡ç®—ï¼ˆå¸¸è§ï¼‰ï¼Œç”¨ **ç¡¬ top-k å‰å‘ + STE åå‘**ï¼Œå¹¶**åŒæ—¶åœ¨ logits æ¦‚ç‡ä¸Šè®¡ç®—è´Ÿè½½å¹³è¡¡æŸå¤±**ï¼ˆè¿™æ · router èƒ½è·å¾—å¹³æ»‘çš„è´Ÿè½½å¯¼æ•°ä¿¡å·ï¼‰ã€‚Fedus ç­‰äººåœ¨ Switch Transformer / GShard çš„å®ç°é‡Œå°±æ˜¯ç±»ä¼¼æ€è·¯ã€‚([arXiv][6])
* è‹¥é¢å¯¹é«˜æ–¹å·®æ¢¯åº¦ï¼ˆè®­ç»ƒä¸ç¨³å®šã€æ”¶æ•›æ…¢ï¼‰ï¼Œè€ƒè™‘**å¤šæ ·æœ¬ä¼°è®¡ / baseline / RELAX/REBAR** ç±»æ–¹æ³•æ¥é™æ–¹å·®ï¼Œä½†å®ƒä»¬å®ç°å¤æ‚ä¸”è®¡ç®—æ›´è´µã€‚([arXiv][7])
* å°å¿ƒ capacityï¼ˆä¸“å®¶æ¥æ”¶çš„ token æ•°ï¼‰å’Œåå¤„ç†ï¼ˆdrop/overflowï¼‰ï¼Œè¿™äº›ä¼šæ”¹å˜æ¢¯åº¦è·¯å¾„ä¸è®­ç»ƒåŠ¨åŠ›å­¦â€”â€”å¸¸ç”¨åšæ³•æ˜¯é™åˆ¶æ¯ä¸ªä¸“å®¶çš„ capacity å¹¶åœ¨è¶…è¿‡ capacity æ—¶æˆªæ–­/é‡åˆ†é…ã€‚([arXiv][6])

---

# ä»£ç å±‚é¢çš„ä¼ªå®ç°ï¼ˆæ€è·¯ï¼ŒPyTorch é£æ ¼ï¼‰

```python
# logits: [batch, num_experts]
g = -torch.log(-torch.log(torch.rand_like(logits)))      # Gumbel noise
s = (logits.log_softmax(dim=-1) + g) / tau
y_soft = torch.softmax(s, dim=-1)                        # Gumbel-Softmax (å¯å¾®)
# ç¡¬ top-k å‰å‘ï¼ˆèŠ‚çœè®¡ç®—ï¼‰
topk_vals, topk_idx = torch.topk(y_soft, k, dim=-1)
mask = torch.zeros_like(y_soft).scatter(-1, topk_idx, 1.0)
# Straight-through: forward use mask, backward use y_soft
y_hard = (mask - y_soft).detach() + y_soft
# dispatch: æŒ‰ y_hard æˆ– topk mask æŠŠ token åˆ†é…ç»™ä¸“å®¶
```

ä¸Šé¢ `y_hard` æ˜¯ STEï¼šå‰å‘ç¨€ç–ï¼ˆmaskï¼‰ï¼Œåå‘æµè¿‡ `y_soft`ã€‚è¦æ³¨æ„ capacityã€å½’ä¸€åŒ–å’Œ load balancing æŸå¤±çš„è®¡ç®—ï¼ˆé€šå¸¸åŸºäº `y_soft` / logitsï¼‰ã€‚

---

# æ¨èè¯»ç‰©ï¼ˆå¿«é€Ÿå…¥å£ï¼‰

* *Categorical Reparameterization with Gumbel-Softmax*ï¼ˆJang et al., ICLR 2017ï¼‰â€”â€” Gumbel-Softmax / Concreteã€‚([arXiv][1])
* *The Gumbel-Top-k trick*ï¼ˆKool et al., 2019ï¼‰ä¸ Xie & Ermon çš„ reparameterizable subset samplingï¼ˆtop-k relaxationsï¼‰ã€‚([arXiv][3])
* *Switch Transformer / GShard*ï¼ˆFedus et al., 2021ï¼‰â€”â€” å·¥ç¨‹åŒ–çš„ noisy top-kã€capacityã€load-balance åšæ³•ç¤ºä¾‹ã€‚([arXiv][6])
* *REBAR / RELAX*ï¼ˆTucker et al., Grathwohl et al.ï¼‰â€”â€” control-variate é™æ–¹å·®æ–¹æ³•ã€‚([arXiv][7])

---

å¦‚æœä½ æƒ³è¦æˆ‘åšä¸‹ä¸€æ­¥ï¼š

* æˆ‘å¯ä»¥åŸºäºä½ å½“å‰çš„ router å®ç°ï¼ˆè´´å‡º logits è®¡ç®—ã€æ˜¯å¦éœ€è¦ç¡¬ç¨€ç–ã€expert æ•°é‡ã€æ˜¯å¦æœ‰ capacityã€ä½ ç”¨çš„æ¡†æ¶ï¼‰ç»™å‡º**å¯è¿è¡Œçš„ PyTorch/TF ä»£ç ç‰‡æ®µ**ï¼ˆå«æ¸©åº¦ scheduleã€load-balance lossã€STE å®ç°ä¸ debug æŒ‡æ ‡ï¼‰ï¼›
* æˆ–è€…æˆ‘å¯ä»¥æŠŠ Gumbel-Top-k çš„è¿ç»­ relaxationï¼ˆè®ºæ–‡å®ç°ï¼‰æ•´ç†æˆä¸€æ®µå¯å¤åˆ¶çš„å®ç°å¹¶è¯´æ˜æ•°å€¼ç»†èŠ‚ï¼ˆå¦‚ä½•æŠ½æ ·ã€å¦‚ä½•å½’ä¸€åŒ–ã€å¦‚ä½•åšå¤šä¸ªæ ·æœ¬ä»¥é™ä½æ–¹å·®ï¼‰ã€‚

ä½ è¦å“ªä¸€ç§ï¼Ÿæˆ‘å¯ä»¥ç›´æ¥æŠŠä»£ç è´´å‡ºæ¥ã€‚

[1]: https://arxiv.org/abs/1611.01144?utm_source=chatgpt.com "Categorical Reparameterization with Gumbel-Softmax"
[2]: https://ericxliu.me/posts/mixture-of-experts-moe-models-challenges-solutions-in-practice/?utm_source=chatgpt.com "Mixture-of-Experts (MoE) Models Challenges & Solutions in ..."
[3]: https://arxiv.org/pdf/1903.06059?utm_source=chatgpt.com "The Gumbel-Top-k Trick for Sampling Sequences Without ..."
[4]: https://papers.neurips.cc/paper_files/paper/2020/file/ec24a54d62ce57ba93a531b460fa8d18-Paper.pdf?utm_source=chatgpt.com "Differentiable Top-k with Optimal Transport"
[5]: https://arxiv.org/html/2306.03745v2?utm_source=chatgpt.com "Soft Merging of Experts with Adaptive Routing"
[6]: https://arxiv.org/pdf/2101.03961?utm_source=chatgpt.com "arXiv:2101.03961v3 [cs.LG] 16 Jun 2022"
[7]: https://arxiv.org/abs/1703.07370?utm_source=chatgpt.com "REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models"
