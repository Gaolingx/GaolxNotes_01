# SFT指令微调数据构建指南

### 🧑‍💻 User

SFT指令微调数据如何构建？

---

### 🤖 Assistant

监督式微调（Supervised Fine-Tuning, SFT）数据的构建是优化大模型性能的关键步骤。以下是系统化的方法和注意事项：

---

### 一、明确SFT数据目标
1. **对齐模型能力**：增强模型在特定任务（如问答、摘要、代码生成）上的表现。
2. **覆盖多样性**：涵盖不同任务、领域和复杂度的样本。
3. **提升指令遵循能力**：让模型理解并响应多样化的人类指令形式。

---

### 二、数据构建流程

#### 1. **任务与数据源定义**
   - **来源选择**：
     - **人工标注**：通过众包平台（如Amazon Turk）或专业团队创建高价值数据。
     - **开源数据集**：利用现有基准数据集（如SST-2、MNLI）或领域专用数据（如医疗、金融）。
     - **用户反馈**：通过A/B测试收集用户交互中的优质示例。
   - **示例参考**：
     - 开源SFT数据集：[Open Assistant](https://open-assistant.io/), [Dolly 2](https://www.databricks.com/blog/2023/04/12/dolly-2-0-instruction-tuned-everyday-language-model)。
     - 许可数据集：[ShareGPT](https://sharegpt.com/)。

#### 2. **数据清洗与去重
   - **去噪**：使用规则（如正则表达式）或模型（如FastText）检测并移除广告、特殊符号。
   - **去重**：通过SimHash或MinHash算法识别重复或高度相似的样本。
   - **敏感信息处理**：用PII检测工具（如PROD角色）过滤敏感数据。

#### 3. **数据多样性增强
   - **指令工程**：
     - 为同一任务设计不同视角的指令（如“总结一下”、“用一句话重述”）。
     - 模板替换法生成变体（如“解释[概念]” → “[概念]是什么？”）。
   - **数据增强**：
     - 回译（Back Translation）：将英文句子翻译回中文以生成复述。
     - 同义词替换：使用WordNet、BERT掩码预测结果替换同义词。
   - **对抗生成**：
     - 利用对抗样本（如输入扰动）生成困难样本，提升模型健壮性。

#### 4. **质量控制
   - **人工评审**：
     - 召集标注员多维度评分（相关性、冗余度、毒性检测）。
     - 使用Krippendorff's α等统计量计算标注者间一致性。
   - **模型验证**：
     - 让大模型自身判断输出质量（如打分、排序）。

---

### 三、数据划分策略
| 集合类型 | 比例 | 目的 |
|----------|------|------|
| 训练集 | 70%  | 优化模型参数 |
| 验证集 | 15%  | 早停与超参数调优 |
| 测试集 | 15%  | 无信息泄露的最终评估 |

- **领域适配**：若目标领域（如法律）数据量少，可采用K折交叉验证。
- **时间序列数据**：按时间切片确保未来信息不泄露。

---

### 四、进阶技巧

#### 1. **课程学习（Curriculum Learning）**
   - **实现方式**：将训练阶段划分为“简单-中等-困难”难度的任务。
   - **示例**：先训练模型做加减法，再逐步引入多步推理任务。

#### 2. **少样本学习（Few-shot）**
   - **思维链（Chain-of-Thought, CoT）**：
     ```markdown
     问题：约翰有3个苹果，玛丽有5个苹果，他们一共有多少个苹果？
     思维链：首先，确定约翰和玛丽各自的苹果数量。约翰有3个，玛丽有5个。然后将两人的苹果数量相加。3 + 5 = 8。所以他们一共有8个苹果。
     答案：他们一共有8个苹果。
     ```
   - **多任务学习**：将多个任务（如翻译+摘要）合并输入，鼓励模型学习跨任务表征。

#### 3. **评估指标设计**
   - **自定义损失函数**：对复杂样本（如法律合同）增加权重。
   - **人工评估**：
     - **BLEU/NIST**：侧重n-gram匹配。
     - **ROUGE-L**：评估最长公共子序列。
     - **BERTScore**：基于上下文的语义匹配。

---

### 五、伦理与偏见控制
1. **偏见检测**：
   - 构建包含刻板印象的模板（如“作为...，我推荐...”），用预训练模型检测偏差词。
   - 使用WeBias库检测性别、种族等偏见。
2. **数据增强对抗偏见**：
   - 通过反事实数据生成（Counterfactual Data Augmentation）平衡样本。例如，将“护士”替换为“工程师”并反转性别代词。

---

### 六、数据格式与工具链
- **标准格式**（JSON Lines示例）：
  ```json
  {"instruction": "将给定的英文句子翻译成法语：Hello, how are you?", "input": "Hello, how are you?", "output": "Bonjour, comment ça va ?"}
  ```
- **工具推荐**：
  - **数据标注**：Label Studio, Prodigy
  - **质量分析**：GEM Metrics Toolkit
  - **自动化构建**：HuggingFace Datasets, OpenAI API（提示工程）

---

### 七、实验与迭代优化
1. **基线测试**：在相同验证集上比较不同清洗策略（如去重、去敏感词）的效果。
2. **错误分析**：
   - 构建混淆矩阵，识别模型在哪些类别上表现不佳。
   - 通过t-SNE可视化潜在的嵌入空间冲突。
3. **A/B测试**：在生产环境中测试不同数据策略的实际效果。

---

通过以上步骤，可以系统化地构建高质量SFT数据，显著提升模型在目标领域的表现。