# DeepSpeedè®­ç»ƒä¼˜åŒ–é…ç½®æŒ‡å—

### ğŸ§‘â€ğŸ’» User

åœ¨deepspeedè®­ç»ƒllmä¸­ï¼Œä¸ºäº†è§£å†³æ˜¾å­˜èµ„æºæœ‰é™çš„æƒ…å†µï¼Œä½†æ˜¯åˆè¦å°½å¯èƒ½å‡å°‘é€šä¿¡å¼€é”€ï¼Œèƒ½å¦ä½¿ç”¨autoTP+zero1ä»£æ›¿zero3ï¼Œé‚£å¦‚ä½•åœ¨llama-factoryé…ç½®ä»–ï¼Ÿ

---

### ğŸ¤– Assistant

åœ¨ DeepSpeed ä¸­ï¼Œä¸ºäº†åœ¨æ˜¾å­˜æœ‰é™çš„æƒ…å†µä¸‹å‡å°‘é€šä¿¡å¼€é”€ï¼Œä½¿ç”¨ **AutoTP (Tensor Parallelism) + ZeRO Stage 1 (ZeRO-1)** æ›¿ä»£ **ZeRO Stage 3 (ZeRO-3)** æ˜¯ä¸€ä¸ª**éå¸¸åˆç†ä¸”æ¨è**çš„ç­–ç•¥ã€‚ä½ çš„ç†è§£å®Œå…¨æ­£ç¡®ã€‚

### ä¸ºä»€ä¹ˆ AutoTP + ZeRO-1 æ˜¯ ZeRO-3 çš„è‰¯å¥½æ›¿ä»£æ–¹æ¡ˆï¼ˆåœ¨æ˜¾å­˜å’Œé€šä¿¡å¼€é”€ä¹‹é—´æƒè¡¡ï¼‰ï¼Ÿ

1.  **æ˜¾å­˜èŠ‚çœå¯¹æ¯”ï¼š**
    *   **ZeRO-3:** æä¾›æœ€å¼ºçš„æ˜¾å­˜èŠ‚çœã€‚å®ƒå°†ä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦å’Œ**æ¨¡å‹å‚æ•°**éƒ½è¿›è¡Œåˆ‡åˆ†ã€‚æ¯ä¸ª GPU åªä¿å­˜å®ƒè´Ÿè´£è®¡ç®—çš„é‚£éƒ¨åˆ†å‚æ•°çš„å®Œæ•´çŠ¶æ€ï¼ˆä¼˜åŒ–å™¨çŠ¶æ€ã€æ¢¯åº¦ã€å‚æ•°æœ¬èº«ï¼‰ã€‚å…¶ä»–å‚æ•°åœ¨éœ€è¦æ—¶é€šè¿‡é€šä¿¡è·å–ã€‚
    *   **AutoTP + ZeRO-1:** ä¹Ÿæä¾›æ˜¾è‘—çš„æ˜¾å­˜èŠ‚çœã€‚
        *   **ZeRO-1:** ä»…åˆ‡åˆ†**ä¼˜åŒ–å™¨çŠ¶æ€**ã€‚æ¯ä¸ª GPU ä¿å­˜å®Œæ•´çš„æ¨¡å‹å‚æ•°å’Œæ¢¯åº¦ï¼Œä½†åªä¿å­˜è‡ªå·±è´Ÿè´£æ›´æ–°çš„é‚£éƒ¨åˆ†å‚æ•°çš„ä¼˜åŒ–å™¨çŠ¶æ€ã€‚è¿™èŠ‚çœäº†ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆé€šå¸¸æ˜¯æ˜¾å­˜å¤§æˆ·ï¼‰å’Œç›¸åº”çš„å‚æ•°æ›´æ–°é€šä¿¡ã€‚
        *   **AutoTP:** åœ¨æ¨¡å‹å±‚å†…éƒ¨ï¼ˆå¦‚ Linear, Embedding, Attentionï¼‰è¿›è¡Œ**æ¨¡å‹å¹¶è¡Œ**ã€‚å°†å¤§çš„æƒé‡çŸ©é˜µåˆ‡åˆ†åˆ°å¤šä¸ª GPU ä¸Šã€‚è¿™ç›´æ¥å‡å°‘äº†**æ¯ä¸ª GPU ä¸Šæ¨¡å‹å‚æ•°å’Œè®¡ç®—æ¿€æ´»å€¼**çš„æ˜¾å­˜å ç”¨ã€‚åŒæ—¶ï¼ŒTP çš„è®¡ç®—æ˜¯å¹¶è¡Œçš„ã€‚
    *   **æ€»ç»“ï¼š** ZeRO-3 > (AutoTP + ZeRO-1) > çº¯æ•°æ®å¹¶è¡Œã€‚ä½† AutoTP+ZeRO-1 é€šå¸¸æ¯” ZeRO-3 å ç”¨ç•¥å¤šæ˜¾å­˜ï¼ˆå› ä¸ºæ¯ä¸ª GPU å­˜æœ‰å®Œæ•´å‚æ•°å‰¯æœ¬ï¼‰ï¼Œä½†è¿œå°‘äºçº¯æ•°æ®å¹¶è¡Œã€‚

2.  **é€šä¿¡å¼€é”€å¯¹æ¯”ï¼š**
    *   **ZeRO-3:** é€šä¿¡å¼€é”€**æœ€å¤§**ã€‚å› ä¸ºå®ƒéœ€è¦åœ¨æ­£å‘ä¼ æ’­ï¼ˆè·å–è¿œç¨‹å‚æ•°ï¼‰ã€åå‘ä¼ æ’­ï¼ˆè·å–è¿œç¨‹å‚æ•°è®¡ç®—æ¢¯åº¦ï¼‰ã€ä¼˜åŒ–å™¨æ­¥éª¤ï¼ˆæ”¶é›†/åˆ‡åˆ†æ¢¯åº¦ã€æ›´æ–°å‚æ•°ï¼‰ä¸­è¿›è¡Œå¤§é‡ç²¾ç»†ç²’åº¦çš„é€šä¿¡ï¼ˆ`all_gather`, `reduce_scatter`ï¼‰ã€‚å°¤å…¶æ˜¯åœ¨è·¨èŠ‚ç‚¹ï¼ˆæ…¢é€Ÿç½‘ç»œï¼‰æ—¶ï¼Œå¼€é”€æ˜¾è‘—ã€‚
    *   **AutoTP + ZeRO-1:** é€šä¿¡å¼€é”€**æ˜¾è‘—ä½äº ZeRO-3**ã€‚
        *   **ZeRO-1:** åªåœ¨æ¢¯åº¦è®¡ç®—å®Œæˆåï¼Œè¿›è¡Œ**ä¸€æ¬¡å…¨å±€çš„æ¢¯åº¦ `allreduce`**ï¼ˆç”¨äºè®¡ç®—å¹³å‡æ¢¯åº¦ï¼Œå› ä¸ºæ•°æ®å¹¶è¡Œï¼‰ã€‚åœ¨ä¼˜åŒ–å™¨æ­¥éª¤ä¸­ï¼Œæ¯ä¸ª GPU ç‹¬ç«‹æ›´æ–°è‡ªå·±è´Ÿè´£çš„é‚£éƒ¨åˆ†å‚æ•°ï¼Œ**ä¸éœ€è¦å‚æ•°é€šä¿¡**ã€‚`allreduce` æ˜¯å¸¦å®½ä¼˜åŒ–è¿‡çš„é›†åˆé€šä¿¡æ“ä½œã€‚
        *   **AutoTP:** åœ¨æ¨¡å‹å±‚å†…éƒ¨è¿›è¡Œé€šä¿¡ï¼ˆä¾‹å¦‚ `allreduce`, `all_gather`ï¼‰ã€‚è¿™äº›é€šä¿¡é€šå¸¸å‘ç”Ÿåœ¨è®¡ç®—å¯†é›†çš„ç®—å­å†…éƒ¨ï¼Œå¹¶ä¸”é€šå¸¸æ˜¯**åœ¨å•ä¸ªèŠ‚ç‚¹å†…çš„ GPU ä¹‹é—´**ï¼ˆé€šè¿‡ NVLink/PCIeï¼Œå¸¦å®½é«˜ï¼Œå»¶è¿Ÿä½ï¼‰ã€‚TP çš„é€šä¿¡å¼€é”€ç›¸å¯¹å›ºå®šï¼Œä¸”é€šå¸¸æ¯” ZeRO-3 çš„ç»†ç²’åº¦é€šä¿¡æ¨¡å¼æ›´é«˜æ•ˆï¼Œå°¤å…¶æ˜¯åœ¨èŠ‚ç‚¹å†…ã€‚
    *   **æ€»ç»“ï¼š** ZeRO-3 > (AutoTP + ZeRO-1) > çº¯æ•°æ®å¹¶è¡Œã€‚AutoTP+ZeRO-1 çš„é€šä¿¡æ¨¡å¼æ›´ç²—ç²’åº¦ã€æ›´é›†ä¸­ï¼Œå¹¶ä¸” TP é€šä¿¡åœ¨é«˜é€ŸèŠ‚ç‚¹å†…è¿›è¡Œï¼Œæ•´ä½“å¼€é”€è¿œå°äº ZeRO-3ã€‚

3.  **é€‚ç”¨åœºæ™¯ï¼š**
    *   **ZeRO-3:** å½“æ¨¡å‹**æå¤§**ï¼Œå³ä½¿ä½¿ç”¨ TP ä¹Ÿæ— æ³•è£…å…¥å•èŠ‚ç‚¹æ‰€æœ‰ GPU çš„æ˜¾å­˜æ€»å’Œæ—¶æ˜¯å¿…è¦çš„ã€‚ç‰ºç‰²é€šä¿¡æ•ˆç‡æ¢å–æœ€å¤§çš„æ¨¡å‹å®¹é‡ã€‚
    *   **AutoTP + ZeRO-1:** å½“æ¨¡å‹å¯ä»¥**é€šè¿‡ TP åœ¨å•èŠ‚ç‚¹ï¼ˆæˆ–å°‘é‡èŠ‚ç‚¹ï¼‰çš„ GPU æ˜¾å­˜å†…æ”¾ä¸‹**æ—¶ï¼Œè¿™æ˜¯**æ›´ä¼˜çš„é€‰æ‹©**ã€‚å®ƒåœ¨æä¾›å¯è§‚æ˜¾å­˜èŠ‚çœçš„åŒæ—¶ï¼Œä¿æŒäº†ç›¸å¯¹è¾ƒä½çš„é€šä¿¡å¼€é”€ï¼Œè®­ç»ƒæ•ˆç‡æ›´é«˜ã€‚ç‰¹åˆ«æ˜¯å¯¹äºèŠ‚ç‚¹å†… NVLink è¿æ¥è‰¯å¥½çš„ç¯å¢ƒï¼ŒTP é€šä¿¡éå¸¸å¿«ã€‚

### å¦‚ä½•åœ¨ LLaMA-Factory ä¸­é…ç½® AutoTP + ZeRO-1

LLaMA-Factory å†…éƒ¨é›†æˆäº† DeepSpeedï¼Œé…ç½®ä¸»è¦é€šè¿‡ `arguments` (`src/llmtuner/hparams/ds_train_args.py` å’Œç›¸å…³å‘½ä»¤è¡Œå‚æ•°) å’Œ DeepSpeed é…ç½®æ–‡ä»¶ (`ds_config.json` æˆ– `ds_config_zero*.json`) æ¥å®ç°ã€‚

ä»¥ä¸‹æ˜¯é…ç½® AutoTP + ZeRO-1 çš„å…³é”®æ­¥éª¤ï¼š

1.  **å¯ç”¨ DeepSpeed å¹¶é€‰æ‹© ZeRO Stage 1:**
    *   ç¡®ä¿åœ¨å¯åŠ¨è®­ç»ƒå‘½ä»¤æ—¶ä¼ é€’ `--trainer_backend deepspeed`ã€‚
    *   ä½ éœ€è¦ä½¿ç”¨æˆ–åˆ›å»ºä¸€ä¸ª DeepSpeed é…ç½®æ–‡ä»¶æŒ‡å®š `"zero_optimization"` çš„ `"stage"` ä¸º `1`ã€‚
    *   é€šå¸¸å¯ä»¥å¤ç”¨æˆ–ä¿®æ”¹ LLaMA-Factory æä¾›çš„ ZeRO-1 é…ç½®æ–‡ä»¶ï¼Œä¾‹å¦‚ `ds_config_zero1.json`ã€‚æ£€æŸ¥è¯¥æ–‡ä»¶ç¡®ä¿ï¼š
        ```json
        "zero_optimization": {
            "stage": 1, // æ ¸å¿ƒé…ç½®é¡¹ï¼Œè®¾ç½®ä¸º1
            ... // å…¶ä»– ZeRO-1 ç›¸å…³å‚æ•°ï¼ˆé€šå¸¸é»˜è®¤å³å¯ï¼‰
        }
        ```

2.  **å¯ç”¨å¹¶é…ç½® Tensor Parallelism (AutoTP):**
    *   **å…³é”®ç‚¹ï¼š** LLaMA-Factory é€šè¿‡ `--template` å‚æ•°é—´æ¥æ”¯æŒ TPï¼Œä½†å…¶æ ¸å¿ƒ TP é…ç½®ä¾èµ–äº DeepSpeed é…ç½®å’Œå¯åŠ¨æ–¹å¼ã€‚
    *   åœ¨ DeepSpeed é…ç½®æ–‡ä»¶ä¸­ï¼Œ**å¯ç”¨** `"tensor_parallel"` æ¨¡å—å¹¶è®¾ç½®å¹¶è¡Œåº¦ `"tp_size"`ï¼š
        ```json
        "tensor_parallel": {
            "enabled": true, // å¯ç”¨ TP
            "tp_size": 2, // è®¾ç½® TP å¹¶è¡Œåº¦ï¼Œä¾‹å¦‚ 2 è¡¨ç¤ºåœ¨ 2 ä¸ª GPU ä¸Šåˆ‡åˆ†å¼ é‡ã€‚å¿…é¡»èƒ½è¢«æ€» GPU æ•°æ•´é™¤ã€‚
            ... // å…¶ä»– AutoTP å‚æ•°ï¼ˆé€šå¸¸é»˜è®¤å³å¯ï¼‰
        }
        ```
    *   **å¹¶è¡Œåº¦ (`tp_size`) é€‰æ‹©ï¼š** è¿™ä¸ªå€¼å¿…é¡»èƒ½æ•´é™¤ä½ ç”¨äºè®­ç»ƒçš„ **æ€» GPU æ•°é‡**ã€‚ä¾‹å¦‚ï¼Œä½ æœ‰ 4 ä¸ª GPUï¼š
        *   `"tp_size": 4`ï¼š 4 è·¯ TPã€‚æ•°æ®å¹¶è¡Œåº¦ä¸º 1 (4/4)ã€‚æ­¤æ—¶æ²¡æœ‰æ•°æ®å¹¶è¡Œï¼Œåªæœ‰æ¨¡å‹å¹¶è¡Œã€‚
        *   `"tp_size": 2`ï¼š 2 è·¯ TPã€‚æ•°æ®å¹¶è¡Œåº¦ä¸º 2 (4/2)ã€‚å½¢æˆ 2 ä¸ª TP ç»„ï¼Œæ¯ä¸ªç»„åŒ…å« 2 ä¸ª GPU è¿›è¡Œæ¨¡å‹å¹¶è¡Œï¼Œç»„é—´è¿›è¡Œæ•°æ®å¹¶è¡Œã€‚
        *   `"tp_size": 1`ï¼š ç¦ç”¨ TPã€‚çº¯æ•°æ®å¹¶è¡Œï¼ˆ4 è·¯ï¼‰ã€‚

3.  **è®¾ç½® `--deepspeed` å‚æ•°æŒ‡å‘é…ç½®æ–‡ä»¶ï¼š**
    *   åœ¨å¯åŠ¨è®­ç»ƒå‘½ä»¤æ—¶ï¼Œä½¿ç”¨ `--deepspeed` å‚æ•°æŒ‡å®šä½ ä¿®æ”¹å¥½çš„ DeepSpeed é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å« ZeRO-1 å’Œ TP é…ç½®çš„ï¼‰ã€‚
    *   ä¾‹å¦‚ï¼š `--deepspeed ds_config_zero1_tp2.json`

4.  **è°ƒæ•´ `--quantization_bit` å’Œ `--model_max_length` (å¯é€‰ä½†æ¨è)ï¼š**
    *   ä¸ºäº†è¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨ `--quantization_bit 4` (QLoRA) è¿›è¡Œ 4 ä½é‡åŒ–è®­ç»ƒã€‚
    *   æ ¹æ®ä½ çš„æ˜¾å­˜æƒ…å†µï¼Œé€‚å½“è°ƒæ•´ `--model_max_length` ä»¥æ§åˆ¶åºåˆ—é•¿åº¦ï¼Œè¿™å¯¹æ¿€æ´»å€¼æ˜¾å­˜å½±å“å¾ˆå¤§ã€‚

### ç¤ºä¾‹å¯åŠ¨å‘½ä»¤ (å‡è®¾ 4 ä¸ª GPU)

```bash
# æ ¸å¿ƒå‚æ•°:
# --trainer_backend deepspeed  : ä½¿ç”¨ DeepSpeed
# --deepspeed ds_config_zero1_tp2.json : æŒ‡å®šåŒ…å« ZeRO-1 å’Œ TP=2 çš„é…ç½®æ–‡ä»¶
# --template deepspeed : é€šå¸¸é€‰æ‹© deepspeed æ¨¡æ¿ (ç¡®ä¿ hf_parser æ­£ç¡®å¤„ç†äº† TP å‚æ•°)
# --quantization_bit 4 : ä½¿ç”¨ 4 ä½ QLoRA (å¯é€‰ï¼Œå¼ºçƒˆæ¨èèŠ‚çœæ˜¾å­˜)
# --model_max_length 512 : è®¾ç½®æœ€å¤§åºåˆ—é•¿åº¦ (æ ¹æ®æ˜¾å­˜è°ƒæ•´)
# --dataset your_data : ä½ çš„æ•°æ®é›†
# --model_name_or_path /path/to/llama-2-7b : æ¨¡å‹è·¯å¾„
# --output_dir /path/to/output : è¾“å‡ºç›®å½•

torchrun --nnodes 1 --nproc_per_node 4 \
    src/train_bash.py \
    --stage sft \
    --do_train \
    --model_name_or_path /path/to/your/base_model \
    --dataset your_dataset \
    --template deepspeed \  # æˆ–æ ¹æ®æ¨¡å‹é€‰æ‹©å¦‚ llama2, ä½†ç¡®ä¿æ”¯æŒ TP
    --finetuning_type lora \
    --lora_target q_proj,v_proj \ # æ ¹æ®æ¨¡å‹è°ƒæ•´
    --output_dir /path/to/save \
    --overwrite_output_dir \
    --per_device_train_batch_size 4 \ # æ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼Œè¿™æ˜¯ *æ¯ä¸ª GPU* çš„ batch size
    --gradient_accumulation_steps 4 \ # æ ¹æ®æ€» batch size è°ƒæ•´
    --lr_scheduler_type cosine \
    --logging_steps 10 \
    --save_steps 1000 \
    --learning_rate 5e-5 \
    --num_train_epochs 3.0 \
    --plot_loss \
    --fp16 \ # æˆ– bf16
    --trainer_backend deepspeed \
    --deepspeed ds_config_zero1_tp2.json \
    --quantization_bit 4 \ # å¦‚æœä½¿ç”¨ QLoRA
    --model_max_length 512
```

### å…³é”®é…ç½®æ–‡ä»¶å’Œå‚æ•°è§£é‡Š (`ds_config_zero1_tp2.json`)

```json
{
  "train_batch_size": "auto", // ç”±å‘½ä»¤è¡Œ per_device_train_batch_size * gradient_accumulation_steps * num_gpus è‡ªåŠ¨è®¡ç®—
  "train_micro_batch_size_per_gpu": "auto", // ç”±å‘½ä»¤è¡Œ per_device_train_batch_size è‡ªåŠ¨å¡«å……
  "gradient_accumulation_steps": "auto", // ç”±å‘½ä»¤è¡ŒåŒåå‚æ•°è‡ªåŠ¨å¡«å……
  "optimizer": {
    "type": "AdamW",
    "params": {
      "lr": "auto", // ç”±å‘½ä»¤è¡Œ learning_rate è‡ªåŠ¨å¡«å……
      "betas": "auto",
      "eps": "auto",
      "weight_decay": "auto"
    }
  },
  "scheduler": {
    "type": "auto" // ç”±å‘½ä»¤è¡Œ lr_scheduler_type è‡ªåŠ¨åŒ¹é…
  },
  "fp16": { // æˆ– "bf16": { ... } æ ¹æ®å‘½ä»¤è¡Œ --fp16/--bf16 è‡ªåŠ¨é€‰æ‹©
    "enabled": "auto",
    "loss_scale": 0,
    "loss_scale_window": 1000,
    "initial_scale_power": 16,
    "hysteresis": 2,
    "min_loss_scale": 1
  },
  "zero_optimization": {
    "stage": 1,  // æ ¸å¿ƒï¼šå¯ç”¨ ZeRO Stage 1 (ä¼˜åŒ–å™¨çŠ¶æ€åˆ‡åˆ†)
    "reduce_bucket_size": "auto", // é€šå¸¸ä¿æŒ auto æˆ–æ ¹æ®ç½‘ç»œè°ƒæ•´
    "allgather_bucket_size": "auto" // é€šå¸¸ä¿æŒ auto æˆ–æ ¹æ®ç½‘ç»œè°ƒæ•´
  },
  "tensor_parallel": { // æ ¸å¿ƒï¼šå¯ç”¨å¹¶é…ç½® Tensor Parallelism
    "enabled": true,
    "tp_size": 2, // å…³é”®ï¼šè®¾ç½® Tensor Parallel å¹¶è¡Œåº¦ä¸º 2 (åœ¨ 2 ä¸ª GPU ä¸Šåˆ‡åˆ†å¼ é‡)
    // ä»¥ä¸‹å‚æ•°é€šå¸¸ä¿æŒé»˜è®¤å³å¯ï¼ŒDeepSpeed çš„ AutoTP ä¼šè‡ªåŠ¨å¤„ç†åˆ‡åˆ†ç­–ç•¥
    "tp_consecutive_ranks": true, // åœ¨è¿ç»­ rank ä¸Šåš TP (å¯¹äºå•èŠ‚ç‚¹æ€»æ˜¯true)
    "pp_partition_method": null, // TP ä¸å…³å¿ƒ PP
    "tp_linear_layer_row_parallelism": true,
    "tp_linear_layer_col_parallelism": true,
    "tp_embedding_layer_col_parallelism": true,
    "tp_attention_row_parallelism": true,
    "tp_attention_col_parallelism": true,
    "tp_mlp_row_parallelism": true,
    "tp_mlp_col_parallelism": true
  },
  "activation_checkpointing": { // å¯é€‰ï¼šæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œè¿›ä¸€æ­¥èŠ‚çœæ˜¾å­˜ï¼Œä¼šå¢åŠ è®¡ç®—æ—¶é—´
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false
  },
  "gradient_clipping": "auto", // ç”±å‘½ä»¤è¡Œ max_grad_norm è‡ªåŠ¨å¡«å……
  "steps_per_print": 10, // å¯è°ƒæ•´
  "wall_clock_breakdown": false, // æ€§èƒ½åˆ†ææ—¶å¼€å¯
  "comms_logger": { // é€šä¿¡æ—¥å¿—ï¼Œè°ƒè¯•æ—¶å¼€å¯
    "enabled": false,
    "verbose": false,
    "prof_all": false,
    "debug": false
  }
}
```

### æ³¨æ„äº‹é¡¹

1.  **TP å…¼å®¹æ€§ï¼š** ç¡®ä¿ä½ çš„æ¨¡å‹ç»“æ„ï¼ˆå¦‚ Transformer å±‚ï¼‰æ”¯æŒ TPã€‚ä¸»æµçš„ Llamaã€GPT ç­‰æ¶æ„é€šå¸¸éƒ½æ”¯æŒã€‚TP ä¼šå°†æ¨¡å‹å±‚å†…çš„æƒé‡çŸ©é˜µåˆ‡åˆ†ã€‚æ³¨æ„æ¨¡å‹å‚æ•°ï¼ˆå¦‚æ³¨æ„åŠ›å¤´æ•° `num_attention_heads`, `num_key_value_heads`ï¼‰éœ€è¦èƒ½è¢« `tp_size` æ•´é™¤ã€‚
2.  **`tp_size` vs `world_size`:** `tp_size` å¿…é¡»èƒ½æ•´é™¤æ€» GPU æ•° (`world_size`)ã€‚å‰©ä¸‹çš„ç»´åº¦å°±æ˜¯æ•°æ®å¹¶è¡Œåº¦ (`dp_size = world_size / tp_size`)ã€‚
3.  **èŠ‚ç‚¹å†…é€šä¿¡ï¼š** TP çš„é€šä¿¡å‘ç”Ÿåœ¨è´Ÿè´£åŒä¸€æ¨¡å‹éƒ¨åˆ†çš„ GPU ä¹‹é—´ï¼ˆå³åŒä¸€ä¸ª TP ç»„å†…ï¼‰ã€‚ä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œ**å¼ºçƒˆå»ºè®®å°†åŒä¸€ä¸ª TP ç»„é…ç½®åœ¨åŒä¸€ä¸ªç‰©ç†èŠ‚ç‚¹å†…**ï¼ˆåˆ©ç”¨ NVLink/PCIe é«˜é€Ÿäº’è”ï¼‰ã€‚è·¨èŠ‚ç‚¹çš„ TP é€šä¿¡ï¼ˆé€šè¿‡è¾ƒæ…¢çš„ç½‘ç»œï¼‰ä¼šä¸¥é‡é™ä½æ€§èƒ½ã€‚LLaMA-Factory/DeepSpeed é»˜è®¤ä¼šåœ¨è¿ç»­ rank ä¸Šåˆ›å»º TP ç»„ (`"tp_consecutive_ranks": true`)ï¼Œè¿™é€šå¸¸èƒ½ä¿è¯ç»„å†… GPU åœ¨åŒä¸€ä¸ªèŠ‚ç‚¹ã€‚
4.  **æ£€æŸ¥ç‚¹å…¼å®¹æ€§ï¼š** ä½¿ç”¨ TP è®­ç»ƒåä¿å­˜çš„æ¨¡å‹æ£€æŸ¥ç‚¹æ˜¯åˆ†ç‰‡çš„ï¼ˆæ¯ä¸ª TP rank ä¿å­˜è‡ªå·±è´Ÿè´£çš„é‚£éƒ¨åˆ†ï¼‰ã€‚è¦åˆå¹¶æˆä¸€ä¸ªå®Œæ•´çš„æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œéœ€è¦ä½¿ç”¨ DeepSpeed æä¾›çš„åˆå¹¶å·¥å…· (`deepspeed.engine.module.DeepSpeedEngine.save_checkpoint` çš„ç‰¹å®šæ–¹å¼æˆ–è½¬æ¢è„šæœ¬ï¼‰ï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨ DeepSpeed Inferenceã€‚LLaMA-Factory çš„å¯¼å‡º/åˆå¹¶è„šæœ¬é€šå¸¸éœ€è¦é€‚é… TPã€‚
5.  **è°ƒè¯•ï¼š** é¦–æ¬¡è¿è¡Œæ—¶ï¼Œå¯†åˆ‡å…³æ³¨æ—¥å¿—ã€‚DeepSpeed ä¼šæ‰“å° TP å’Œ ZeRO çš„åˆå§‹åŒ–ä¿¡æ¯ã€‚å¦‚æœé‡åˆ°é”™è¯¯ï¼ˆå¦‚å½¢çŠ¶ä¸åŒ¹é…ï¼‰ï¼Œé€šå¸¸æ˜¯ `tp_size` è®¾ç½®ä¸æ¨¡å‹ç»“æ„ä¸å…¼å®¹ã€‚
6.  **æ€§èƒ½ç›‘æ§ï¼š** ä½¿ç”¨ `nvidia-smi`, `dcgm` æˆ– DeepSpeed çš„æ—¥å¿— (`"comms_logger"`, `"wall_clock_breakdown"`) ç›‘æ§ GPU åˆ©ç”¨ç‡ã€æ˜¾å­˜å ç”¨å’Œé€šä¿¡æ—¶é—´ï¼Œä»¥ç¡®è®¤é…ç½®è¾¾åˆ°äº†é¢„æœŸæ•ˆæœï¼ˆæ˜¾å­˜é™ä½ã€é€šä¿¡å¼€é”€å¯æ§ï¼‰ã€‚

### æ€»ç»“

åœ¨æ˜¾å­˜å—é™ä¸”å¸Œæœ›æœ€å°åŒ–é€šä¿¡å¼€é”€çš„åœºæ™¯ä¸‹ï¼Œä½¿ç”¨ **`--trainer_backend deepspeed` + `--deepspeed ds_config_zero1_tpN.json`**ï¼ˆå…¶ä¸­ `ds_config_zero1_tpN.json` é…ç½®äº† `"zero_optimization": {"stage": 1}` å’Œ `"tensor_parallel": {"enabled": true, "tp_size": N}`ï¼‰æ˜¯ LLaMA-Factory ä¸­é…ç½® AutoTP + ZeRO-1 æ›¿ä»£ ZeRO-3 çš„æ ‡å‡†æ–¹æ³•ã€‚è¿™èƒ½æœ‰æ•ˆå¹³è¡¡æ˜¾å­˜å ç”¨å’Œè®­ç»ƒæ•ˆç‡ï¼Œå°¤å…¶é€‚åˆåœ¨ NVLink è¿æ¥è‰¯å¥½çš„å•èŠ‚ç‚¹æˆ–å¤šèŠ‚ç‚¹ï¼ˆèŠ‚ç‚¹å†… TPï¼‰ç¯å¢ƒä¸‹è®­ç»ƒä¸­ç­‰è§„æ¨¡çš„å¤§è¯­è¨€æ¨¡å‹ã€‚è®°å¾—æ ¹æ®ä½ çš„æ€» GPU æ•°é‡ (`world_size`) åˆç†é€‰æ‹© `tp_size` (N)ã€‚