# 语法约束采样提升工具调用成功率

### 🧑‍💻 User

语法约束采样是如何提高agentic llm tool calling成功率的？

---

### 🤖 Assistant

语法约束采样（Grammar-Constrained Sampling 或 Structured Generation）是提高 Agentic LLM（代理式大语言模型）工具调用（Tool Calling / Function Calling）成功率的一种关键推理（Inference）技术。

简单来说，它的核心机制是**在 LLM 生成每一个 token 之前，强制过滤掉那些不符合预定义语法规则（如 JSON Schema）的 token，从而保证输出在语法和结构上是 100% 正确的。**

以下是它如何提高成功率的详细原理解析：

### 1. 核心矛盾：概率性 vs. 确定性

LLM 本质上是一个概率预测模型，其目标是计算给定上下文后，下一个 token 的条件概率分布：
$$P(x_t | x_{<t})$$
这意味着 LLM 有非零的概率生成“错误”的 token。

而在 Tool Calling 场景下，外部 API 需要的是**严格的确定性结构**（通常是 JSON），任何细微的语法错误（如漏掉一个 `}` 或引号）都会导致解析失败。

### 2. 语法约束采样的工作原理

语法约束采样通过在解码阶段引入一个**掩码（Mask）**机制来解决上述矛盾。

假设我们定义了一个工具调用的 JSON Schema。系统会将这个 Schema 转化为一个**有限状态机（Finite State Automaton, FSA）**或**上下文无关文法（Context-Free Grammar, CFG）**。

在生成第 $t$ 个 token 时：
1.  **计算状态**：根据当前已生成的文本 $x_{<t}$，状态机判断当前处于语法的哪个节点（例如：正在等待一个键名，还是正在等待一个整数值）。
2.  **构建掩码**：确定在这个状态下，词表（Vocabulary）中哪些 token 是合法的，哪些是非法的。
3.  **调整概率**：
    $$P_{\text{constrained}}(x_t | x_{<t}) \propto \begin{cases} P(x_t | x_{<t}) & \text{if } x_t \in \mathcal{V}_{\text{valid}} \\ 0 & \text{if } x_t \notin \mathcal{V}_{\text{valid}} \end{cases}$$
    其中 $\mathcal{V}_{\text{valid}}$ 是当前语境下符合语法的 token 集合。

### 3. 具体如何提高成功率？

#### A. 杜绝 JSON 语法错误 (Syntactic Correctness)
最常见的工具调用失败原因是生成的 JSON 格式错误（Invalid JSON）。
*   **无约束情况**：LLM 可能会生成 `{"args": "val"`（忘了闭合括号）或者 `{'key': ...}`（使用了单引号而非双引号）。
*   **有约束情况**：当 LLM 生成了 `"` 开始一个字符串后，语法约束会强制 LLM 最终必须生成 `"` 来闭合，并且在对象结束时强制生成 `}`。**解析错误的概率降为 0%**。

#### B. 强制类型匹配 (Type Enforcement)
API 定义往往对参数类型有严格要求（如 `age` 必须是 `integer`，`price` 必须是 `number`）。
*   **无约束情况**：LLM 可能会输出 `{"age": "twenty"}`。
*   **有约束情况**：如果 Schema 定义 `age` 为 `integer`，那么当生成 `age` 的值时，词表中所有非数字字符（a-z, 标点等）的概率会被置为 0。LLM **只能** 从数字 token 中进行采样。

#### C. 防止参数幻觉 (Hallucination Reduction)
LLM 有时会编造 API 中不存在的参数。
*   **无约束情况**：用户请求“查询天气”，LLM 调用 `get_weather(location="Beijing", mood="happy")`。`mood` 参数是不存在的。
*   **有约束情况**：FSA 知道合法的键名（Key）集合只有 `["location", "unit"]`。当生成键名时，除了这两个字符串及其前缀对应的 token 外，其他所有 token 都被屏蔽。LLM **无法** 生成 `mood` 这个键。

#### D. 消除“废话”输出 (Stop Token Reliability)
在 Agent 场景中，我们希望 LLM 输出完 JSON 后立即停止，不要继续生成解释性文字。
*   **无约束情况**：LLM 生成完 JSON 后，可能会继续输出：“...这是您要的参数。” 导致解析器报错。
*   **有约束情况**：一旦 JSON 对象的闭合括号 `}` 生成完毕，语法状态机进入“结束状态”，此时只有 EOS (End of Sequence) token 是合法的，强制模型停止生成。

### 4. 举例说明

假设我们有一个工具：
```json
{
  "name": "set_volume",
  "parameters": {
    "type": "object",
    "properties": {
      "level": {"type": "integer", "minimum": 0, "maximum": 10}
    }
  }
}
```

当 LLM 已经生成了 `{"level": ` 之后：

1.  **标准采样**：词表中几万个 token 都有概率被选中。模型可能抽风生成 `"high"`（字符串）或 `11`（超出范围，虽然有些约束库难以处理数值范围，但可以处理类型）。
2.  **语法约束采样**：
    *   掩码会将所有字母 token 屏蔽。
    *   掩码会将 `"`、`[`、`{` 等符号屏蔽。
    *   **只有数字 0-9 对应的 token 是可选的。**

### 5. 总结与优势

语法约束采样将 Tool Calling 从一个**自然语言生成问题**转化为了一个**填空题**。

| 指标 | 无约束采样 (Standard) | 语法约束采样 (Constrained) |
| :--- | :--- | :--- |
| **解析成功率** | < 100% (依赖模型能力) | **100% (数学保证)** |
| **参数类型错误** | 常见 | **不可能** |
| **幻觉参数** | 偶尔发生 | **不可能** |
| **推理延迟** | 较高 (可能需要 Retry) | **较低 (一次通过)** |

**常用的实现库：**
*   **llama.cpp (GBNF grammars):** 底层推理引擎广泛支持。
*   **Outlines:** 一个专门用于结构化生成的 Python 库，使用正则表达式或 Pydantic 模型约束生成。
*   **Guidance:** Microsoft 推出的控制 LLM 输出结构的语言。
*   **OpenAI JSON Mode / Structured Outputs:** OpenAI 内部实现的类似机制。