# KV Cacheç²¾åº¦è¦æ±‚åˆ†æ

### ğŸ§‘â€ğŸ’» User

å…³äºllmæ¨ç†å¼•æ“çš„"kv cacheé‡åŒ–"ï¼Œå¦‚æœåªæ˜¯ç®€å•çš„çŸ¥è¯†é—®ç­”ï¼Œä¸æ¶‰åŠå¤šè½®å¯¹è¯ã€é•¿æ–‡æœ¬ç”Ÿæˆç­‰ä»»åŠ¡ï¼Œå¯¹"Key"ç²¾åº¦è¦æ±‚æ˜¯å¦ä¼šç›¸å¯¹æ›´ä½ï¼Ÿ

---

### ğŸ¤– Assistant

ç®€çŸ­ç»“è®º
â€”â€”åœ¨åªåšä¸€æ¬¡æ€§çš„çŸ¥è¯†é—®ç­”ã€ä¸Šä¸‹æ–‡å¾ˆçŸ­ï¼ˆå‡ ååˆ°ä¸€ä¸¤ç™¾ tokenï¼‰çš„åœºæ™¯é‡Œï¼Œ**Key çš„ç²¾åº¦å¯ä»¥æ¯”é•¿æ–‡æœ¬ç”Ÿæˆæ—¶é€‚å½“å†å‹ä½ä¸€ç‚¹ï¼Œä½†ä»ç„¶ä¸èƒ½ä½åˆ°æ¯” Value æ›´ç²—**ã€‚å®æµ‹ï¼š

| é‡åŒ–æ–¹æ¡ˆ                                 | å…¸å‹ä»»åŠ¡ï¼ˆMMLU/CEVAL ç­‰ï¼‰ç²¾åº¦æŸå¤± | é€‚ç”¨å»ºè®®                                   |
| ------------------------------------ | ---------------------- | -------------------------------------- |
| FP16 â†’ INT8 (Key=8 bit, Value=8 bit) | â‰ˆ0 â€“ 0.1 pp            | å‡ ä¹æ— æ„ŸçŸ¥ï¼Œé¦–é€‰é€šç”¨æ–¹æ¡ˆ ([LMDeploy][1])           |
| INT4 (Key=4 bit, Value=4 bit)        | 0.3 â€“ 1 pp             | çŸ­é—®ç­”åŸºæœ¬å¯æ¥å—ï¼›é•¿ä¸Šä¸‹æ–‡å¼€å§‹æ˜æ˜¾åŠ£åŒ– ([LMDeploy][2])    |
| INT2 (Key=2 bit, Value=4 bit)        | >15 pp ä¸‹é™              | Key è¿‡ä½ç²¾åº¦ä¼šæ”¾å¤§è¯¯å·®ï¼Œä¸å»ºè®®ï¼Œå³ä¾¿ä¸Šä¸‹æ–‡å¾ˆçŸ­ ([arXiv][3]) |

---

### ä¸ºä»€ä¹ˆçŸ­é—®ç­”å¯¹ Key â€œå®½å®¹â€ä¸€äº›ï¼Ÿ

1. **è¯¯å·®ç´¯ç§¯è·¯å¾„çŸ­**

   * Key é‡åŒ–è¯¯å·®é€šè¿‡â€œQueryÂ·Keyâ€çš„ç‚¹ç§¯å½±å“æ³¨æ„åŠ›åˆ†å¸ƒã€‚
   * å½“ç¼“å­˜é‡Œåªæœ‰åå‡ ä¸ª Key æ—¶ï¼Œåˆ†å¸ƒè¢«æ‹‰åçš„æœºä¼šè¾ƒå°‘ï¼›ç”Ÿæˆ 1000+ token æ—¶ï¼Œæ¯å±‚ã€æ¯æ­¥éƒ½åœ¨ç´¯åŠ è¯¯å·®ï¼Œå®¹é”™åº¦å°±å¤§å¹…é™ä½ã€‚([Hugging Face][4])

2. **ç›¸å¯¹åŠ¨æ€èŒƒå›´å°**
   é—®ç­”æç¤ºé€šå¸¸åªå«ä¸€ä¸ªé—®é¢˜ + å°‘é‡ç³»ç»ŸæŒ‡ä»¤ï¼ŒKey å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦å·®å¼‚æ²¡é‚£ä¹ˆæç«¯ï¼Œä½ bit-width æ›´æ˜“è¦†ç›–å…¶æ•°å€¼èŒƒå›´ã€‚

---

### ä»éœ€ç»™ Key â€œæ¯” Value æ›´é«˜â€æˆ–â€œè‡³å°‘ç›¸åŒâ€ç²¾åº¦çš„åŸå› 

* ç³»ç»Ÿæ€§åˆ†æï¼ˆKV-AdaQuant, Feb 2025ï¼‰å‘ç° Key çŸ©é˜µçš„è°±èŒƒæ•°æ›´å¤§ï¼Œé‡åŒ–å™ªå£°è¢«æ”¾å¤§å¾—æ›´å‰å®³ï¼›åŒæ · 4 bitï¼Œåªè¦æŠŠ Key å’Œ Value å¯¹æ¢ï¼Œå‡†ç¡®ç‡å¯å·® 20 pp ä»¥ä¸Šã€‚([arXiv][3])
* è®¸å¤šéƒ¨ç½²æ¡†æ¶ï¼ˆå¦‚ LMDeploy v0.4.0ï¼‰é»˜è®¤ä¹Ÿæ˜¯ **Keyâ‰¥Value**ï¼ˆæ”¯æŒ 8/4 bitï¼Œå¯æ··åˆï¼‰ã€‚([LMDeploy][1])

---

### å®æˆ˜å»ºè®®

| åœºæ™¯                   | æ¨è KV æ–¹æ¡ˆ                                     | å¤‡æ³¨                                 |
| -------------------- | -------------------------------------------- | ---------------------------------- |
| å•è½®é—®ç­”ã€â‰¤128 token      | **Key 8 bit / Value 8 bit**ï¼›å­˜å‚¨å‹åŠ›å¤§æ—¶å¯è¯• **4/4** | å‡ ä¹æ— å¯æ„ŸçŸ¥å·®å¼‚ï¼Œå‹æ˜¾å­˜å³ç”¨ 4/4                 |
| ä¸­é•¿åº¦æ‘˜è¦æˆ–ä»£ç è§£é‡Šï¼ˆå‡ ç™¾ tokenï¼‰ | **Key 8 bit / Value 4 bit**                  | mixed-precisionï¼ŒèŠ‚çœä¸€åŠ Value æ˜¾å­˜ã€å½±å“å¾®å¼± |
| >1 k token ç”Ÿæˆ / Chat | ä¿å®ˆç”¨ **8/8**ï¼›å°è¯• 4 bit æ—¶è¦å›å½’æµ‹è¯•                  | é•¿ä¸Šä¸‹æ–‡å¯¹ Key é‡åŒ–ææ•æ„Ÿ                    |

> âš ï¸ å½“æ¨¡å‹è¦åšæ•°å€¼è®¡ç®—æˆ–é€»è¾‘æ¨ç†ï¼ˆå¦‚ GSM8Kï¼‰æ—¶ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œä¹Ÿå»ºè®®ä¿æŒ Key 8 bitï¼Œå› ä¸ºæ³¨æ„åŠ›è¯¯å·®ä¼šç›´æ¥å½±å“æ¨ç†é“¾æ¡ã€‚

---

**ç»“è®º**
åœ¨â€œç®€å•çŸ¥è¯†é—®ç­”â€é‡Œï¼Œä½ å¯ä»¥æŠŠ Key ä» FP16 å‹åˆ° INT8ï¼›å¦‚æœæ˜¾å­˜åƒç´§ï¼Œå†è¯• INT4ã€‚å†å¾€ä¸‹ï¼ˆ <4 bitï¼‰Key ç²¾åº¦çš„æŸå¤±é€šå¸¸ä¼šç«‹åˆ»ä½“ç°ä¸ºç­”æ¡ˆé”™æ¼ï¼Œä¸å€¼å¾—å†’é™©ã€‚è‹¥éœ€è¦è¿›ä¸€æ­¥å‹ç¼©ï¼Œé‡‡ç”¨ **Keyâ‰¥Value** çš„æ··åˆç²¾åº¦æˆ–åŸºäºæ¢¯åº¦/è°±èŒƒæ•°çš„è‡ªé€‚åº”æ–¹æ¡ˆï¼Œä¼šæ¯”å•çº¯é™ä½ Key ä½å®½ç¨³å¥å¾—å¤šã€‚

[1]: https://lmdeploy.readthedocs.io/en/latest/quantization/kv_quant.html?utm_source=chatgpt.com "INT4/INT8 KV Cache â€” lmdeploy - Read the Docs"
[2]: https://lmdeploy.readthedocs.io/zh-cn/latest/quantization/kv_quant.html?utm_source=chatgpt.com "Key-Value(KV) Cache é‡åŒ– â€” lmdeploy"
[3]: https://arxiv.org/abs/2502.15075?utm_source=chatgpt.com "More for Keys, Less for Values: Adaptive KV Cache Quantization"
[4]: https://huggingface.co/blog/kv-cache-quantization?utm_source=chatgpt.com "Unlocking Longer Generation with Key-Value Cache Quantization"


---

### ğŸ§‘â€ğŸ’» User

å…·ä½“åˆ°å„é¡¹ä»»åŠ¡ä»¥åŠä¸åŒçš„åºåˆ—é•¿åº¦é‡Œé¢ï¼Œ"Key"é‡åŒ–å¯¹generation qualityå½±å“æœ‰å¤šå¤§ï¼Ÿå…·ä½“æ˜¯å“ªäº›æ–¹é¢çš„æ€§èƒ½ä¸‹é™ï¼Ÿ

---

### ğŸ¤– Assistant

### 1. ä¸€çœ¼ç»“è®º

| ä»»åŠ¡ â†’<br/>åºåˆ—é•¿åº¦                              | **Key 8 bit** (Val 8 bit)<br/>æŸå¤± | **Key 4 bit** (Val 4 bit)<br/>æŸå¤± | **Key 2 bit** (Val â‰¥ 4 bit)<br/>æŸå¤± | ä¸»è¦å¤±çœŸè¡¨ç°                     |
| ------------------------------------------ | -------------------------------- | -------------------------------- | ---------------------------------- | -------------------------- |
| çº¯çŸ¥è¯†é—®ç­” (MMLU/TriviaQA, â‰¤ 128 tok)           | â‰ˆ 0 pp                           | 0 â€“ 0.5 pp                       | â‰¥ 5 pp                             | top-1 é€‰é¡¹æ··æ·†                 |
| ä»£ç /æ•°å­¦æ¨ç† (GSM8K, \~300 tok)                 | â‰ˆ 0 pp                           | 0.4 pp (ZipCache)                | **>15 pp**ï¼Œæ¥è¿‘éšæœº                    | Chain-of-Thought è¢«æˆªæ–­ã€ç®—é”™ä¸­é—´é‡ |
| æ–°é—»æ‘˜è¦ (CNN/DailyMail, \~512 tok)            | â‰¤ 0.3 ROUGE-L                    | 1 â€“ 1.5 ROUGE-L                  | 8 + ROUGE-L                        | å¼€å§‹æ¼æ‰ç»†èŠ‚ã€æ®µè½é‡å¤                |
| LongBench æ£€ç´¢/QA (4 k tok)                  | < 1 pp                           | 1 â€“ 3 pp (SimLayerKV)            | 10 + ppã€å¬å›ç‡éª¤é™                      | æ—©æœŸ token é—å¿˜ã€ç­”æ¡ˆæ¼‚ç§»           |
| Needle-in-Haystack & code-doc (â‰¥ 32 k tok) | 2 pp å†…                           | **4 â€“ 6 pp**ï¼›éœ€æ··åˆç²¾åº¦               | **å´©æºƒ**ï¼šéšæœº / æ— æ³•åœæ­¢                   | é•¿è·ä¾èµ–å½»åº•å¤±æ•ˆã€é‡å¤æ®µè½æ¿€å¢            |

<sub>pp = percentage pointsï¼›æ‰€æœ‰æ•°å­—å–è‡ªå…¬å¼€åŸºå‡†å¹³å‡å€¼ï¼Œè§å¼•ç”¨</sub>

### 2. å…³é”®å®æµ‹ä¾æ®

* **Key 8 bit åŸºæœ¬æ— æŸ**ï¼šLMDeploy åœ¨ 50 ä¸ª OpenCompass åŸºå‡†ä¸Šç»™å‡ºçš„å¹³å‡å·®å¼‚ <0.1 ppï¼›æ¨ç†ååé‡ +30 % â€“ 40 % ([LMDeploy][1])
* **Key 4 bit å¯æ¥å—ä½†å¯è§**ï¼š

  * LongBench 16 é¡¹ä»»åŠ¡å¹³å‡ â†“1.2 ppï¼ˆSimLayerKVï¼‰ ([OpenReview][2])
  * åœ¨ 4 k-token æ£€ç´¢ä»»åŠ¡ä¸­ï¼ŒKVCrush 4Ã— å‹ç¼©ä»… â†“0.9 ppï¼Œä½†é‡å¤ç‡ä¸Šå‡ 7 % ([arXiv][3])
* **Key 2 bit é£é™©æé«˜**ï¼š

  * KV-AdaQuant å¯¹ LLaMA-7Bï¼šKey-2 / Val-4 ä»… 54.7 % å‡†ç¡®ï¼Œè€Œ Key-4 / Val-2 è¾¾ 75.2 % â€”â€”åŒæ · 3 bit/entry æ€»é¢„ç®—ï¼Œå´å·® 20 pp+ ([arXiv][4])
  * Emergent-Ability studyï¼š2-bit æ—¶ GSM8Kã€MMLU æ¥è¿‘éšæœº (â‰ˆ 25 %) ([ar5iv][5])
* **æ¨ç†ç±»ä»»åŠ¡æœ€æ•æ„Ÿ**ï¼šZipCache åœ¨ GSM8K ä¸Š 4.98Ã— å‹ç¼©ï¼ˆKeyâ‰ˆ4 bit ç­‰ä»·ï¼‰åª â†“0.38 ppï¼Œä½†åœ¨ 2 bit è®¾ç½®ä¸‹ç›´æ¥ >10 pp ([NeurIPS ä¼šè®®å½•][6])
* **æç«¯ä½ bit ä»æœ‰äººåšåˆ°**ï¼šAKVQ-VL & SKVQ å€ŸåŠ©æ³¨æ„åŠ›æ˜¾è‘—æ€§/WHTï¼Œå¯åœ¨ 2 - 2.5 bit ä¸‹ä¿æŒ <1 pp æŸå¤±ï¼Œä½†éœ€å¤æ‚åŠ¨æ€åˆ†é…ï¼Œä¸”ç›®å‰åªåœ¨å¤šæ¨¡æ€æˆ–æ»‘çª—åœºæ™¯æŠ¥å‘ŠæˆåŠŸ ([arXiv][7], [OpenReview][8])

### 3. é‡åŒ–ååˆ°åº•ååœ¨å“ªï¼Ÿ

| å¤±çœŸç‚¹              | å…·ä½“è¡¨å¾                      | è§¦å‘æ¡ä»¶                      | å…³è”æœºåˆ¶                                   |
| ---------------- | ------------------------- | ------------------------- | -------------------------------------- |
| **æ³¨æ„åŠ›åˆ†å¸ƒæŠ–åŠ¨**      | log-prob æ¢¯åº¦å™ªå£°â†‘ â†’ é€‰é”™ top-K | Key <4 bitï¼›é•¿åºåˆ—            | QueryÂ·Key å†…ç§¯è¯¯å·® âˆ Key è°±èŒƒæ•°Â² ([arXiv][4]) |
| **è¿œè· token æ‰æƒé‡** | é•¿æ–‡æ‘˜è¦æ¼ä¿¡æ¯ã€Needle-QA ç­”å      | >2 k tok æ—¶å°¤ç”š              | é‡åŒ–å™ªå£°éšè·ç¦»ç´¯ç§¯ï¼Œæ—©æœŸ Key æƒé‡è¢«ç¨€é‡Š                 |
| **å¾ªç¯é‡å¤**         | â€œæ‰€ä»¥æ‰€ä»¥æ‰€ä»¥â€¦â€ï¼›å¥å—å¤åˆ¶            | Key 4 bit+æé•¿æ¨ç† (>8 k tok) | Attention éšæœºæ¸¸èµ°é€ æˆ entropy å‡å°            |
| **é€»è¾‘é“¾æ–­è£‚**        | GSM8K è§£é¢˜æ­¥éª¤ä¸¢ä¸€è¡Œ             | ä»»æ„é•¿åº¦ï¼ŒKey <4 bit           | è¯¯å·®åœ¨æ¯æ­¥è‡ªå›å½’ä¸­æ”¾å¤§                            |
| **å¯¹é½é€€åŒ–**         | æœ‰å®³/å¹»è§‰å›ç­” â†‘                 | å½“ Key\<Val ç²¾åº¦æˆ–é”™é…          | è‡ªç›‘ç£å¯¹é½ç›®æ ‡æ•æ„Ÿäºä¿¡æ¯æ£€ç´¢å¤±è´¥                       |

### 4. å®æ“å»ºè®®çŸ©é˜µ

| åœºæ™¯                | æ¨è Key/Val ä½å®½                               | å¤‡æ³¨               |
| ----------------- | ------------------------------------------- | ---------------- |
| â‰¤128 tok å•è½® QA    | **8/8** â†’ 4/4 å¦‚æ˜¾å­˜ç´§å¼                          | å‡ ä¹æ— æ„ŸçŸ¥å·®å¼‚          |
| 256â€“512 tok æ‘˜è¦ã€ç¿»è¯‘ | **8/4** (æ··åˆ)                                | èŠ‚çœ Â½ æ˜¾å­˜ï¼Œè´¨é‡å¾®æŸ     |
| ä»£ç /æ•°å­¦æ¨ç†           | **8/8**ï¼›æˆ– KV-AdaQuant 8/4                   | æ¨ç†é“¾æ¡å¯¹ Key æŠ–åŠ¨ææ•æ„Ÿ  |
| â‰¥4 k tok é•¿æ–‡æœ¬ç”Ÿæˆ    | **è‡³å°‘ 8/8**ï¼Œæˆ– SimLayerKV 4/4 + Token-Pruning | å…ˆå‹ Valueï¼Œå†è€ƒè™‘ Key |
| è¶…é•¿çª— (â‰¥32 k)       | KVQuant / RotateKV / SKVQ åŠ¨æ€ 2â€“4 bit        | å¿…è¦æ—¶é€å±‚è‡ªé€‚åº”ï¼›ç¦»çº¿æ ¡å‡†    |

> **ç»éªŒæ³•åˆ™**ï¼š**Key çš„å¹³å‡ bit æ•°åº” â‰¥ Value**ï¼›è‹¥å¿…é¡»ä½äº 4 bitï¼ŒåŠ¡å¿…é‡‡ç”¨è°±èŒƒæ•°/æ˜¾è‘—æ€§é©±åŠ¨çš„ *mixed-precision* æˆ–æ»‘çª—æ–¹æ¡ˆæ¥â€œé‡ç‚¹ä¿æŠ¤â€é«˜æƒé‡ Keyï¼Œè€Œä¸æ˜¯ä¸€åˆ€åˆ‡é™ä½ã€‚

---

#### 5. è¿›ä¸€æ­¥é˜…è¯»

KV-AdaQuant (spectral åˆ†æ)ã€SimLayerKVã€ZipCacheã€RotateKVã€AKVQ-VLã€KVCrushã€SKVQ ç­‰è®ºæ–‡åœ¨ä¸åŒä»»åŠ¡å’Œåºåˆ—é•¿åº¦ä¸Šç»™å‡ºäº†ç³»ç»Ÿå®éªŒï¼Œå»ºè®®æŒ‰ä¸ä½ æ¨¡å‹è§„æ¨¡æœ€æ¥è¿‘çš„é‚£ç¯‡è¿›è¡Œå›å½’æµ‹è¯•å†ä¸Šçº¿ã€‚

[1]: https://lmdeploy.readthedocs.io/zh-cn/v0.4.2/quantization/kv_quant.html?utm_source=chatgpt.com "Key-Value (KV) Cache é‡åŒ– â€” lmdeploy 0.4.2 æ–‡æ¡£"
[2]: https://openreview.net/forum?id=UjSmUlUU6y&utm_source=chatgpt.com "SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction"
[3]: https://arxiv.org/pdf/2503.00022?utm_source=chatgpt.com "KVCrush: Key Value Cache size-reduction using similarity in head-behaviour"
[4]: https://arxiv.org/abs/2502.15075?utm_source=chatgpt.com "More for Keys, Less for Values: Adaptive KV Cache Quantization"
[5]: https://ar5iv.labs.arxiv.org/html/2307.08072?utm_source=chatgpt.com "Do Emergent Abilities Exist in Quantized Large Language Models:"
[6]: https://proceedings.neurips.cc/paper_files/paper/2024/hash/7e57131fdeb815764434b65162c88895-Abstract-Conference.html?utm_source=chatgpt.com "ZipCache: Accurate and Efficient KV Cache Quantization with Salient ..."
[7]: https://arxiv.org/abs/2501.15021?utm_source=chatgpt.com "AKVQ-VL: Attention-Aware KV Cache Adaptive 2-Bit Quantization for Vision-Language Models"
[8]: https://openreview.net/forum?id=nI6JyFSnyV&utm_source=chatgpt.com "SKVQ: Sliding-window Key and Value Cache Quantization for Large..."
