# Llama2等模型去除QKV偏置原因

### 🧑‍💻 User

为什么像llama2，qwen2，都把qkv的bias参数去掉了？

---

### 🤖 Assistant

这是一个非常好的问题，它触及了现代Transformer架构中一个精细但重要的设计选择。

像Llama 2、Qwen 2、GPT-NeoX等众多先进模型去掉QKV（Query, Key, Value）线性投影中的偏置（bias）参数，主要是出于**简化模型、提升计算效率、数值稳定性以及减少过拟合风险**的综合考虑。这并不是一个偶然的决定，而是经过深思熟虑和实验验证的优化。

以下是几个核心原因：

### 1. 减少参数与计算量，提升效率
这是一个最直接的原因。对于一个有 `d_model` 维隐藏状态和 `n_heads` 个注意力头的模型，每个头的维度是 `d_k = d_v = d_model / n_heads`。

*   **带有Bias的情况**：Q、K、V三个投影矩阵各需要一个形状为 `(d_model,)` 的偏置向量。总共增加 `3 * d_model` 个参数。
*   **不带Bias的情况**：直接去掉这 `3 * d_model` 个参数。

对于拥有70B（700亿）参数的Llama 2来说，`d_model` 可能是8192甚至更大。去掉这3*8192个参数看似微不足道，但这是一种“积少成多”的优化。在训练和推理时，每个token的前向传播中都会少3次长度为 `d_model` 的向量加法操作。在大规模模型和海量数据处理中，这一点点效率提升会被放大，从而节省可观的计算资源和时间。

### 2. 避免与LayerNorm的冗余，保持数值稳定性
这是更深层次的技术原因。在现代Transformer架构（如Llama 2）中，注意力层之前通常有一个**Layer Normalization（层归一化）**。

*   **LayerNorm的作用**：它会将输入数据重新中心化和缩放，使其均值为0，方差为1。这意味着，进入QKV投影层的输入 `X` 从统计上来看已经是“零中心化”的。
*   **线性投影的本质**：`Y = WX + b`。这里的偏置 `b` 的作用是为输出 `Y` 提供一个固定的“偏移量”或“基线”。
*   **冗余性**：当一个已经是零中心化（均值为0）的数据 `X` 经过线性变换 `WX` 后，其结果 `WX` 的均值可能不是零，但通常会在0附近。此时再添加一个可学习的偏置 `b`，其效果与LayerNorm已经完成的“中心化”工作是重复的。模型完全可以通过调整权重 `W` 来学习到所需的任何变换，偏置 `b` 变得不是必需的。

移除偏置可以简化学习过程，让模型更专注于学习权重 `W` 的核心变换，而不是去学习一个可能与LayerNorm功能重叠的偏置。

### 3. 一致性与对称性
在注意力机制中，我们计算的是Query和Key之间的点积相似度：`Q·K^T`。

*   如果Q和K的投影都包含偏置，那么它们的点积中会引入一些常数项（与偏置有关的交叉项）。这些常数项可能并不有助于模型学习到更有意义的注意力模式，反而增加了计算的复杂性。
*   去掉偏置后，`Q·K^T` 的计算纯粹是输入经过LayerNorm和权重变换后的结果，形式更干净，更具对称性，理论上更易于优化。

### 4. 潜在的正则化效果，减少过拟合风险
虽然参数减少的量不大，但移除任何不必要的参数都是一种形式的**正则化**。它降低了模型的容量和复杂度，理论上可以稍微降低过拟合的风险，让模型更好地泛化。在已经非常大的模型中，这种微小的正则化可能效果有限，但“有胜于无”。

### 为什么不去掉所有线性层的偏置？

你可能会注意到，在这些模型中，**并不是所有线性层的偏置都被移除了**。例如，许多模型在**输出投影层（将注意力输出映射回模型维度）和FFN（前馈网络）层中仍然保留了偏置**。

*   **FFN层**：通常包含两个线性层（up和down投影），中间夹着一个激活函数（如SiLU，ReLU）。这里的偏置对于帮助激活函数在合适的位置“激活”至关重要。例如，ReLU函数在输入大于0时才有输出，偏置项可以学习并控制这个阈值，这对于模型的表达能力非常重要。
*   **输出投影层**：这些层的输入并不总是像QKV层那样有严格的、前置的LayerNorm进行零中心化（取决于架构设计），或者其功能需要更大的灵活性，因此保留偏置可能更有益。

### 总结

| 方面 | 解释 |
| :--- | :--- |
| **效率提升** | 减少参数量和计算量，加速训练和推理。 |
| **避免冗余** | 前置的LayerNorm已经完成了中心化工作，使QKV的偏置成为非必要。 |
| **数值稳定** | 简化计算图，使注意力得分计算更干净、稳定。 |
| **正则化** | 轻微降低模型复杂度，可能有助于泛化。 |
| **行业趋势** | 大量实验证明去除QKV偏置不会损失性能，甚至可能有益，因此成为先进模型的标准做法。 |

总而言之，去除QKV线性层的偏置是一项经过充分验证的“剪枝”优化，它用更少的资源实现了同等的甚至更优的性能，体现了深度学习模型设计中“如无必要，勿增实体”的哲学。