# 现代大语言模型（四）

## 四、权重的概念与分析方法

### 4.1 权重的定义

在对模型的生成进行分析时，可以使用"权重"计量（当然分析方法和计量方式是分开的，用其他计量方式只要严谨合适即可）。

**权重**，是指语言模型在生成文本时，对不同类型内容生成的生成偏好，可以理解为：模型在众多可能的输出中，更倾向于生成哪些内容，这种倾向性在我们的分析中，可以用概率或相对比例来表示。

而对于模型的分析，就是在对生成内容进行观察-分析，尝试找到它的内容生成概率。

### 4.2 分析的精度问题

那么，我们观察什么？当然是观察模型生成内容的"性质"和"范围"。分析什么？自然是这些不同范围和性质的内容的生成的概率。

当然这个概率是永远测不准的，众所周知，精度越高样本量需求就要越高，精度越低样本量需求就越低。如对词语或者句子精确测量，那要的样本量简直是天文数字。所以我们只能退而求其次，通过内容的性质或者范围上进行分析。其核心原理就是**只要我分析的精度够低，那么分析结果的误差甚至差错再大都能就能忽略不见，使结论在该条件下保持准确**。简单而又高效😋

#### 为什么测不到精确值?

因为我们对内容的分析，除非做到无限细分，那么因为低精度，就一定存在些误差。而且我们要分析模型的权重，那么就得知道提示词的影响，要知道提示词的影响，又得知道模型的权重......这个差异只能在后面通过"预分析"大致消除。

也能注意到，当精度在未到达无穷大时，因为误差存在必定取不到精确值。而当精度趋近一个字或一个词，那么需要的样本量也趋向于无穷大，同样无法得出精确值

> （可以试试让ai帮你证明一下）

### 4.3 分析方式

于是可以发现上面的分析，是把范围缩的很小很小，甚至是直接缩到了每个词的权重。是，不可否认这是符合分析方法的，但对于这个样本量，这种少量的内容中不适用。越是想要精确的分析，需要的样本量越多，提示词影响要更小。

> （在这段提示词里不容易看出来，因为例子中用的不是理想提示词_(:зゝ∠)_，提示词严格来说不可能完全消除影响，只能在后面通过使用极简提示词和预分析的方法来消减去其影响，来得到极近似值）

相反如果我们分析是在一定范围内的去分析生成内容的性质，那么样本量的需求就相对少了很多，而且预测在定义上能更加准确，相对误差相应的也更小。（精度低误差肯定也跟着低这一块）

---

### 4.4 实际分析示例

在我们对模型的分析中，对模型的生成内容的"性质"进行分析，是最实用也是最直观的分析。

该分析不需要定死说一定只能说从某某方面进行分析，就是怎么顺手怎么来，需要什么就分析什么，往大了讲你可分析模型对长文和短文的权重，往小了讲你可以像上面那样对某些或者某一词语的生成倾向进行分析，但是得注意其因果关系和证明。

#### 回到例子

好的，我们回到这个假设的例子中。

不妨设：对于"某一内容"的生成，可记为事件：（某一内容）。特别的，我们用 **W_basic（某一内容）** 来专门表示模型在理想提示词下，即无限近似于无提示词下，对该内容的生成倾向性，即基础的权重。

回到上文的例子，我们可以发现内容可以从"角色扮演"的角度范围进行精确分析，显而易见，内容划分为（可爱的猫娘）（傲娇的猫娘）还有个（语言模型助手）。

可以注意到（可爱的猫娘）是最多的，即W_basic（可爱的猫娘）很高的。而这内容中还存在一部分类如："今天想做什么吗"之类的内容，嗯感觉有点眼熟，在语言模型中，这些内容很常见，如"今天我可以帮助您什么吗"因此，此时还存在一定的W_basic（语言模型助手）。

> **注:** 角色扮演是个特殊情况，在任何范围任何角度上，只要分析无误，它的分析结果得到的预期结果一定是准确的。之后我们在说。

#### 多角度分析

不满意？那当然分析又不是只能进行一次，只能从一个角度进行分析。我们也能发现，语言描写很多，同时伴有少量的动作描写，所以可以分别记为事件：（语言描写）和（动作描写）。还有少量的颜文字和emoji的生成，也记为事件：（颜文字）和（emoji）。

读者可自证（懒得写）：

- W_basic（语言描写）最高
- W_basic（动作描写）其次
- W_basic（颜文字）描写较低
- W_basic（emoji）最少（少的可怜）

---

### 4.5 权重的数学运算

到这就完了？不可能的，我们都用数学符号了，这说明权重的运算是符合数学规定的。

一般情况下，各个分析角度和范围的内容没有明显重合，我们可以把不同分析方法得到的事件，视为互相独立，方便计算观察。因为其得到的结果基本符合真实值，误差在分析中可忽略不计。

对于我们两个分析结果，假设我们需要生成的是可爱猫娘的语言，于是我们可以记为事件：（可爱猫娘的语言描写），要对它重新分析吗？不用的

我们可注意到，可爱猫娘的语言描写等价于生成可爱猫娘的内容时同时生成语言描写，

**W_basic（可爱猫娘的语言描写）＝W_basic（语言描写∩可爱的猫娘）**

**＝W_basic[（语言描写）|（可爱的猫娘）]\*W_basic（可爱的猫娘）**

**＝W_basic[(可爱的猫娘) | （语言描写）]\*W_basic（语言描写）**

同理，又可注意到W_basic（可爱的猫娘）＝W_basic（可爱的内容∩猫娘），试试看能不能在此基础上，以最小代价找出W_basic（可爱的内容）和W_basic（猫娘）吧😊

---

### 4.6 常见错误与纠正（续）

不过小心，这是个常常错误的地方，不难发现我们的分析，难点在于怎么去划分范围，如何选择角度。如果我们想找到W_basic（猫娘），用的依旧是理想提示词。但我们看到的只是模型在生成很可爱的猫娘，此时测出来的是W_basic（可爱的猫娘）而不是W_basic（猫娘）。

运用数学知识不难发现（假设只使用理想提示词）：

∵ W_basic（可爱的猫娘）＝W_basic[（可爱的内容）｜（猫娘）]\*W_basic（猫娘）

∴ W_basic（猫娘）＝W_basic（可爱的猫娘）/W_basic[(可爱的内容)｜(猫娘)]

∴ 我们还得需要测量出，当模型在生成猫娘的内容时，可爱的内容的权重是多少，才能得到W（猫娘）

不过，注意到

∵ 易发现绝大部分模型在生成猫娘有关内容时，可爱的内容很多很多，即W_basic[(可爱的内容)｜(猫娘)]→1

∴ 一般可认为，在任何模型下，**W_basic（猫娘）≈W_basic（可爱的猫娘）**

即一般情况下，测量出W_basic（可爱的猫娘），就基本知道W_basic（猫娘）是多大

---

### 4.7 权重分析小结

怎么样，是不是很好用😋运用非常简单的中学知识，通过一些简单的分析，便可以知道复杂情况的内容生成权重，甚至大概推测出还没测量的内容权重。一般来讲，生成个2到3次就能得到较为准确的合适精度结果了。

关于数学方面，其实也用不了太高等的数学方法，一个是样本太少，一个是量化麻烦。

---

### 4.8 处理异常情况

但是如果你发现分析结果很怪，比如对于上述例子。如果在角色扮演的分析上，只得到了两个事件（悲伤的猫娘）与（语言模型助手）

显然：

- W_basic（悲伤的猫娘）与W_basic（语言模型助手）都小的可怜
- 易知其的和小的可怜，甚至都不可能到50%

#### 引入"其他内容"

对于这种情况，有个方法就是，可以设：其他全部没考虑分析的内容的生成事件，合并统称为（其他内容）

然后在生成内容中，忽视去已经分析出有相对应性质或者有对应（事件）的内容，把剔除已知已分析内容后的剩余的内容，看作为一个完整的，新生成的内容进行分析。

有点绕，换个方式表示：

∵ 设所有生成内容的全集为"全部内容"，事件（悲伤的猫娘）、（语言模型助手）和（其他内容）互斥且覆盖了全部内容。

∴ W_basic（悲伤的猫娘） + W_basic（语言模型助手） + W_basic（其他内容） = 1。

∴ W_basic（其他内容） = 1 - W_basic（悲伤的猫娘） - W_basic（语言模型助手）。

∵ 对"其他内容"单独进行分析，得出在此情况下"内容1"的权重为 a，"内容2"的权重为 b（即a 和 b 都∈ (0,1)，且 a + b = 1）。

∴ 在"其他内容"中，W_basic（内容1 | 其他内容） = a，W_basic（内容2 | 其他内容） = b。

∵ W_basic（内容1） = W_basic（内容1 | 其他内容） × W_basic（其他内容）。

∴ W_basic（内容1） = a × [1 - W_basic（悲伤的猫娘） - W_basic（语言模型助手）]。

同理，

∵ W_basic（内容2） = W_basic（内容2 | 其他内容） × W_basic（其他内容）。

∴ W_basic（内容2） = b × [1 - W_basic（悲伤的猫娘） - W_basic（语言模型助手）]。

---

#### 分析建议

无论分析是否完美准确，个人都建议是加个（其他内容）上去进行分析，一个是稍微严谨点，二个是容易发现错误，纠正也方便。

**如果W_basic（其他内容）太大了，就应当考虑是不是分析错了**

或者说

如果分为（可爱的内容）和（活泼的内容）

发现W_basic（可爱的内容）和W_basic（活泼的内容）都很大，其的和超过100%

那说明两个内容分类不合理，内容重合的地方太多。

**在一次分析内，最好选择在精度内，重合内容相对不多的分类方式**

---

### 4.9 问题排查清单

如果奇葩结果，应当考虑是不是：

1. 缺少考虑了某些内容
2. 是不是这个角度或方面，范围上的分析方法不适合当前情况
3. 使用的提示词不是理想提示词，对生成产生影响（当然知道提示词是什么，一样能测量出来）
4. 或许能问问ai（？）

---

### 4.10 权重的性质总结

总之，权重有以下性质和内容：

1. 各个模型有各种不同的权重分布，但大部分内容上相互不会偏差太大
2. 一次权重的分析结论可以推广到其他生成中
3. 分析方法和分析角度范围不受限，各分析方法之间的区别只有误差大小
4. 符合数学法则
5. 不可能得到精确结果，但可以逼近
6. 一般来说，各个分析角度和范围的内容没有明显重合，我们可以把不同分析方法得到的事件视为互相独立，方便计算观察
7. 特殊情况不适用（比如你在注意力衰退，还是能力衰退什么的情况下用就不行了，得到的结果会很离谱）

---

### 4.11 如何给生成内容定性

如何给生成内容定性呢？首先，我们猜测语言模型的生成前提是，语言模型的训练内容是符合人类正常思维的，根据模型的语料内容和厂商的训练目的就不难推测，一般情况，绝大部分模型的生成必然是机械且稳定的。因此，**如果你阅读一篇语言模型的生成内容，你的第一印象，甚至是直接基于刻板印象的判断，通常就能准确地反映该内容的性质**。

至于角度嘛，从**内容性质**和**角色扮演**两个角度进行观察分析基本足以解决90%的问题，另外10%正常玩我觉得都不太可能碰到吧╮( •́ω•̀ )╭。还有9%换成提示词分析和角色扮演就能解决。1%我不知道😇

假如不会呢，这个不难，随便让模型生成点什么，体验一下，我不信还不知道模型的"机械"的理解性质是什么样。只要知道一个模型，基本就能随随便便推广到其他模型，有时国内外的模型极小概率存在小差异，不过稍微注意一下就行，或者可以直接忽略不计。

**以上就是一些语言模型内容生成的分析方法。** 权重的主要目的在于，将抽象的无法理解的分析具体化，并能够用数学符号去准确的分析，并拓展分析结果。这只是个具体化的分析方法，不是严格的数学计算。如果有其他更好的分析方法，那可不必使用这玩意，欢迎讨论分享。

---