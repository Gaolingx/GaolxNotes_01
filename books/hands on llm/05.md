# 现代大语言模型（五）

## 提示词

---

## 五、提示词基础

### 5.1 什么是提示词

提示词，就是你和模型交流用的话。不用把他想的太高端，其实就是你发给模型的文字字符，这个就叫做**提示词（prompt）**

> **AI提示词（AI prompt）** 是指用户通过生成式人工智能平台（如OpenAI的ChatGPT或Microsoft Copilot）向大语言模型（LLM）提交的输入内容。这类输入可以表现为问题、指令、陈述、代码片段或其他文本形式。部分大语言模型还支持非文本输入，包括图像和音频文件。当输入内容提交后，人工智能平台会将其加载至大语言模型，模型则以此为基础生成相应回复。
>
> 根据提示词的表述方式差异，AI模型可能产生多种输出结果。提示词既可以简单到仅含几个单词，也能复杂至包含多个段落，甚至可附带待分析的引用内容或图像。其核心目标是为AI模型提供精准生成相关输出所需的完整信息。AI提示词也可作为对大语言模型前序回复的跟进，例如要求补充细节或提供额外信息以优化响应内容。
>
> *--节选自: https://www.techtarget.com/searchenterpriseai/definition/AI-prompt*

---

### 5.2 提示词工程

而我们编写提示词，优化提示词，研究这玩意的东西，有一个专门的学名-**提示词工程（prompt-engineer）**

其概念大致为：

> 您可以通过提示词实现很多功能，且模型的输出结果质量很大程度上取决于你的提示词。
>
> 提示可以包含诸如传递给模型的
>
> - **instruction**（中文翻译：指令，告诉模型要去做什么，如：生成一篇小说）
> - **question**（中文翻译：问题，就是字面意思，如：为什么这盘炒面非常的新鲜非常的美味？）等等信息。
>
> 也包括其他细节，例如：
>
> - **inputs**（中文意思：输入，指你给模型提供的信息，小说文本，世界书等）
> - **examples**（中文意思：例子，给模型示范怎么生成，说它是一段QA也行，告诉模型这个是标准答案，根据这个回答，如：你的生成可以参考这段对话，医生问：逸一时误一世，你：忆久意久把意领）等等等等各种细节

#### 简单示例

这是一个简单提示的基本例子：

假如我们想让模型生成第一人称的，对天空的简短感叹

**我们输入的提示词：**
```
The sky is
```

**模型的输出：**
```
蓝色的，在晴朗的日子里，天空是蓝色的。 在多云的日子里，天空可能是灰色或白色的。
```

正如您所见，语言模型输出了这句话缺失的延续部分，使之与上下文"The sky is"意思完整且语法连贯。但输出不在我们的预期内，没有很好的完成我们的任务。

让我们尝试改进一下这个提示词：

**输入的提示词：**
```
天空，抒发简短的感慨
```

**模型的输出：**
```
今天的天空真美啊！
```

这样好一些了吗？我们明确要求模型要生成感慨这个内容，相比之前的输出更符合我们的需求，生成结果很好的完成了我们的任务。

当然也不是必须一定要非常明确指出来，含蓄和明显的要求各有各特点，按需求使用。不过一般情况下都推荐使用明确的要求，因为模型能理解的更好，改起来也更方便。

这种设计最优提示以指导模型完成任务的方法，被称为：**提示词工程**

> *--节选改编于: https://github.com/yunwei37/Prompt-Engineering-Guide-zh-CN/blob/main/guides/prompts-intro.md*

---

### 5.3 提示词的本质

> **需要注意，提示词永远不存在任何形式上的"标准答案"、"最佳答案"或普适性的"设计原则"。其价值和效力的唯一评判标准是结果，即："能用就是好用"。**
>
> 任何试图将提示词工程固化为一系列"金科玉律"的行为，都是对其动态、对抗和创造性本质的误解。恰恰是因为没有标准答案，提示词的使用才成为一个充满策略和创意的领域。
>
> 这正是提示词攻防（攻击与防御）和其他各种看起来奇怪的结构和写法，有这些存在的根本前提，恰好证实了上述观点。如果存在一个绝对正确的编写原则和方法，那么所有的破限和简单自然语言之外的所有提示词都将成为无稽之谈，因为在此理论上都不应该存在。现实是，提示词的效果高度依赖于具体模型、上下文、以及对话中的各种提示词。因此，提示词工程的本质，就是在这种无标准、无定式的环境中，进行的一场永无止境的进步。
>
> *--ai写的，有修改，说实话写的比我好多了，有点嫉妒(*

---

## 六、提示词分析

接下来我们只关注对提示词的分析。

### 6.1 思维

在那之前，别急，先好好想想，我们应该怎么去分析提示词？

根据可靠的常见理论，我们是用户，语言模型是助手。所以我们应该看看我们的问题，再看看例子......如果语言模型道歉还是什么的，就把提示词说的更加清晰明确，遵守道德法律，还有什么来着？还要和和睦睦，耐心的细细解答，当作一个真正的助手一样跟它耐心的*对话*，调整提示词去提示他，对吧😇然后说个谢谢......

对！显然，根据大量实践和文章，教学，这是正确的，我们应当去掌握遵守它（？）

哈哈，真这样想试图分析所有提示词，那就会故步自封，就像1/x-1的泰勒展开一样，显然正确，但自己把自己的定义域收缩了。

证明这个很简单。用这种方法分析那种《deepseek的50条顶级提示词》固然确确实实做得到，但可以再找个预设，试试看分析一下每个提示词的作用和效果，顺便找找哪些在对内容生成作优化调整，各自的效果又是什么？哪些提示词是用于破限的，怎么破限的，在那些方面"破"了什么样的甲？

自然根据以上的思维方式，除非注意力惊人，私以为不太可能做到全部分析出这些东西。

---

### 6.2 视角方法

我们之前提到过"语言模型本质上就是一个巨大的数学公式"，同样的，我们忽略掉它种种"人性化"的回答，毕竟我们都知道当下把模型当作"人"是一个很笨蛋的行为。不妨把这件事做绝，**就把它当作一个完完全全的工具，一个用来生成文字的机器**，它的作用就是根据内部设置来读取我们的输入，然后生成符合它内部生成方法的内容。

有点想法了吧，不要把它当作任何角色，**它就是一台生成文字的机器，它生成文字的根据就是厂商的训练和它接收到的东西**。

刚才它的"生成内容的基础方法"我们已经分析过了，我们在看看怎么分析我们的输入。

---

### 6.3 两种分析方式

提示词分析有两种，一种是"**预分析**"，另一种就是和上面一样是简单的"**分析**"

两者唯一不同的地方在于：

- **"预分析"** 是先验的，就是说我们在发给模型前，直接进行分析，得到的一个大概的预期结果。
- **"分析"** 是后验的，就是说我们先发给模型，得到了生成结果，再从这个结果，推出提示词作用

"预分析"建立于"分析"之上，得先会"分析"才知道"预分析"怎么办。好巧不巧，学会"预分析"后，才知道在有提示词影响的情况下，分析出模型的初始权重

不是说去"分析"中背哪些提示词的效果是什么，才能在"预分析"里运用，没这必要，知道效果就行了（

这玩意就像是微积分公式，拿出来是拿来用，不是去背无数个公式所对应的答案（

---

### 6.4 上下文结构

我们都知道，对模型的生成产生影响的就是模型本身和上下文。

模型本身我们已经分析过了，所以我们再分析上下文就能预测其结果是什么。

#### 上下文是什么？

上下文广义上来讲，就是语言模型能接收处理到的所有字符。

也就是说，**系统提示词，你之前的全部对话记录，即将发送的提示词，与之后模型正在生成中的文段都能算是整个上下文的一份**。

其中"你即将发送的提示词"是一定存在的。

#### 上下文结构

语言模型的上下文结构为：

```
[system prompt/系统提示词]
[历史对话记录]
[即将发送的提示词]（必定存在的成分）
[模型正在生成的文本]（提示词发送后才有，其特点为一定不可能完整）
```

其中 **[历史对话记录]** 展开有：

```
[你的第一次输入]：。。。。。→第一楼
[模型第一次输出]：。。。。。↗
[你的第二次输入]：。。。。。→第二楼
[模型第二次输出]：。。。。。↗
.......
[你的第n次输入]：。。。。。→第n楼
[模型第n次输出]：。。。。。↗
```

> **注：** 你已进行了多少轮对话，或者已发送了多少次信息，就会有多少层楼

**任何无论是何种情况，任何前段，网页，APP，只要是语言模型的，就必然会有这个经典的结构。万变不离其中**

每个结构都可以进行"分析"或者"预分析"，同样的[模型正在生成的文本]也能进行分析，但人脑的分析很有可能没有模型生成的快（

---

### 6.5 分析的重点

在整个上下文中，很多情况下，都是提示词的影响都占大头。基本上说**只要知道提示词的影响，那么其他随便扫一眼（没说忽略掉），就能较为准确得到不赖的分析结果**。

> **注：** 这里的提示词泛指整个上下文中，存在的所有提示词。有时提示词可能出现在模型的消息中，得注意一下

接下来我们先从最简单的提示词分析开始。

> **注：** 除其他说明，接下来的情况，全部都为整个上下文只存在[即将发送的提示词]

---

### 6.6 语义拆解法

基于“模型是机器”的视角，我们在分析提示词时，必须摒弃人类阅读自然语言的习惯（即去理解语气、礼貌用语等）。

我们需要做的是**语义拆解（Semantic Deconstruction）**。简单来说，就是把一段话拆成给机器执行的“功能代码块”。

在最基础的单轮对话中，通过“预分析”视角，任何提示词都可以被暴力拆解为三个核心部分：

* **核心指令 (Action):** 你想让模型做什么动作？（动词：写、画、计算、分析...）
* **操作对象 (Subject):** 这个动作是针对谁的？（名词：代码、小说、数据、图片...）
* **参数限制 (Constraints):** 输出有什么具体要求？（形容词/状语：简短的、Python语言、鲁迅风格、JSON格式...）

#### 示例分析

**提示词：**

> “请你帮我写一段关于下雨的悲伤文字，字数不要太多，大概50字左右。”

**人类视角：**
这是一个礼貌的请求，想要一段描写心情不好的下雨的短文。

**机器/分析视角（拆解）：**
我们过滤掉噪音（“请你帮我”、“大概”），提取影响权重的关键词：

* **[Action]**: 写 (Generate/Write)
* **[Subject]**: 下雨 (Rain)、悲伤 (Sadness)
* **[Constraints]**: <50字 (Length < 50 chars)

**预分析结论：**
模型将激活“雨”和“悲伤”相关的语料潜空间，并受到“长度惩罚”机制的限制，生成一段短文本。

**这就是最基础的分析。** 看透了这一点，你就会发现，**所有复杂的提示词，本质上都是在不断叠加和调整这三个部分的权重，以对抗模型原本的生成概率。**

---

### 6.7 噪音与权重的博弈

在拆解过程中，你可能会发现提示词里包含大量“废话”。在提示词工程中，我们称之为**噪音（Noise）**。

* **有效提示词：** 能直接改变模型生成概率分布的词（如“代码”、“翻译”）。
* **噪音：** 对生成结果影响极小，甚至产生干扰的词（如过度的客套话、模棱两可的形容词）。

分析的精髓在于：**迅速识别并剔除噪音，只看骨架。**

如果一个提示词写了500字，但拆解后发现核心指令模糊不清，参数限制自相矛盾，那么在“预分析”阶段我们就可以断定：**这个提示词的效果一定很差**，无论它看起来写得多么华丽。

记住，模型听不懂你的“言外之意”，它只执行你给它的“字面参数”。

---